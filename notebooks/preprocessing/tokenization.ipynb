{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31824049",
   "metadata": {},
   "source": [
    "# Tokenizers exploration\n",
    "\n",
    "## Description:\n",
    "Basic **pipeline** for tokenization: initialization & application. Also includes **execution time** labels.\n",
    "\n",
    "## Contents:\n",
    "* imports & dataset initialization\n",
    "* `nltk.tokenize.TreebankWordTokenizer` example\n",
    "* `razdel` example\n",
    "* `rutokenizer` example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1cbcc017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yaroslav Pristalov\\Documents\\Programming\\nlp-coursework\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>«Зеленую милю» я смотрела два раза: 10 лет наз...</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Период конца девяностых годов-начало двухтысяч...</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Очень сложно писать рецензию на этот фильм, та...</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Любимая многими миллионами ценителями киноиску...</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>В нашем мире существует много разных фильмов. ...</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90641</th>\n",
       "      <td>Конечно, этот фильм - не лучший представитель ...</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90642</th>\n",
       "      <td>Фильм «Ламборгини: Человек-легенда» снят в 202...</td>\n",
       "      <td>NEGATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90643</th>\n",
       "      <td>Эй, рагацци, вы это серьёзно, ТАК показывать и...</td>\n",
       "      <td>NEGATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90644</th>\n",
       "      <td>Вообще, говоря о байопиках, стоит отметить, чт...</td>\n",
       "      <td>NEGATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90645</th>\n",
       "      <td>Визуальное качество, впрочем, также не безупре...</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90646 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review     label\n",
       "0      «Зеленую милю» я смотрела два раза: 10 лет наз...   NEUTRAL\n",
       "1      Период конца девяностых годов-начало двухтысяч...  POSITIVE\n",
       "2      Очень сложно писать рецензию на этот фильм, та...  POSITIVE\n",
       "3      Любимая многими миллионами ценителями киноиску...  POSITIVE\n",
       "4      В нашем мире существует много разных фильмов. ...  POSITIVE\n",
       "...                                                  ...       ...\n",
       "90641  Конечно, этот фильм - не лучший представитель ...  POSITIVE\n",
       "90642  Фильм «Ламборгини: Человек-легенда» снят в 202...  NEGATIVE\n",
       "90643  Эй, рагацци, вы это серьёзно, ТАК показывать и...  NEGATIVE\n",
       "90644  Вообще, говоря о байопиках, стоит отметить, чт...  NEGATIVE\n",
       "90645  Визуальное качество, впрочем, также не безупре...   NEUTRAL\n",
       "\n",
       "[90646 rows x 2 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%cd ../..\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "import razdel\n",
    "import rutokenizer\n",
    "\n",
    "from datasets.getters import load_reviews_Review_Label\n",
    "\n",
    "data = load_reviews_Review_Label()\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b6aed18",
   "metadata": {},
   "source": [
    "#### Tokenization time test (`razdel.tokenize()`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6157310b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4min 38s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0        [«, Зеленую, милю, », я, смотрела, два, раза, ...\n",
       "1        [Период, конца, девяностых, годов-начало, двух...\n",
       "2        [Очень, сложно, писать, рецензию, на, этот, фи...\n",
       "3        [Любимая, многими, миллионами, ценителями, кин...\n",
       "4        [В, нашем, мире, существует, много, разных, фи...\n",
       "                               ...                        \n",
       "90641    [Конечно, ,, этот, фильм, -, не, лучший, предс...\n",
       "90642    [Фильм, «, Ламборгини, :, Человек-легенда, », ...\n",
       "90643    [Эй, ,, рагацци, ,, вы, это, серьёзно, ,, ТАК,...\n",
       "90644    [Вообще, ,, говоря, о, байопиках, ,, стоит, от...\n",
       "90645    [Визуальное, качество, ,, впрочем, ,, также, н...\n",
       "Name: review, Length: 90646, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "data.review.apply(lambda review: [token.text for token in list(razdel.tokenize(review))])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "040f65c0",
   "metadata": {},
   "source": [
    "#### Tokenization time test (`TreebankWordTokenizer()`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f97cbff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 26s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0        [«Зеленую, милю», я, смотрела, два, раза, :, 1...\n",
       "1        [Период, конца, девяностых, годов-начало, двух...\n",
       "2        [Очень, сложно, писать, рецензию, на, этот, фи...\n",
       "3        [Любимая, многими, миллионами, ценителями, кин...\n",
       "4        [В, нашем, мире, существует, много, разных, фи...\n",
       "                               ...                        \n",
       "90641    [Конечно, ,, этот, фильм, -, не, лучший, предс...\n",
       "90642    [Фильм, «Ламборгини, :, Человек-легенда», снят...\n",
       "90643    [Эй, ,, рагацци, ,, вы, это, серьёзно, ,, ТАК,...\n",
       "90644    [Вообще, ,, говоря, о, байопиках, ,, стоит, от...\n",
       "90645    [Визуальное, качество, ,, впрочем, ,, также, н...\n",
       "Name: review, Length: 90646, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "data.review.apply(TreebankWordTokenizer().tokenize)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f081b0f",
   "metadata": {},
   "source": [
    "#### Tokenization time test (`rutokenizer`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64923f10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 51.4 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0        [«, Зеленую, милю, », я, смотрела, два, раза, ...\n",
       "1        [Период, конца, девяностых, годов, -, начало, ...\n",
       "2        [Очень, сложно, писать, рецензию, на, этот, фи...\n",
       "3        [Любимая, многими, миллионами, ценителями, кин...\n",
       "4        [В, нашем, мире, существует, много, разных, фи...\n",
       "                               ...                        \n",
       "90641    [Конечно, ,, этот, фильм, -, не, лучший, предс...\n",
       "90642    [Фильм, «, Ламборгини, :, Человек, -, легенда,...\n",
       "90643    [Эй, ,, рагацци, ,, вы, это, серьёзно, ,, ТАК,...\n",
       "90644    [Вообще, ,, говоря, о, байопиках, ,, стоит, от...\n",
       "90645    [Визуальное, качество, ,, впрочем, ,, также, н...\n",
       "Name: review, Length: 90646, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "data.review.apply(t.tokenize)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3170552",
   "metadata": {},
   "source": [
    "#### Tokenization time test (`spacy_russian_tokenizer`): [source](https://github.com/aatimofeev/spacy_russian_tokenizer)\n",
    "*Unsuccessful attempt*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "43df3a23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blank tokenizer : Python, spacy, tokenizer, isn't, N.A., "
     ]
    }
   ],
   "source": [
    "# No_rules\n",
    "\n",
    "from spacy.tokenizer import Tokenizer\n",
    "from spacy.lang.en import English\n",
    "py_nlp = English ()\n",
    "py_tokenizer = Tokenizer (py_nlp.vocab)\n",
    "py_tokens = py_tokenizer (\"Python spacy tokenizer isn't N.A.\")\n",
    "print (\"Blank tokenizer\", end=\" : \")\n",
    "for py_tokens in py_tokens:\n",
    "    print (py_tokens, end=', ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "330553e3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "error",
     "evalue": "bad escape \\p at position 28632",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_10104\\101113231.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mspacy_russian_tokenizer\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mRussianTokenizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMERGE_PATTERNS\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"Не ветер, а какой-то ураган!\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mnlp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRussian\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mrussian_tokenizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRussianTokenizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnlp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMERGE_PATTERNS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\anaconda3\\lib\\site-packages\\spacy\\language.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, vocab, max_length, meta, create_tokenizer, batch_size, **kwargs)\u001b[0m\n\u001b[0;32m    188\u001b[0m             \u001b[0mtokenizer_cfg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"tokenizer\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_config\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"nlp\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"tokenizer\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    189\u001b[0m             \u001b[0mcreate_tokenizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mregistry\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresolve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtokenizer_cfg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"tokenizer\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 190\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtokenizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_tokenizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    191\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdefault_error_handler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mraise_error\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\anaconda3\\lib\\site-packages\\spacy\\language.py\u001b[0m in \u001b[0;36mtokenizer_factory\u001b[1;34m(nlp)\u001b[0m\n\u001b[0;32m     89\u001b[0m         \u001b[0mprefix_search\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile_prefix_regex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprefixes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msearch\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mprefixes\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m         \u001b[0msuffix_search\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile_suffix_regex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msuffixes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msearch\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0msuffixes\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 91\u001b[1;33m         \u001b[0minfix_finditer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile_infix_regex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minfixes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfinditer\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0minfixes\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         return Tokenizer(\n\u001b[0;32m     93\u001b[0m             \u001b[0mnlp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\anaconda3\\lib\\site-packages\\spacy\\util.py\u001b[0m in \u001b[0;36mcompile_infix_regex\u001b[1;34m(entries)\u001b[0m\n\u001b[0;32m   1186\u001b[0m     \"\"\"\n\u001b[0;32m   1187\u001b[0m     \u001b[0mexpression\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"|\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpiece\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mpiece\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mpiece\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[misc, union-attr]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1188\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexpression\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1189\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\anaconda3\\lib\\re.py\u001b[0m in \u001b[0;36mcompile\u001b[1;34m(pattern, flags)\u001b[0m\n\u001b[0;32m    250\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    251\u001b[0m     \u001b[1;34m\"Compile a regular expression pattern, returning a Pattern object.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 252\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_compile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    253\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mpurge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\anaconda3\\lib\\re.py\u001b[0m in \u001b[0;36m_compile\u001b[1;34m(pattern, flags)\u001b[0m\n\u001b[0;32m    302\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msre_compile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misstring\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    303\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"first argument must be string or compiled pattern\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 304\u001b[1;33m     \u001b[0mp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msre_compile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    305\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mflags\u001b[0m \u001b[1;33m&\u001b[0m \u001b[0mDEBUG\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    306\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_cache\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0m_MAXCACHE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\anaconda3\\lib\\sre_compile.py\u001b[0m in \u001b[0;36mcompile\u001b[1;34m(p, flags)\u001b[0m\n\u001b[0;32m    786\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misstring\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    787\u001b[0m         \u001b[0mpattern\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 788\u001b[1;33m         \u001b[0mp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msre_parse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    789\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    790\u001b[0m         \u001b[0mpattern\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\anaconda3\\lib\\sre_parse.py\u001b[0m in \u001b[0;36mparse\u001b[1;34m(str, flags, state)\u001b[0m\n\u001b[0;32m    953\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    954\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 955\u001b[1;33m         \u001b[0mp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_parse_sub\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m \u001b[1;33m&\u001b[0m \u001b[0mSRE_FLAG_VERBOSE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    956\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mVerbose\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    957\u001b[0m         \u001b[1;31m# the VERBOSE flag was switched on inside the pattern.  to be\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\anaconda3\\lib\\sre_parse.py\u001b[0m in \u001b[0;36m_parse_sub\u001b[1;34m(source, state, verbose, nested)\u001b[0m\n\u001b[0;32m    442\u001b[0m     \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msource\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtell\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    443\u001b[0m     \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 444\u001b[1;33m         itemsappend(_parse(source, state, verbose, nested + 1,\n\u001b[0m\u001b[0;32m    445\u001b[0m                            not nested and not items))\n\u001b[0;32m    446\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msourcematch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"|\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\anaconda3\\lib\\sre_parse.py\u001b[0m in \u001b[0;36m_parse\u001b[1;34m(source, state, verbose, nested, first)\u001b[0m\n\u001b[0;32m    753\u001b[0m                         \u001b[1;32mif\u001b[0m \u001b[0mlookbehindgroups\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    754\u001b[0m                             \u001b[0mstate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlookbehindgroups\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 755\u001b[1;33m                     \u001b[0mp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_parse_sub\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnested\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    756\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mdir\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    757\u001b[0m                         \u001b[1;32mif\u001b[0m \u001b[0mlookbehindgroups\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\anaconda3\\lib\\sre_parse.py\u001b[0m in \u001b[0;36m_parse_sub\u001b[1;34m(source, state, verbose, nested)\u001b[0m\n\u001b[0;32m    442\u001b[0m     \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msource\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtell\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    443\u001b[0m     \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 444\u001b[1;33m         itemsappend(_parse(source, state, verbose, nested + 1,\n\u001b[0m\u001b[0;32m    445\u001b[0m                            not nested and not items))\n\u001b[0;32m    446\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msourcematch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"|\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\anaconda3\\lib\\sre_parse.py\u001b[0m in \u001b[0;36m_parse\u001b[1;34m(source, state, verbose, nested, first)\u001b[0m\n\u001b[0;32m    553\u001b[0m                     \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    554\u001b[0m                 \u001b[1;32melif\u001b[0m \u001b[0mthis\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"\\\\\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 555\u001b[1;33m                     \u001b[0mcode1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_class_escape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    556\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    557\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mset\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mthis\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;34m'-&~|'\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0msource\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mthis\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\anaconda3\\lib\\sre_parse.py\u001b[0m in \u001b[0;36m_class_escape\u001b[1;34m(source, escape)\u001b[0m\n\u001b[0;32m    348\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mescape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    349\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mASCIILETTERS\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 350\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0msource\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'bad escape %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mescape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mescape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    351\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mLITERAL\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mord\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mescape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    352\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: bad escape \\p at position 28632"
     ]
    }
   ],
   "source": [
    "from spacy.lang.ru import Russian\n",
    "from spacy_russian_tokenizer import RussianTokenizer, MERGE_PATTERNS\n",
    "text = \"Не ветер, а какой-то ураган!\"\n",
    "nlp = Russian()\n",
    "doc = nlp(text)\n",
    "russian_tokenizer = RussianTokenizer(nlp, MERGE_PATTERNS)\n",
    "nlp.add_pipe(russian_tokenizer, name='russian_tokenizer')\n",
    "doc = nlp(text)\n",
    "print([token.text for token in doc])\n",
    "# ['Не', 'ветер', ',', 'а', 'какой-то', 'ураган', '!']\n",
    "# Notice that word \"какой-то\" remains a single token. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b239e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a7453c16",
   "metadata": {},
   "source": [
    "#### The difference between `razdel` and `TreebankWordTokenizer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "01f2a0b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Я',\n",
       " 'уважаю',\n",
       " 'музыку',\n",
       " 'П',\n",
       " '.',\n",
       " 'И',\n",
       " '.',\n",
       " 'Чайковского',\n",
       " '.',\n",
       " 'А',\n",
       " 'Баха',\n",
       " 'тоже',\n",
       " 'уважаю',\n",
       " '.']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[token.text for token in list(razdel.tokenize('Я уважаю музыку П.И. Чайковского. А Баха тоже уважаю.'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "14d8a5ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Я',\n",
       " 'уважаю',\n",
       " 'музыку',\n",
       " 'П.И.',\n",
       " 'Чайковского.',\n",
       " 'А',\n",
       " 'Баха',\n",
       " 'тоже',\n",
       " 'уважаю',\n",
       " '.']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TreebankWordTokenizer().tokenize('Я уважаю музыку П.И. Чайковского. А Баха тоже уважаю.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5399679",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
