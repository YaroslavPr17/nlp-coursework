{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ee2902f",
   "metadata": {},
   "source": [
    "# `log_reg_classification_with_ngrams . Saved model` notebook\n",
    "### Descriprion\n",
    "This notebook was additionally created to conduct experiments ignored in the first iteration of experiments with logistic regression. Here you will see attempts to reduce model size and explorations of the least number of features with best classification metrics obtained. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c345487",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/pristalovya/Документы/nlp-coursework\n"
     ]
    }
   ],
   "source": [
    "%cd ../.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ebb04e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets_ import DatasetLoader\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import dill\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from nltk.tokenize import WhitespaceTokenizer\n",
    "\n",
    "np.set_printoptions(threshold=np.inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b6fa809",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/pristalovya/Документы/nlp-coursework/data/reviews_Review_Label/reviews_Review_Label_razdel_no.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>54700</th>\n",
       "      <td>фильм не стоить бы выходить за предел великобр...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67873</th>\n",
       "      <td>это один из самый впечатляющий и по-настоящему...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44030</th>\n",
       "      <td>первый часть ' чужой ' в свой время произвести...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21503</th>\n",
       "      <td>история начинающий барабанщик эндрю зародиться...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75163</th>\n",
       "      <td>&lt; b &gt; ну вот мы и дождаться . в прокат выйти н...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6265</th>\n",
       "      <td>весь мы в равный мера свойственно как злорадст...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54886</th>\n",
       "      <td>даже в такой неординарный фильм . да , я увери...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76820</th>\n",
       "      <td>я не быть сильно заинтересованный ' дэдпул ' ,...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>фильм , который неизменно занимать первый мест...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15795</th>\n",
       "      <td>этот фильм я ждать весь сердце , как истинный ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>55346 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review  label\n",
       "54700  фильм не стоить бы выходить за предел великобр...      0\n",
       "67873  это один из самый впечатляющий и по-настоящему...      2\n",
       "44030  первый часть ' чужой ' в свой время произвести...      2\n",
       "21503  история начинающий барабанщик эндрю зародиться...      2\n",
       "75163  < b > ну вот мы и дождаться . в прокат выйти н...      2\n",
       "...                                                  ...    ...\n",
       "6265   весь мы в равный мера свойственно как злорадст...      0\n",
       "54886  даже в такой неординарный фильм . да , я увери...      2\n",
       "76820  я не быть сильно заинтересованный ' дэдпул ' ,...      2\n",
       "860    фильм , который неизменно занимать первый мест...      2\n",
       "15795  этот фильм я ждать весь сердце , как истинный ...      2\n",
       "\n",
       "[55346 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, test = DatasetLoader.load_reviews_Review_Label_dataset(tokenizer='razdel',\n",
    "                                                              stopwords='no',\n",
    "                                                             remove_neutral_class=True,\n",
    "                                                             train_test_split=True,\n",
    "                                                             classnames_to_int=True,\n",
    "                                                             show_path=True,\n",
    "                                                             )\n",
    "\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7671b1e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountVectorizing...\n",
      "CPU times: user 2min 31s, sys: 4.51 s, total: 2min 36s\n",
      "Wall time: 2min 36s\n",
      "(55346, 15287875)\n",
      "Training logreg...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pristalovya/Inter/linux_packages/anaconda3/envs/nlp/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 57min 56s, sys: 2min 19s, total: 1h 16s\n",
      "Wall time: 19min 58s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.85      0.86      2979\n",
      "           2       0.98      0.98      0.98     20742\n",
      "\n",
      "    accuracy                           0.97     23721\n",
      "   macro avg       0.93      0.92      0.92     23721\n",
      "weighted avg       0.97      0.97      0.97     23721\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('CountVectorizing...')\n",
    "cnt_vec = CountVectorizer(tokenizer=WhitespaceTokenizer().tokenize, ngram_range=(1, 3))\n",
    "%time X_train = cnt_vec.fit_transform(train.review)\n",
    "X_test  = cnt_vec.transform(test.review)\n",
    "print(X_train.shape)\n",
    "\n",
    "\n",
    "print('Training logreg...')\n",
    "clf = LogisticRegression(max_iter=500, class_weight='balanced')\n",
    "%time clf.fit(X_train, train.label)\n",
    "pred = clf.predict(X_test)\n",
    "\n",
    "print(classification_report(test.label, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5046a9a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountVectorizing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pristalovya/Inter/linux_packages/anaconda3/envs/nlp/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 58.7 s, sys: 1.99 s, total: 1min\n",
      "Wall time: 1min\n",
      "(55346, 162847)\n",
      "Training logreg...\n",
      "CPU times: user 13min 25s, sys: 8.43 s, total: 13min 34s\n",
      "Wall time: 2min 18s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.86      0.86      2979\n",
      "           2       0.98      0.98      0.98     20742\n",
      "\n",
      "    accuracy                           0.97     23721\n",
      "   macro avg       0.92      0.92      0.92     23721\n",
      "weighted avg       0.97      0.97      0.97     23721\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('CountVectorizing...')\n",
    "cnt_vec = CountVectorizer(tokenizer=WhitespaceTokenizer().tokenize, ngram_range=(1, 3), min_df=30)\n",
    "%time X_train = cnt_vec.fit_transform(train.review)\n",
    "X_test  = cnt_vec.transform(test.review)\n",
    "print(X_train.shape)\n",
    "\n",
    "\n",
    "print('Training logreg...')\n",
    "clf = LogisticRegression(max_iter=1000, class_weight='balanced')\n",
    "%time clf.fit(X_train, train.label)\n",
    "pred = clf.predict(X_test)\n",
    "\n",
    "print(classification_report(test.label, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3146e799",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountVectorizing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pristalovya/Inter/linux_packages/anaconda3/envs/nlp/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 58.5 s, sys: 1.94 s, total: 1min\n",
      "Wall time: 1min\n",
      "(55346, 70542)\n",
      "Training logreg...\n",
      "CPU times: user 10min 39s, sys: 6.51 s, total: 10min 46s\n",
      "Wall time: 1min 48s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.86      0.86      2979\n",
      "           2       0.98      0.98      0.98     20742\n",
      "\n",
      "    accuracy                           0.96     23721\n",
      "   macro avg       0.91      0.92      0.92     23721\n",
      "weighted avg       0.96      0.96      0.96     23721\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('CountVectorizing...')\n",
    "cnt_vec = CountVectorizer(tokenizer=WhitespaceTokenizer().tokenize, ngram_range=(1, 3), min_df=70)\n",
    "%time cnt_vec.fit(train.review)\n",
    "X_train, X_test  = cnt_vec.transform(train.review), cnt_vec.transform(test.review)\n",
    "print(X_train.shape)\n",
    "\n",
    "\n",
    "print('Training logreg...')\n",
    "clf = LogisticRegression(max_iter=2000, class_weight='balanced')\n",
    "%time clf.fit(X_train, train.label)\n",
    "pred = clf.predict(X_test)\n",
    "\n",
    "print(classification_report(test.label, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dba96f72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountVectorizing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pristalovya/Inter/linux_packages/anaconda3/envs/nlp/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 45s, sys: 1.77 s, total: 1min 47s\n",
      "Wall time: 1min 46s\n",
      "(55346, 70542)\n",
      "Training logreg...\n",
      "CPU times: user 10min 25s, sys: 6.86 s, total: 10min 31s\n",
      "Wall time: 1min 45s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.86      0.86      2979\n",
      "           2       0.98      0.98      0.98     20742\n",
      "\n",
      "    accuracy                           0.96     23721\n",
      "   macro avg       0.92      0.92      0.92     23721\n",
      "weighted avg       0.96      0.96      0.96     23721\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('CountVectorizing...')\n",
    "cnt_vec = CountVectorizer(tokenizer=WhitespaceTokenizer().tokenize, ngram_range=(1, 3), max_features=70542)\n",
    "%time cnt_vec.fit(train.review)\n",
    "X_train, X_test  = cnt_vec.transform(train.review), cnt_vec.transform(test.review)\n",
    "print(X_train.shape)\n",
    "\n",
    "\n",
    "print('Training logreg...')\n",
    "clf = LogisticRegression(max_iter=2000, class_weight='balanced')\n",
    "%time clf.fit(X_train, train.label)\n",
    "pred = clf.predict(X_test)\n",
    "\n",
    "print(classification_report(test.label, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e47bc89c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountVectorizing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pristalovya/Inter/linux_packages/anaconda3/envs/nlp/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 3s, sys: 1.67 s, total: 1min 5s\n",
      "Wall time: 1min 5s\n",
      "(55346, 75888)\n",
      "Training logreg...\n",
      "CPU times: user 10min 54s, sys: 7.16 s, total: 11min 2s\n",
      "Wall time: 1min 50s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.86      0.86      2979\n",
      "           2       0.98      0.98      0.98     20742\n",
      "\n",
      "    accuracy                           0.96     23721\n",
      "   macro avg       0.92      0.92      0.92     23721\n",
      "weighted avg       0.96      0.96      0.96     23721\n",
      "\n",
      "CPU times: user 13min 6s, sys: 9.07 s, total: 13min 15s\n",
      "Wall time: 4min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "print('CountVectorizing...')\n",
    "cnt_vec = CountVectorizer(tokenizer=WhitespaceTokenizer().tokenize, ngram_range=(1, 3), min_df=65)\n",
    "%time cnt_vec.fit(train.review)\n",
    "X_train, X_test  = cnt_vec.transform(train.review), cnt_vec.transform(test.review)\n",
    "print(X_train.shape)\n",
    "\n",
    "\n",
    "print('Training logreg...')\n",
    "clf = LogisticRegression(max_iter=2000, class_weight='balanced')\n",
    "%time clf.fit(X_train, train.label)\n",
    "pred = clf.predict(X_test)\n",
    "\n",
    "print(classification_report(test.label, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c6247a74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountVectorizing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pristalovya/Inter/linux_packages/anaconda3/envs/nlp/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 34s, sys: 2.77 s, total: 1min 37s\n",
      "Wall time: 1min 37s\n",
      "(55346, 50000)\n",
      "Training logreg...\n",
      "CPU times: user 7min 28s, sys: 4.56 s, total: 7min 32s\n",
      "Wall time: 1min 15s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.85      0.84      2979\n",
      "           2       0.98      0.98      0.98     20742\n",
      "\n",
      "    accuracy                           0.96     23721\n",
      "   macro avg       0.91      0.91      0.91     23721\n",
      "weighted avg       0.96      0.96      0.96     23721\n",
      "\n",
      "CPU times: user 9min 51s, sys: 7.78 s, total: 9min 58s\n",
      "Wall time: 3min 41s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "print('CountVectorizing...')\n",
    "cnt_vec = CountVectorizer(tokenizer=WhitespaceTokenizer().tokenize, ngram_range=(1, 3), max_features=50000)\n",
    "%time cnt_vec.fit(train.review)\n",
    "X_train, X_test  = cnt_vec.transform(train.review), cnt_vec.transform(test.review)\n",
    "print(X_train.shape)\n",
    "\n",
    "\n",
    "print('Training logreg...')\n",
    "clf = LogisticRegression(max_iter=2000, class_weight='balanced')\n",
    "%time clf.fit(X_train, train.label)\n",
    "pred = clf.predict(X_test)\n",
    "\n",
    "print(classification_report(test.label, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9821ea3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e2aaf17",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/pristalovya/Документы/nlp-coursework/data/reviews_Review_Label/reviews_Review_Label_razdel_no.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19135</th>\n",
       "      <td>начать с начало : очень долго не мочь собратьс...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25023</th>\n",
       "      <td>с первый кадр обстановка захватить я . знакомы...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72716</th>\n",
       "      <td>это чувство возникнуть ещё при просмотр первый...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7891</th>\n",
       "      <td>полнометражный мультфильм ' wall-e ' относитьс...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68417</th>\n",
       "      <td>с сам начало зритель погружаться в голливуд ко...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6265</th>\n",
       "      <td>искренность и непринуждённость ' 1 + 1 ' притя...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54886</th>\n",
       "      <td>давно хотеть ознакомиться с жанр кукольный ани...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76820</th>\n",
       "      <td>« я должный верить в тот мир , который создава...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>я не любить фильм о война , но наверное нужно ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15795</th>\n",
       "      <td>- magical emma watson вот и выйти в свет после...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>63452 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review  label\n",
       "19135  начать с начало : очень долго не мочь собратьс...      2\n",
       "25023  с первый кадр обстановка захватить я . знакомы...      2\n",
       "72716  это чувство возникнуть ещё при просмотр первый...      0\n",
       "7891   полнометражный мультфильм ' wall-e ' относитьс...      2\n",
       "68417  с сам начало зритель погружаться в голливуд ко...      2\n",
       "...                                                  ...    ...\n",
       "6265   искренность и непринуждённость ' 1 + 1 ' притя...      2\n",
       "54886  давно хотеть ознакомиться с жанр кукольный ани...      2\n",
       "76820  « я должный верить в тот мир , который создава...      2\n",
       "860    я не любить фильм о война , но наверное нужно ...      1\n",
       "15795  - magical emma watson вот и выйти в свет после...      2\n",
       "\n",
       "[63452 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, test = DatasetLoader.load_reviews_Review_Label_dataset(tokenizer='razdel',\n",
    "                                                             stopwords='no',\n",
    "                                                             train_test_split=True,\n",
    "                                                             classnames_to_int=True,\n",
    "                                                             show_path=True,\n",
    "                                                             )\n",
    "\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "192fa899",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountVectorizing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pristalovya/Inter/linux_packages/anaconda3/envs/nlp/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 6s, sys: 2.33 s, total: 1min 8s\n",
      "Wall time: 1min 9s\n",
      "(63452, 275941)\n",
      "Training logreg...\n",
      "CPU times: user 1h 32min 14s, sys: 58.9 s, total: 1h 33min 13s\n",
      "Wall time: 15min 46s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.70      0.71      3030\n",
      "           1       0.44      0.41      0.43      3429\n",
      "           2       0.92      0.93      0.93     20735\n",
      "\n",
      "    accuracy                           0.84     27194\n",
      "   macro avg       0.69      0.68      0.69     27194\n",
      "weighted avg       0.84      0.84      0.84     27194\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pristalovya/Inter/linux_packages/anaconda3/envs/nlp/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "print('CountVectorizing...')\n",
    "cnt_vec = CountVectorizer(tokenizer=WhitespaceTokenizer().tokenize, ngram_range=(1, 3), min_df=20)\n",
    "%time cnt_vec.fit(train.review)\n",
    "X_train, X_test = cnt_vec.transform(train.review), cnt_vec.transform(test.review)\n",
    "print(X_train.shape)\n",
    "\n",
    "\n",
    "print('Training logreg...')\n",
    "clf = LogisticRegression(max_iter=2000, class_weight='balanced')\n",
    "%time clf.fit(X_train, train.label)\n",
    "pred = clf.predict(X_test)\n",
    "\n",
    "print(classification_report(test.label, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62871898",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pristalovya/Inter/linux_packages/anaconda3/envs/nlp/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountVectorizing...\n",
      "CPU times: user 1min 6s, sys: 2.14 s, total: 1min 8s\n",
      "Wall time: 1min 8s\n",
      "(63452, 275941)\n",
      "Training logreg...\n",
      "CPU times: user 1h 26min 41s, sys: 53.7 s, total: 1h 27min 34s\n",
      "Wall time: 14min 39s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.70      0.72      3030\n",
      "           1       0.45      0.40      0.43      3429\n",
      "           2       0.92      0.94      0.93     20735\n",
      "\n",
      "    accuracy                           0.85     27194\n",
      "   macro avg       0.70      0.68      0.69     27194\n",
      "weighted avg       0.84      0.85      0.84     27194\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('CountVectorizing...')\n",
    "cnt_vec = CountVectorizer(tokenizer=WhitespaceTokenizer().tokenize, ngram_range=(1, 3), min_df=20)\n",
    "%time cnt_vec.fit(train.review)\n",
    "X_train, X_test = cnt_vec.transform(train.review), cnt_vec.transform(test.review)\n",
    "print(X_train.shape)\n",
    "\n",
    "\n",
    "print('Training logreg...')\n",
    "clf = LogisticRegression(max_iter=2000, class_weight='balanced', multi_class='ovr')\n",
    "%time clf.fit(X_train, train.label)\n",
    "pred = clf.predict(X_test)\n",
    "\n",
    "print(classification_report(test.label, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "330d7ce4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountVectorizing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pristalovya/Inter/linux_packages/anaconda3/envs/nlp/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 5s, sys: 2.1 s, total: 1min 7s\n",
      "Wall time: 1min 7s\n",
      "(63452, 275941)\n",
      "Training logreg...\n",
      "CPU times: user 39min 27s, sys: 130 ms, total: 39min 27s\n",
      "Wall time: 39min 27s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.73      0.72      3030\n",
      "           1       0.44      0.47      0.45      3429\n",
      "           2       0.93      0.92      0.93     20735\n",
      "\n",
      "    accuracy                           0.84     27194\n",
      "   macro avg       0.70      0.71      0.70     27194\n",
      "weighted avg       0.85      0.84      0.84     27194\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pristalovya/Inter/linux_packages/anaconda3/envs/nlp/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "print('CountVectorizing...')\n",
    "cnt_vec = CountVectorizer(tokenizer=WhitespaceTokenizer().tokenize, ngram_range=(1, 3), min_df=20)\n",
    "%time cnt_vec.fit(train.review)\n",
    "X_train, X_test = cnt_vec.transform(train.review), cnt_vec.transform(test.review)\n",
    "print(X_train.shape)\n",
    "\n",
    "\n",
    "print('Training logreg...')\n",
    "clf = LogisticRegression(max_iter=2000, class_weight='balanced', multi_class='multinomial', solver='saga')\n",
    "%time clf.fit(X_train, train.label)\n",
    "pred = clf.predict(X_test)\n",
    "\n",
    "print(classification_report(test.label, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eeb03940",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountVectorizing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pristalovya/Inter/linux_packages/anaconda3/envs/nlp/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 50s, sys: 6.84 s, total: 3min 57s\n",
      "Wall time: 3min 57s\n",
      "(55346, 100000)\n",
      "Training logreg...\n",
      "CPU times: user 4min 17s, sys: 2.38 s, total: 4min 19s\n",
      "Wall time: 45.7 s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.83      0.83      2979\n",
      "           2       0.98      0.98      0.98     20742\n",
      "\n",
      "    accuracy                           0.96     23721\n",
      "   macro avg       0.91      0.90      0.91     23721\n",
      "weighted avg       0.96      0.96      0.96     23721\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('CountVectorizing...')\n",
    "cnt_vec = CountVectorizer(tokenizer=WhitespaceTokenizer().tokenize, ngram_range=(1, 4), max_features=100000)\n",
    "%time cnt_vec.fit(train.review)\n",
    "X_train, X_test = cnt_vec.transform(train.review), cnt_vec.transform(test.review)\n",
    "print(X_train.shape)\n",
    "\n",
    "\n",
    "print('Training logreg...')\n",
    "clf = LogisticRegression(max_iter=2000, class_weight='balanced')\n",
    "%time clf.fit(X_train, train.label)\n",
    "pred = clf.predict(X_test)\n",
    "\n",
    "print(classification_report(test.label, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef51ae9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2208c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29012f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('models/logreg_tokrazdel_stopno_100k.model', 'wb') as f:\n",
    "    dill.dump(clf, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "576fc035",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('models/count_vectorizer_1_4_100000.vocab', 'wb') as f:\n",
    "    dill.dump(cnt_vec.vocabulary_, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "13009d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('models/logreg_tokrazdel_stopno_100k.model', 'rb') as f:\n",
    "    clf = dill.load(f)\n",
    "\n",
    "with open('models/count_vectorizer_1_4_100000.vocab', 'rb') as f:\n",
    "    vocab = dill.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ad87ea48",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt_vec = CountVectorizer(tokenizer=WhitespaceTokenizer().tokenize, ngram_range=(1, 4), vocabulary=vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b36f114e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = cnt_vec.transform(test.review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e77ee583",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4fec9e9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 0, ..., 2, 2, 2])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "adac3399",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.86      0.86      2979\n",
      "           2       0.98      0.98      0.98     20742\n",
      "\n",
      "    accuracy                           0.96     23721\n",
      "   macro avg       0.92      0.92      0.92     23721\n",
      "weighted avg       0.96      0.96      0.96     23721\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test.label, pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
