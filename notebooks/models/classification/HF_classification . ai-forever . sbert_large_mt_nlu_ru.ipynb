{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6d9af0b",
   "metadata": {},
   "source": [
    "# `HF_classification . ai-forever . sbert_large_mt_nlu_ru` notebook\n",
    "### Descriprion\n",
    "This notebook is one of those which were used to training large DL models from `transformers` library and measuring classification performance. Experiments with **sbert-large-mt-nlu-ru** model was conducted here. However, the model was not profoundly explored due to its size and lack of local computational resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7331aaf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/pristalovya/Документы/nlp-coursework\n"
     ]
    }
   ],
   "source": [
    "%cd ../.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4f29d455",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets_ import DatasetLoader\n",
    "\n",
    "from datasets import load_dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.utils import resample\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib notebook\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from transformers import AdamW\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import sys\n",
    "\n",
    "from nltk import WhitespaceTokenizer\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from transformers import (\n",
    "    pipeline,                       \n",
    "    AutoModelForSequenceClassification,                       \n",
    "    BertForSequenceClassification,                       \n",
    "    AutoTokenizer,\n",
    "    AdamW,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b713c7cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/pristalovya/Документы/nlp-coursework/data/reviews_Review_Label/reviews_Review_Label.csv\n",
      "(55346, 2) (23721, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7527/3832119039.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train.label[train['label'] == 2] = 1\n",
      "/tmp/ipykernel_7527/3832119039.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test.label[test['label'] == 2] = 1\n"
     ]
    }
   ],
   "source": [
    "train, test = DatasetLoader.load_reviews_Review_Label_dataset(train_test_split=True,\n",
    "                                                              classnames_to_int=True,\n",
    "                                                              remove_neutral_class=True,\n",
    "                                                              show_path=True,)\n",
    "train.label[train['label'] == 2] = 1\n",
    "test.label[test['label'] == 2] = 1\n",
    "\n",
    "print(train.shape, test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5ab76756",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>54700</th>\n",
       "      <td>Фильму не стоило бы выходить за пределы Велико...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67873</th>\n",
       "      <td>Это один из самых впечатляющих и по-настоящему...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44030</th>\n",
       "      <td>Первая часть 'Чужих' в свое время произвела на...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21503</th>\n",
       "      <td>История начинающего барабанщика Эндрю зародила...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75163</th>\n",
       "      <td>&lt;b&gt;Ну вот мы и дождались. В прокат вышла новая...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6265</th>\n",
       "      <td>Всем нам в равной мере свойственно как злорадс...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54886</th>\n",
       "      <td>Даже в таком неординарном фильме. Да, я уверен...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76820</th>\n",
       "      <td>Я не был сильно заинтересован 'Дэдпулом', одна...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>Фильм, который неизменно занимает первые места...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15795</th>\n",
       "      <td>Этот фильм я ждала всем сердцем, как истинный ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>55346 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review  label\n",
       "54700  Фильму не стоило бы выходить за пределы Велико...      0\n",
       "67873  Это один из самых впечатляющих и по-настоящему...      1\n",
       "44030  Первая часть 'Чужих' в свое время произвела на...      1\n",
       "21503  История начинающего барабанщика Эндрю зародила...      1\n",
       "75163  <b>Ну вот мы и дождались. В прокат вышла новая...      1\n",
       "...                                                  ...    ...\n",
       "6265   Всем нам в равной мере свойственно как злорадс...      0\n",
       "54886  Даже в таком неординарном фильме. Да, я уверен...      1\n",
       "76820  Я не был сильно заинтересован 'Дэдпулом', одна...      1\n",
       "860    Фильм, который неизменно занимает первые места...      1\n",
       "15795  Этот фильм я ждала всем сердцем, как истинный ...      1\n",
       "\n",
       "[55346 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2205b9e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    48477\n",
       "0     6869\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "94e3177f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.concat([train, resample(train[train.label == 0], n_samples=41608, random_state=42)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4f3d9ddb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>54700</th>\n",
       "      <td>Фильму не стоило бы выходить за пределы Велико...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67873</th>\n",
       "      <td>Это один из самых впечатляющих и по-настоящему...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44030</th>\n",
       "      <td>Первая часть 'Чужих' в свое время произвела на...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21503</th>\n",
       "      <td>История начинающего барабанщика Эндрю зародила...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75163</th>\n",
       "      <td>&lt;b&gt;Ну вот мы и дождались. В прокат вышла новая...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7435</th>\n",
       "      <td>Есть разведенка, которая совсем не умеет общат...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62124</th>\n",
       "      <td>– Артем, у тебя есть три дня, чтобы предупреди...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42486</th>\n",
       "      <td>Что нам обещает показать фильм «Пролетая над г...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33186</th>\n",
       "      <td>Это новый мир. Этот фильм раз и навсегда измен...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16327</th>\n",
       "      <td>На сегодняшний день, по мнению пользователей К...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>96954 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review  label\n",
       "54700  Фильму не стоило бы выходить за пределы Велико...      0\n",
       "67873  Это один из самых впечатляющих и по-настоящему...      1\n",
       "44030  Первая часть 'Чужих' в свое время произвела на...      1\n",
       "21503  История начинающего барабанщика Эндрю зародила...      1\n",
       "75163  <b>Ну вот мы и дождались. В прокат вышла новая...      1\n",
       "...                                                  ...    ...\n",
       "7435   Есть разведенка, которая совсем не умеет общат...      0\n",
       "62124  – Артем, у тебя есть три дня, чтобы предупреди...      0\n",
       "42486  Что нам обещает показать фильм «Пролетая над г...      0\n",
       "33186  Это новый мир. Этот фильм раз и навсегда измен...      0\n",
       "16327  На сегодняшний день, по мнению пользователей К...      0\n",
       "\n",
       "[96954 rows x 2 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8d9f52df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    48477\n",
       "1    48477\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ef51e093",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25749</th>\n",
       "      <td>Большое количество фильмов советского кинемато...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44489</th>\n",
       "      <td>Тяжело ответить на вопрос, что же такое Догвил...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53162</th>\n",
       "      <td>В наше время такие героини, как скажем наприме...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25843</th>\n",
       "      <td>В 2001 году нам довелось познакомиться с новой...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44609</th>\n",
       "      <td>«Это фильм?», «У них не хватило денег на декор...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14104</th>\n",
       "      <td>- Через столько лет?\\r\\n- Всегда\\r\\n\\r\\nБезусл...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22232</th>\n",
       "      <td>После просмотра трейлера, я был под большим вп...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73314</th>\n",
       "      <td>Многие не верят, но я легко подключаюсь к прои...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47848</th>\n",
       "      <td>Как часто нам нужна поддержка? Да, пожалуй, оч...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10215</th>\n",
       "      <td>15 апреля 2012 исполнилось ровно 100 лет с тог...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23721 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review  label\n",
       "25749  Большое количество фильмов советского кинемато...      1\n",
       "44489  Тяжело ответить на вопрос, что же такое Догвил...      1\n",
       "53162  В наше время такие героини, как скажем наприме...      0\n",
       "25843  В 2001 году нам довелось познакомиться с новой...      1\n",
       "44609  «Это фильм?», «У них не хватило денег на декор...      1\n",
       "...                                                  ...    ...\n",
       "14104  - Через столько лет?\\r\\n- Всегда\\r\\n\\r\\nБезусл...      1\n",
       "22232  После просмотра трейлера, я был под большим вп...      1\n",
       "73314  Многие не верят, но я легко подключаюсь к прои...      1\n",
       "47848  Как часто нам нужна поддержка? Да, пожалуй, оч...      1\n",
       "10215  15 апреля 2012 исполнилось ровно 100 лет с тог...      1\n",
       "\n",
       "[23721 rows x 2 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6792a65a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f79f0df5e5f04f6683bdaac58353b974",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/1.71G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at ai-forever/sbert_large_mt_nlu_ru and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# 1.71 Gb\n",
    "\n",
    "checkpoint = \"ai-forever/sbert_large_mt_nlu_ru\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11b4b852",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReviewDataset(Dataset):\n",
    "    def __init__(self, reviews, labels, tokenizer, max_model_input_length=512):\n",
    "        self.reviews = reviews\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_model_input_length = max_model_input_length\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        review = self.reviews.iloc[idx]\n",
    "        label = self.labels.iloc[idx]\n",
    "        review_tokenized = self.tokenizer(\n",
    "            review,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_model_input_length,\n",
    "            padding='max_length',\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt',\n",
    "            truncation=True,\n",
    "        )\n",
    "        input_ids = review_tokenized['input_ids'].flatten()\n",
    "        attn_mask = review_tokenized['attention_mask'].flatten()\n",
    "        \n",
    "        return {\n",
    "            'review': review,\n",
    "            'input_ids': input_ids,\n",
    "            'attention_mask': attn_mask,\n",
    "            'label': label,\n",
    "        }\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3131a12a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(120138, 1024, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 1024)\n",
       "      (token_type_embeddings): Embedding(2, 1024)\n",
       "      (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-23): 24 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=1024, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31bf59f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertClassifier:\n",
    "    def __init__(self, checkpoint, n_classes=2):\n",
    "        \n",
    "        self.model = BertForSequenceClassification.from_pretrained(checkpoint, ignore_mismatched_sizes=True)\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.max_len = 1024\n",
    "        self.out_features = 1024\n",
    "        self.model.classifier = torch.nn.Linear(self.out_features, n_classes)\n",
    "        self.model.to(self.device)\n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "        \n",
    "        self.optimizer = torch.optim.Adam(self.model.classifier.parameters(), lr=1e-3)\n",
    "        \n",
    "        self.all_losses = []\n",
    "        self.epoch_losses = []\n",
    "        self.epoch_acc = []       \n",
    "\n",
    "        \n",
    "    def fit(self):\n",
    "        self.model.train()\n",
    "        losses = []\n",
    "        correct_predictions = 0\n",
    "        \n",
    "        t = tqdm(train_dataloader, file=sys.stdout, ncols=100)\n",
    "\n",
    "        for data in t:\n",
    "            input_ids = data['input_ids'].to(self.device)\n",
    "            attention_mask = data['attention_mask'].to(self.device).to(float)\n",
    "            labels = data['label'].to(self.device)\n",
    "\n",
    "            outputs = self.model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask\n",
    "                )\n",
    "\n",
    "            preds = outputs.logits.argmax(dim=1)\n",
    "            \n",
    "            loss = self.loss_fn(outputs.logits, labels)\n",
    "\n",
    "            correct_predictions += torch.sum(preds == labels)\n",
    "\n",
    "            losses.append(loss.item())\n",
    "\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            self.optimizer.zero_grad()\n",
    "            \n",
    "            t.set_postfix(ordered_dict={'loss': loss.item()}, refresh=True)\n",
    "\n",
    "\n",
    "        train_acc = correct_predictions.double() / len(train_dataset)\n",
    "        train_loss = np.mean(losses)\n",
    "        self.all_losses.extend(losses)\n",
    "        self.epoch_losses.append(train_loss)\n",
    "        self.epoch_acc.append(train_acc)\n",
    "        return train_acc, train_loss\n",
    "    \n",
    "    \n",
    "    def evaluate(self):\n",
    "        self.model.eval()\n",
    "        losses = []\n",
    "        correct_predictions = 0\n",
    "        \n",
    "        all_preds = []\n",
    "        \n",
    "        t = tqdm(test_dataloader, file=sys.stdout, ncols=100)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for data in t:\n",
    "                input_ids = data[\"input_ids\"].to(self.device)\n",
    "                attention_mask = data[\"attention_mask\"].to(self.device)\n",
    "                labels = data[\"label\"].to(self.device)\n",
    "\n",
    "                outputs = self.model(\n",
    "                    input_ids=input_ids,\n",
    "                    attention_mask=attention_mask\n",
    "                )\n",
    "\n",
    "                preds = torch.argmax(outputs.logits, dim=1)\n",
    "                loss = self.loss_fn(outputs.logits, labels)\n",
    "                correct_predictions += torch.sum(preds == labels)\n",
    "                \n",
    "                all_preds.extend(preds.tolist())\n",
    "                \n",
    "                losses.append(loss.item())\n",
    "                \n",
    "                t.set_postfix(ordered_dict={'loss': loss.item()}, refresh=True)\n",
    "                \n",
    "        print('Classification report:')\n",
    "        print(classification_report(test_dataset.labels, all_preds))\n",
    "\n",
    "        val_acc = correct_predictions.double() / len(test_dataset)\n",
    "        val_loss = np.mean(losses)\n",
    "        return val_acc.item(), val_loss\n",
    "    \n",
    "\n",
    "    \n",
    "    def train(self, n_epochs, pretrain_test=False):\n",
    "        try:\n",
    "            best_accuracy = 0\n",
    "\n",
    "            if pretrain_test:\n",
    "                print('Pre-training test:')\n",
    "                val_acc, val_loss = self.evaluate()\n",
    "                print(f'Test loss {val_loss} accuracy {val_acc}')\n",
    "                print('-' * 10)\n",
    "\n",
    "            for epoch in range(n_epochs):\n",
    "                print(f'Epoch {epoch + 1}/{n_epochs}')\n",
    "                train_acc, train_loss = self.fit()\n",
    "                print(f'Train loss {train_loss} accuracy {train_acc}')\n",
    "\n",
    "                val_acc, val_loss = self.evaluate()\n",
    "                print(f'Test loss {val_loss} accuracy {val_acc}')\n",
    "                print('-' * 10)\n",
    "\n",
    "    \n",
    "        except KeyboardInterrupt:\n",
    "            print('Training was manually stopped. ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c806cdb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = BertClassifier(\"ai-forever/sbert_large_mt_nlu_ru\")\n",
    "\n",
    "train_dataset = ReviewDataset(train.review, train.label, clf.tokenizer)\n",
    "test_dataset = ReviewDataset(test.review, test.label, clf.tokenizer)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "67cf50f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All parameters: 426910722\n",
      "Trainable parameters: 2050\n"
     ]
    }
   ],
   "source": [
    "for param in clf.model.bert.parameters():\n",
    "    param.requires_grad = False\n",
    "print('All parameters:', sum(p.numel() for p in clf.model.parameters()))\n",
    "print('Trainable parameters:', sum(p.numel() for p in clf.model.parameters() if p.requires_grad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b436039",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      " 32%|██████████████▊                               | 556/1730 [43:54<1:32:43,  4.74s/it, loss=0.381]\n",
      "Training was manually stopped. \n"
     ]
    }
   ],
   "source": [
    "clf.train(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6db4754b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pristalovya/Inter/linux_packages/anaconda3/envs/nlp/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdamW (\n",
      "Parameter Group 0\n",
      "    betas: (0.9, 0.999)\n",
      "    correct_bias: False\n",
      "    eps: 1e-06\n",
      "    lr: 2e-05\n",
      "    weight_decay: 0.0\n",
      ")\n",
      "Pre-training test:\n",
      "100%|█████████████████████████████████████████████████| 742/742 [56:06<00:00,  4.54s/it, loss=0.127]\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.28      0.41      2979\n",
      "           1       0.90      0.99      0.94     20742\n",
      "\n",
      "    accuracy                           0.90     23721\n",
      "   macro avg       0.83      0.63      0.67     23721\n",
      "weighted avg       0.89      0.90      0.88     23721\n",
      "\n",
      "Test loss 0.25290343917484553 accuracy 0.8979385354748957\n",
      "----------\n",
      "Epoch 1/10\n",
      "  4%|█▋                                             | 61/1730 [04:47<2:11:12,  4.72s/it, loss=0.135]\n",
      "Training was manually stopped. \n"
     ]
    }
   ],
   "source": [
    "clf.optimizer = AdamW(clf.model.classifier.parameters(), lr=2e-5, correct_bias=False)\n",
    "print(clf.optimizer)\n",
    "clf.train(10, pretrain_test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d7cc4926",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pristalovya/Inter/linux_packages/anaconda3/envs/nlp/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdamW (\n",
      "Parameter Group 0\n",
      "    betas: (0.9, 0.999)\n",
      "    correct_bias: False\n",
      "    eps: 1e-06\n",
      "    lr: 2e-05\n",
      "    weight_decay: 0.0\n",
      ")\n",
      "Epoch 1/10\n",
      "100%|█████████████████████████████████████████████| 3030/3030 [3:51:16<00:00,  4.58s/it, loss=0.472]\n",
      "Train loss 0.4514490670791947 accuracy 0.7965530045176062\n",
      "100%|█████████████████████████████████████████████████| 742/742 [54:41<00:00,  4.42s/it, loss=0.429]\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.85      0.53      2979\n",
      "           1       0.97      0.80      0.88     20742\n",
      "\n",
      "    accuracy                           0.81     23721\n",
      "   macro avg       0.68      0.83      0.70     23721\n",
      "weighted avg       0.90      0.81      0.84     23721\n",
      "\n",
      "Test loss 0.42632369245239343 accuracy 0.8089878167024999\n",
      "----------\n",
      "Epoch 2/10\n",
      "100%|██████████████████████████████████████████████| 3030/3030 [3:49:59<00:00,  4.55s/it, loss=0.46]\n",
      "Train loss 0.44220961745422666 accuracy 0.8018854302040143\n",
      "100%|█████████████████████████████████████████████████| 742/742 [54:47<00:00,  4.43s/it, loss=0.431]\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.39      0.85      0.54      2979\n",
      "           1       0.97      0.81      0.88     20742\n",
      "\n",
      "    accuracy                           0.82     23721\n",
      "   macro avg       0.68      0.83      0.71     23721\n",
      "weighted avg       0.90      0.82      0.84     23721\n",
      "\n",
      "Test loss 0.4147186418869746 accuracy 0.8155221112094768\n",
      "----------\n",
      "Epoch 3/10\n",
      " 39%|████████████████▊                          | 1184/3030 [1:30:07<2:20:31,  4.57s/it, loss=0.522]\n",
      "Training was manually stopped. \n"
     ]
    }
   ],
   "source": [
    "clf.optimizer = AdamW(clf.model.classifier.parameters(), lr=2e-5, correct_bias=False)\n",
    "print(clf.optimizer)\n",
    "clf.train(10, pretrain_test=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
