{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b01b9d5",
   "metadata": {},
   "source": [
    "# Classification experiments with `CountVectorizer` and `TfidfVectorizer` + `LogisticRegression`\n",
    "\n",
    "### Descriprion\n",
    "This notebook was initially created to conduct experiments with logistic regression. Here you will see numerous experiments with different hyperparameters.\n",
    "\n",
    "## Contents:\n",
    "* imports & dataset initialization\n",
    "* Serial classification experiments (before balancing) (6 Experiments)\n",
    "    \\+ Additional experiment (Best result)\n",
    "* Balancing algotithm dev\n",
    "* Serial classification experiments (after balancing) (5 Experiments)\n",
    "* What if binary encoding chosen?\n",
    "\n",
    "**Dataset:** Complete dataset\n",
    "\n",
    "**Dataset shape:** $(90646, 2)$\n",
    "\n",
    "**Reviews preprocessing:** depends on experiment\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d192004",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/pristalovya/Документы/nlp-coursework\n"
     ]
    }
   ],
   "source": [
    "%cd ../.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b7a31b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import DatasetLoader\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import dill\n",
    "import scipy\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from nltk.tokenize import TreebankWordTokenizer, TweetTokenizer, WhitespaceTokenizer\n",
    "import nltk\n",
    "from sklearn.utils import resample\n",
    "import catboost as cb\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "from pymystem3 import Mystem\n",
    "\n",
    "np.set_printoptions(threshold=np.inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7103ba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data.shape=(90646, 2)\n",
      "POSITIVE    69219\n",
      "NEUTRAL     11579\n",
      "NEGATIVE     9848\n",
      "Name: label, dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(55346, 2) (23721, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>54700</th>\n",
       "      <td>фильм не стоить бы выходить за предел великобр...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67873</th>\n",
       "      <td>это один из самый впечатляющий и по-настоящему...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44030</th>\n",
       "      <td>первый часть ' чужой ' в свой время произвести...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21503</th>\n",
       "      <td>история начинающий барабанщик эндрю зародиться...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75163</th>\n",
       "      <td>&lt; b &gt; ну вот мы и дождаться . в прокат выйти н...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6265</th>\n",
       "      <td>весь мы в равный мера свойственно как злорадст...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54886</th>\n",
       "      <td>даже в такой неординарный фильм . да , я увери...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76820</th>\n",
       "      <td>я не быть сильно заинтересованный ' дэдпул ' ,...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>фильм , который неизменно занимать первый мест...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15795</th>\n",
       "      <td>этот фильм я ждать весь сердце , как истинный ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>55346 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review  label\n",
       "54700  фильм не стоить бы выходить за предел великобр...      0\n",
       "67873  это один из самый впечатляющий и по-настоящему...      2\n",
       "44030  первый часть ' чужой ' в свой время произвести...      2\n",
       "21503  история начинающий барабанщик эндрю зародиться...      2\n",
       "75163  < b > ну вот мы и дождаться . в прокат выйти н...      2\n",
       "...                                                  ...    ...\n",
       "6265   весь мы в равный мера свойственно как злорадст...      0\n",
       "54886  даже в такой неординарный фильм . да , я увери...      2\n",
       "76820  я не быть сильно заинтересованный ' дэдпул ' ,...      2\n",
       "860    фильм , который неизменно занимать первый мест...      2\n",
       "15795  этот фильм я ждать весь сердце , как истинный ...      2\n",
       "\n",
       "[55346 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Open dataset\n",
    "data = DatasetLoader.load_reviews_Review_Label_dataset('razdel', 'no')\n",
    "print(f'{data.shape=}')\n",
    "print(data.label.value_counts())\n",
    "\n",
    "# Basic visual\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "ax[0].bar(data.label.value_counts().index, \n",
    "       data.label.value_counts().values, \n",
    "       color = 'moccasin', width = 0.9)\n",
    "ax[0].set_title(\"Category distribution\")\n",
    "ax[0].set_xlabel(\"Review types\")\n",
    "ax[0].set_ylabel(\"Number of reviews\")\n",
    "ax[0].grid(True)\n",
    "\n",
    "ax[1].pie(data.label.value_counts(), labels=data.label.value_counts().index, autopct='%1.1f%%')\n",
    "ax[1].set_title('Distribution of review types')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Basic preprocessing\n",
    "label_encoding = {\n",
    "    'POSITIVE': 2,\n",
    "    'NEUTRAL': 1,\n",
    "    'NEGATIVE': 0\n",
    "}\n",
    "\n",
    "data.label = data.label.apply(lambda label: label_encoding[label])\n",
    "data = data[data.label != 1].reset_index().drop(columns=['index'])\n",
    "train, test = train_test_split(data, test_size=0.3, random_state=42)\n",
    "\n",
    "print(train.shape, test.shape)\n",
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06921b51",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34283249",
   "metadata": {},
   "source": [
    "## Serial classification experiments (before balancing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e55ca9aa",
   "metadata": {},
   "source": [
    "### Experiment 1\n",
    "\n",
    "**Tokenizer:** [`razdel`, `TreebankWordTokenizer`, `rutokenizer`]\n",
    "\n",
    "**Stopwords:** [`nltk`, `spacy`, custom_list]\n",
    "\n",
    "**Model:** `LogisticRegression`\n",
    "\n",
    "**Vectorizer:** `CountVectorizer`, `TfidfVectorizer`\n",
    "\n",
    "**Comments:** Before balancing training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d27a2687",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data was loaded from 'reviews_Review_Label_razdel_nltk.df'\n",
      "_tokenizer='razdel', stopwords=nltk\n",
      "data.shape=(90646, 2)\n",
      "\n",
      "CountVectorizer:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.76      0.78      2979\n",
      "           2       0.97      0.98      0.97     20742\n",
      "\n",
      "    accuracy                           0.95     23721\n",
      "   macro avg       0.89      0.87      0.88     23721\n",
      "weighted avg       0.95      0.95      0.95     23721\n",
      "\n",
      "\n",
      "TfidfVectorizer:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.55      0.69      2979\n",
      "           2       0.94      0.99      0.97     20742\n",
      "\n",
      "    accuracy                           0.94     23721\n",
      "   macro avg       0.93      0.77      0.83     23721\n",
      "weighted avg       0.94      0.94      0.93     23721\n",
      "\n",
      "\n",
      "---------------------------------------------------------------\n",
      "\n",
      "Data was loaded from 'reviews_Review_Label_razdel_spacy.df'\n",
      "_tokenizer='razdel', stopwords=spacy\n",
      "data.shape=(90646, 2)\n",
      "\n",
      "CountVectorizer:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.76      0.78      2979\n",
      "           2       0.97      0.97      0.97     20742\n",
      "\n",
      "    accuracy                           0.95     23721\n",
      "   macro avg       0.88      0.86      0.87     23721\n",
      "weighted avg       0.94      0.95      0.94     23721\n",
      "\n",
      "\n",
      "TfidfVectorizer:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.53      0.67      2979\n",
      "           2       0.94      0.99      0.96     20742\n",
      "\n",
      "    accuracy                           0.93     23721\n",
      "   macro avg       0.92      0.76      0.82     23721\n",
      "weighted avg       0.93      0.93      0.93     23721\n",
      "\n",
      "\n",
      "---------------------------------------------------------------\n",
      "\n",
      "Data was loaded from 'reviews_Review_Label_razdel_third_party_nltk.df'\n",
      "_tokenizer='razdel', stopwords=third_party_nltk\n",
      "data.shape=(90646, 2)\n",
      "\n",
      "CountVectorizer:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.75      0.78      2979\n",
      "           2       0.96      0.98      0.97     20742\n",
      "\n",
      "    accuracy                           0.95     23721\n",
      "   macro avg       0.89      0.86      0.88     23721\n",
      "weighted avg       0.95      0.95      0.95     23721\n",
      "\n",
      "\n",
      "TfidfVectorizer:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.54      0.68      2979\n",
      "           2       0.94      0.99      0.96     20742\n",
      "\n",
      "    accuracy                           0.94     23721\n",
      "   macro avg       0.92      0.77      0.82     23721\n",
      "weighted avg       0.93      0.94      0.93     23721\n",
      "\n",
      "\n",
      "---------------------------------------------------------------\n",
      "\n",
      "Data was loaded from 'reviews_Review_Label_TreebankWordTokenizer_nltk.df'\n",
      "_tokenizer='TreebankWordTokenizer', stopwords=nltk\n",
      "data.shape=(90646, 2)\n",
      "\n",
      "CountVectorizer:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.70      0.75      2979\n",
      "           2       0.96      0.98      0.97     20742\n",
      "\n",
      "    accuracy                           0.94     23721\n",
      "   macro avg       0.88      0.84      0.86     23721\n",
      "weighted avg       0.94      0.94      0.94     23721\n",
      "\n",
      "\n",
      "TfidfVectorizer:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.50      0.64      2979\n",
      "           2       0.93      0.99      0.96     20742\n",
      "\n",
      "    accuracy                           0.93     23721\n",
      "   macro avg       0.91      0.75      0.80     23721\n",
      "weighted avg       0.93      0.93      0.92     23721\n",
      "\n",
      "\n",
      "---------------------------------------------------------------\n",
      "\n",
      "Data was loaded from 'reviews_Review_Label_TreebankWordTokenizer_spacy.df'\n",
      "_tokenizer='TreebankWordTokenizer', stopwords=spacy\n",
      "data.shape=(90646, 2)\n",
      "\n",
      "CountVectorizer:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.69      0.73      2979\n",
      "           2       0.96      0.97      0.96     20742\n",
      "\n",
      "    accuracy                           0.94     23721\n",
      "   macro avg       0.87      0.83      0.85     23721\n",
      "weighted avg       0.93      0.94      0.94     23721\n",
      "\n",
      "\n",
      "TfidfVectorizer:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.46      0.61      2979\n",
      "           2       0.93      0.99      0.96     20742\n",
      "\n",
      "    accuracy                           0.93     23721\n",
      "   macro avg       0.91      0.72      0.78     23721\n",
      "weighted avg       0.92      0.93      0.91     23721\n",
      "\n",
      "\n",
      "---------------------------------------------------------------\n",
      "\n",
      "Data was loaded from 'reviews_Review_Label_TreebankWordTokenizer_third_party_nltk.df'\n",
      "_tokenizer='TreebankWordTokenizer', stopwords=third_party_nltk\n",
      "data.shape=(90646, 2)\n",
      "\n",
      "CountVectorizer:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.70      0.74      2979\n",
      "           2       0.96      0.97      0.97     20742\n",
      "\n",
      "    accuracy                           0.94     23721\n",
      "   macro avg       0.88      0.84      0.86     23721\n",
      "weighted avg       0.94      0.94      0.94     23721\n",
      "\n",
      "\n",
      "TfidfVectorizer:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.48      0.62      2979\n",
      "           2       0.93      0.99      0.96     20742\n",
      "\n",
      "    accuracy                           0.93     23721\n",
      "   macro avg       0.91      0.73      0.79     23721\n",
      "weighted avg       0.93      0.93      0.92     23721\n",
      "\n",
      "\n",
      "---------------------------------------------------------------\n",
      "\n",
      "Data was loaded from 'reviews_Review_Label_rutokenizer_nltk.df'\n",
      "_tokenizer='rutokenizer', stopwords=nltk\n",
      "data.shape=(90646, 2)\n",
      "\n",
      "CountVectorizer:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.75      0.78      2979\n",
      "           2       0.96      0.97      0.97     20742\n",
      "\n",
      "    accuracy                           0.95     23721\n",
      "   macro avg       0.88      0.86      0.87     23721\n",
      "weighted avg       0.94      0.95      0.94     23721\n",
      "\n",
      "\n",
      "TfidfVectorizer:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.55      0.69      2979\n",
      "           2       0.94      0.99      0.97     20742\n",
      "\n",
      "    accuracy                           0.94     23721\n",
      "   macro avg       0.93      0.77      0.83     23721\n",
      "weighted avg       0.94      0.94      0.93     23721\n",
      "\n",
      "\n",
      "---------------------------------------------------------------\n",
      "\n",
      "Data was loaded from 'reviews_Review_Label_rutokenizer_spacy.df'\n",
      "_tokenizer='rutokenizer', stopwords=spacy\n",
      "data.shape=(90646, 2)\n",
      "\n",
      "CountVectorizer:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.73      0.76      2979\n",
      "           2       0.96      0.97      0.97     20742\n",
      "\n",
      "    accuracy                           0.94     23721\n",
      "   macro avg       0.88      0.85      0.86     23721\n",
      "weighted avg       0.94      0.94      0.94     23721\n",
      "\n",
      "\n",
      "TfidfVectorizer:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.52      0.67      2979\n",
      "           2       0.94      0.99      0.96     20742\n",
      "\n",
      "    accuracy                           0.93     23721\n",
      "   macro avg       0.93      0.76      0.81     23721\n",
      "weighted avg       0.93      0.93      0.93     23721\n",
      "\n",
      "\n",
      "---------------------------------------------------------------\n",
      "\n",
      "Data was loaded from 'reviews_Review_Label_rutokenizer_third_party_nltk.df'\n",
      "_tokenizer='rutokenizer', stopwords=third_party_nltk\n",
      "data.shape=(90646, 2)\n",
      "\n",
      "CountVectorizer:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.74      0.78      2979\n",
      "           2       0.96      0.98      0.97     20742\n",
      "\n",
      "    accuracy                           0.95     23721\n",
      "   macro avg       0.89      0.86      0.87     23721\n",
      "weighted avg       0.95      0.95      0.95     23721\n",
      "\n",
      "\n",
      "TfidfVectorizer:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.54      0.67      2979\n",
      "           2       0.94      0.99      0.96     20742\n",
      "\n",
      "    accuracy                           0.93     23721\n",
      "   macro avg       0.92      0.76      0.82     23721\n",
      "weighted avg       0.93      0.93      0.93     23721\n",
      "\n",
      "\n",
      "---------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for _tokenizer in ['razdel', 'TreebankWordTokenizer', 'rutokenizer']:\n",
    "    for i, _stopwords in enumerate(['fictitious', 'stopwords', 'list']):        \n",
    "        i_to_sw_name = {0: 'nltk', 1: 'spacy', 2: 'third_party_nltk'}\n",
    "        \n",
    "        with open(f'reviews_Review_Label_{_tokenizer}_{i_to_sw_name[i]}.df', 'rb') as file:\n",
    "            data = dill.load(file)\n",
    "            print(f\"Data was loaded from '{file.name}'\")\n",
    "        \n",
    "        print(f'{_tokenizer=}, stopwords={i_to_sw_name[i]}')\n",
    "        print(f'{data.shape=}\\n')\n",
    "        \n",
    "        # Basic preprocessing\n",
    "        label_encoding = {\n",
    "            'POSITIVE': 2,\n",
    "            'NEUTRAL': 1,\n",
    "            'NEGATIVE': 0\n",
    "        }\n",
    "\n",
    "        data.label = data.label.apply(lambda label: label_encoding[label])\n",
    "        data = data[data.label != 1].reset_index().drop(columns=['index'])\n",
    "        train, test = train_test_split(data, test_size=0.3, random_state=42)\n",
    "\n",
    "        \n",
    "        print('CountVectorizer:')\n",
    "        cnt_vec = CountVectorizer(tokenizer=WhitespaceTokenizer().tokenize)\n",
    "        X_train = cnt_vec.fit_transform(train.review)\n",
    "        X_test  = cnt_vec.transform(test.review)\n",
    "\n",
    "        clf = LogisticRegression(max_iter=200, n_jobs=-1)\n",
    "        clf.fit(X_train, train.label)\n",
    "        pred = clf.predict(X_test)\n",
    "\n",
    "        print(classification_report(test.label, pred))\n",
    "        \n",
    "        \n",
    "        print('\\nTfidfVectorizer:')\n",
    "        cnt_vec = TfidfVectorizer(tokenizer=WhitespaceTokenizer().tokenize)\n",
    "        X_train = cnt_vec.fit_transform(train.review)\n",
    "        X_test  = cnt_vec.transform(test.review)\n",
    "\n",
    "        clf = LogisticRegression(max_iter=200, n_jobs=-1)\n",
    "        clf.fit(X_train, train.label)\n",
    "        pred = clf.predict(X_test)\n",
    "\n",
    "        print(classification_report(test.label, pred))\n",
    "        \n",
    "        print('\\n---------------------------------------------------------------\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbab2e41",
   "metadata": {},
   "source": [
    "### Experiment 2\n",
    "\n",
    "**Tokenizer:** [`razdel`, `TreebankWordTokenizer`, `rutokenizer`]\n",
    "\n",
    "**Stopwords:** [`nltk`, `spacy`, custom_list]\n",
    "\n",
    "**Model:** `LogisticRegression`\n",
    "\n",
    "**LogReg params**: \n",
    "* **class_weight =** 'balanced'\n",
    "\n",
    "**Vectorizer:** `CountVectorizer`, `TfidfVectorizer`\n",
    "\n",
    "**Comments:** Before balancing training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "deef7944",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data was loaded from 'reviews_Review_Label_razdel_nltk.df'\n",
      "_tokenizer='razdel', stopwords=nltk\n",
      "data.shape=(90646, 2)\n",
      "\n",
      "CountVectorizer:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.83      0.79      2979\n",
      "           2       0.98      0.96      0.97     20742\n",
      "\n",
      "    accuracy                           0.94     23721\n",
      "   macro avg       0.86      0.89      0.88     23721\n",
      "weighted avg       0.95      0.94      0.94     23721\n",
      "\n",
      "\n",
      "TfidfVectorizer:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.90      0.77      2979\n",
      "           2       0.99      0.94      0.96     20742\n",
      "\n",
      "    accuracy                           0.93     23721\n",
      "   macro avg       0.83      0.92      0.86     23721\n",
      "weighted avg       0.95      0.93      0.94     23721\n",
      "\n",
      "\n",
      "---------------------------------------------------------------\n",
      "\n",
      "Data was loaded from 'reviews_Review_Label_razdel_spacy.df'\n",
      "_tokenizer='razdel', stopwords=spacy\n",
      "data.shape=(90646, 2)\n",
      "\n",
      "CountVectorizer:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.83      0.77      2979\n",
      "           2       0.97      0.95      0.96     20742\n",
      "\n",
      "    accuracy                           0.94     23721\n",
      "   macro avg       0.85      0.89      0.87     23721\n",
      "weighted avg       0.94      0.94      0.94     23721\n",
      "\n",
      "\n",
      "TfidfVectorizer:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.90      0.76      2979\n",
      "           2       0.98      0.93      0.96     20742\n",
      "\n",
      "    accuracy                           0.93     23721\n",
      "   macro avg       0.82      0.92      0.86     23721\n",
      "weighted avg       0.94      0.93      0.93     23721\n",
      "\n",
      "\n",
      "---------------------------------------------------------------\n",
      "\n",
      "Data was loaded from 'reviews_Review_Label_razdel_third_party_nltk.df'\n",
      "_tokenizer='razdel', stopwords=third_party_nltk\n",
      "data.shape=(90646, 2)\n",
      "\n",
      "CountVectorizer:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.82      0.77      2979\n",
      "           2       0.97      0.96      0.97     20742\n",
      "\n",
      "    accuracy                           0.94     23721\n",
      "   macro avg       0.86      0.89      0.87     23721\n",
      "weighted avg       0.94      0.94      0.94     23721\n",
      "\n",
      "\n",
      "TfidfVectorizer:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.90      0.77      2979\n",
      "           2       0.98      0.94      0.96     20742\n",
      "\n",
      "    accuracy                           0.93     23721\n",
      "   macro avg       0.83      0.92      0.86     23721\n",
      "weighted avg       0.95      0.93      0.94     23721\n",
      "\n",
      "\n",
      "---------------------------------------------------------------\n",
      "\n",
      "Data was loaded from 'reviews_Review_Label_TreebankWordTokenizer_nltk.df'\n",
      "_tokenizer='TreebankWordTokenizer', stopwords=nltk\n",
      "data.shape=(90646, 2)\n",
      "\n",
      "CountVectorizer:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.76      0.76      2979\n",
      "           2       0.97      0.96      0.96     20742\n",
      "\n",
      "    accuracy                           0.94     23721\n",
      "   macro avg       0.86      0.86      0.86     23721\n",
      "weighted avg       0.94      0.94      0.94     23721\n",
      "\n",
      "\n",
      "TfidfVectorizer:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.87      0.74      2979\n",
      "           2       0.98      0.93      0.95     20742\n",
      "\n",
      "    accuracy                           0.92     23721\n",
      "   macro avg       0.81      0.90      0.85     23721\n",
      "weighted avg       0.94      0.92      0.93     23721\n",
      "\n",
      "\n",
      "---------------------------------------------------------------\n",
      "\n",
      "Data was loaded from 'reviews_Review_Label_TreebankWordTokenizer_spacy.df'\n",
      "_tokenizer='TreebankWordTokenizer', stopwords=spacy\n",
      "data.shape=(90646, 2)\n",
      "\n",
      "CountVectorizer:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.75      0.74      2979\n",
      "           2       0.96      0.96      0.96     20742\n",
      "\n",
      "    accuracy                           0.94     23721\n",
      "   macro avg       0.85      0.86      0.85     23721\n",
      "weighted avg       0.94      0.94      0.94     23721\n",
      "\n",
      "\n",
      "TfidfVectorizer:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.87      0.73      2979\n",
      "           2       0.98      0.93      0.95     20742\n",
      "\n",
      "    accuracy                           0.92     23721\n",
      "   macro avg       0.80      0.90      0.84     23721\n",
      "weighted avg       0.94      0.92      0.92     23721\n",
      "\n",
      "\n",
      "---------------------------------------------------------------\n",
      "\n",
      "Data was loaded from 'reviews_Review_Label_TreebankWordTokenizer_third_party_nltk.df'\n",
      "_tokenizer='TreebankWordTokenizer', stopwords=third_party_nltk\n",
      "data.shape=(90646, 2)\n",
      "\n",
      "CountVectorizer:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.75      0.75      2979\n",
      "           2       0.96      0.96      0.96     20742\n",
      "\n",
      "    accuracy                           0.94     23721\n",
      "   macro avg       0.85      0.86      0.86     23721\n",
      "weighted avg       0.94      0.94      0.94     23721\n",
      "\n",
      "\n",
      "TfidfVectorizer:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.87      0.73      2979\n",
      "           2       0.98      0.93      0.95     20742\n",
      "\n",
      "    accuracy                           0.92     23721\n",
      "   macro avg       0.81      0.90      0.84     23721\n",
      "weighted avg       0.94      0.92      0.93     23721\n",
      "\n",
      "\n",
      "---------------------------------------------------------------\n",
      "\n",
      "Data was loaded from 'reviews_Review_Label_rutokenizer_nltk.df'\n",
      "_tokenizer='rutokenizer', stopwords=nltk\n",
      "data.shape=(90646, 2)\n",
      "\n",
      "CountVectorizer:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.82      0.78      2979\n",
      "           2       0.97      0.96      0.97     20742\n",
      "\n",
      "    accuracy                           0.94     23721\n",
      "   macro avg       0.86      0.89      0.87     23721\n",
      "weighted avg       0.95      0.94      0.94     23721\n",
      "\n",
      "\n",
      "TfidfVectorizer:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.90      0.76      2979\n",
      "           2       0.99      0.93      0.96     20742\n",
      "\n",
      "    accuracy                           0.93     23721\n",
      "   macro avg       0.82      0.92      0.86     23721\n",
      "weighted avg       0.94      0.93      0.93     23721\n",
      "\n",
      "\n",
      "---------------------------------------------------------------\n",
      "\n",
      "Data was loaded from 'reviews_Review_Label_rutokenizer_spacy.df'\n",
      "_tokenizer='rutokenizer', stopwords=spacy\n",
      "data.shape=(90646, 2)\n",
      "\n",
      "CountVectorizer:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.82      0.76      2979\n",
      "           2       0.97      0.95      0.96     20742\n",
      "\n",
      "    accuracy                           0.94     23721\n",
      "   macro avg       0.84      0.89      0.86     23721\n",
      "weighted avg       0.94      0.94      0.94     23721\n",
      "\n",
      "\n",
      "TfidfVectorizer:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.89      0.75      2979\n",
      "           2       0.98      0.93      0.96     20742\n",
      "\n",
      "    accuracy                           0.93     23721\n",
      "   macro avg       0.82      0.91      0.86     23721\n",
      "weighted avg       0.94      0.93      0.93     23721\n",
      "\n",
      "\n",
      "---------------------------------------------------------------\n",
      "\n",
      "Data was loaded from 'reviews_Review_Label_rutokenizer_third_party_nltk.df'\n",
      "_tokenizer='rutokenizer', stopwords=third_party_nltk\n",
      "data.shape=(90646, 2)\n",
      "\n",
      "CountVectorizer:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.81      0.77      2979\n",
      "           2       0.97      0.96      0.97     20742\n",
      "\n",
      "    accuracy                           0.94     23721\n",
      "   macro avg       0.86      0.88      0.87     23721\n",
      "weighted avg       0.94      0.94      0.94     23721\n",
      "\n",
      "\n",
      "TfidfVectorizer:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.90      0.77      2979\n",
      "           2       0.98      0.94      0.96     20742\n",
      "\n",
      "    accuracy                           0.93     23721\n",
      "   macro avg       0.83      0.92      0.86     23721\n",
      "weighted avg       0.94      0.93      0.94     23721\n",
      "\n",
      "\n",
      "---------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for _tokenizer in ['razdel', 'TreebankWordTokenizer', 'rutokenizer']:\n",
    "    for i, _stopwords in enumerate(['fictitious', 'stopwords', 'list']):        \n",
    "        i_to_sw_name = {0: 'nltk', 1: 'spacy', 2: 'third_party_nltk'}\n",
    "        \n",
    "        with open(f'reviews_Review_Label_{_tokenizer}_{i_to_sw_name[i]}.df', 'rb') as file:\n",
    "            data = dill.load(file)\n",
    "            print(f\"Data was loaded from '{file.name}'\")\n",
    "        \n",
    "        print(f'{_tokenizer=}, stopwords={i_to_sw_name[i]}')\n",
    "        print(f'{data.shape=}\\n')\n",
    "        \n",
    "        \n",
    "        # Basic preprocessing\n",
    "        label_encoding = {\n",
    "            'POSITIVE': 2,\n",
    "            'NEUTRAL': 1,\n",
    "            'NEGATIVE': 0\n",
    "        }\n",
    "\n",
    "        data.label = data.label.apply(lambda label: label_encoding[label])\n",
    "        data = data[data.label != 1].reset_index().drop(columns=['index'])\n",
    "        train, test = train_test_split(data, test_size=0.3, random_state=42)\n",
    "        \n",
    "        \n",
    "        print('CountVectorizer:')\n",
    "        cnt_vec = CountVectorizer(tokenizer=WhitespaceTokenizer().tokenize)\n",
    "        X_train = cnt_vec.fit_transform(train.review)\n",
    "        X_test  = cnt_vec.transform(test.review)\n",
    "\n",
    "        clf = LogisticRegression(max_iter=200, n_jobs=-1, class_weight='balanced')\n",
    "        clf.fit(X_train, train.label)\n",
    "        pred = clf.predict(X_test)\n",
    "\n",
    "        print(classification_report(test.label, pred))\n",
    "        \n",
    "        \n",
    "        print('\\nTfidfVectorizer:')\n",
    "        cnt_vec = TfidfVectorizer(tokenizer=WhitespaceTokenizer().tokenize)\n",
    "        X_train = cnt_vec.fit_transform(train.review)\n",
    "        X_test  = cnt_vec.transform(test.review)\n",
    "\n",
    "        clf = LogisticRegression(max_iter=200, n_jobs=-1, class_weight='balanced')\n",
    "        clf.fit(X_train, train.label)\n",
    "        pred = clf.predict(X_test)\n",
    "\n",
    "        print(classification_report(test.label, pred))\n",
    "        \n",
    "        print('\\n---------------------------------------------------------------\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a3fe42",
   "metadata": {},
   "source": [
    "### Additional Experiment (BEST RESULT)\n",
    "\n",
    "**Tokenizer:** [`razdel`]\n",
    "\n",
    "**Stopwords:** [`[]`]\n",
    "\n",
    "**Model:** `LogisticRegression`\n",
    "\n",
    "**Vectorizer:** `CountVectorizer`\n",
    "* **ngram_range =** $(1, 3)$\n",
    "\n",
    "**LogReg params**: \n",
    "* **class_weight =** 'balanced'\n",
    "\n",
    "**Comments:** Before balancing training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "363c3c57",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data.shape=(90646, 2)\n",
      "\n",
      "CountVectorizing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pristalovya/Inter/linux_packages/anaconda3/envs/nlp/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(55346, 15287875)\n",
      "Training logreg...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pristalovya/Inter/linux_packages/anaconda3/envs/nlp/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.85      0.86      2979\n",
      "           2       0.98      0.98      0.98     20742\n",
      "\n",
      "    accuracy                           0.97     23721\n",
      "   macro avg       0.93      0.92      0.92     23721\n",
      "weighted avg       0.97      0.97      0.97     23721\n",
      "\n",
      "\n",
      "---------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = DatasetLoader.load_reviews_Review_Label_dataset('razdel', 'no')\n",
    "\n",
    "print(f'{data.shape=}\\n')\n",
    "\n",
    "# Basic preprocessing\n",
    "label_encoding = {\n",
    "    'POSITIVE': 2,\n",
    "    'NEUTRAL': 1,\n",
    "    'NEGATIVE': 0\n",
    "}\n",
    "\n",
    "data.label = data.label.apply(lambda label: label_encoding[label])\n",
    "data = data[data.label != 1].reset_index().drop(columns=['index'])\n",
    "train, test = train_test_split(data, test_size=0.3, random_state=42)\n",
    "\n",
    "\n",
    "print('CountVectorizing...')\n",
    "cnt_vec = CountVectorizer(tokenizer=WhitespaceTokenizer().tokenize, ngram_range=(1, 3))\n",
    "X_train = cnt_vec.fit_transform(train.review)\n",
    "X_test  = cnt_vec.transform(test.review)\n",
    "print(X_train.shape)\n",
    "\n",
    "from joblib import parallel_backend\n",
    "\n",
    "with parallel_backend('threading', n_jobs=50):\n",
    "    print('Training logreg...')\n",
    "    clf = LogisticRegression(max_iter=500, n_jobs=50, class_weight='balanced')\n",
    "    clf.fit(X_train, train.label)\n",
    "    pred = clf.predict(X_test)\n",
    "\n",
    "print(classification_report(test.label, pred))\n",
    "\n",
    "print('\\n---------------------------------------------------------------\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "26ddd628",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('models/logreg_086_ngrams_1_3_preprocessed.model', 'wb') as f:\n",
    "    dill.dump(clf, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a62d94e2",
   "metadata": {},
   "source": [
    "### Experiment 3\n",
    "\n",
    "**Tokenizer:** [`razdel`, `TreebankWordTokenizer`, `rutokenizer`]\n",
    "\n",
    "**Stopwords:** [`nltk`, `spacy`, custom_list]\n",
    "\n",
    "**Model:** `LogisticRegression`\n",
    "\n",
    "**LogReg params**: \n",
    "* **class_weight =** 'balanced'\n",
    "\n",
    "**Vectorizer:** `CountVectorizer`, `TfidfVectorizer`\n",
    "\n",
    "**Vectorizer params**: \n",
    "* **max_df =** $0.6$\n",
    "* **max_features =** $10000$\n",
    "\n",
    "**Comments:** Before balancing training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e337a881",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data was loaded from 'reviews_Review_Label_razdel_nltk.df'\n",
      "_tokenizer='razdel', stopwords=nltk\n",
      "data.shape=(90646, 2)\n",
      "\n",
      "CountVectorizer:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.81      0.76      2979\n",
      "           2       0.97      0.96      0.96     20742\n",
      "\n",
      "    accuracy                           0.94     23721\n",
      "   macro avg       0.85      0.88      0.86     23721\n",
      "weighted avg       0.94      0.94      0.94     23721\n",
      "\n",
      "\n",
      "TfidfVectorizer:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.90      0.76      2979\n",
      "           2       0.98      0.94      0.96     20742\n",
      "\n",
      "    accuracy                           0.93     23721\n",
      "   macro avg       0.83      0.92      0.86     23721\n",
      "weighted avg       0.94      0.93      0.93     23721\n",
      "\n",
      "\n",
      "---------------------------------------------------------------\n",
      "\n",
      "Data was loaded from 'reviews_Review_Label_razdel_spacy.df'\n",
      "_tokenizer='razdel', stopwords=spacy\n",
      "data.shape=(90646, 2)\n",
      "\n",
      "CountVectorizer:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.79      0.75      2979\n",
      "           2       0.97      0.95      0.96     20742\n",
      "\n",
      "    accuracy                           0.93     23721\n",
      "   macro avg       0.84      0.87      0.85     23721\n",
      "weighted avg       0.94      0.93      0.93     23721\n",
      "\n",
      "\n",
      "TfidfVectorizer:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.89      0.75      2979\n",
      "           2       0.98      0.93      0.96     20742\n",
      "\n",
      "    accuracy                           0.93     23721\n",
      "   macro avg       0.82      0.91      0.85     23721\n",
      "weighted avg       0.94      0.93      0.93     23721\n",
      "\n",
      "\n",
      "---------------------------------------------------------------\n",
      "\n",
      "Data was loaded from 'reviews_Review_Label_razdel_third_party_nltk.df'\n",
      "_tokenizer='razdel', stopwords=third_party_nltk\n",
      "data.shape=(90646, 2)\n",
      "\n",
      "CountVectorizer:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.79      0.75      2979\n",
      "           2       0.97      0.96      0.96     20742\n",
      "\n",
      "    accuracy                           0.93     23721\n",
      "   macro avg       0.84      0.87      0.86     23721\n",
      "weighted avg       0.94      0.93      0.94     23721\n",
      "\n",
      "\n",
      "TfidfVectorizer:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.89      0.76      2979\n",
      "           2       0.98      0.93      0.96     20742\n",
      "\n",
      "    accuracy                           0.93     23721\n",
      "   macro avg       0.82      0.91      0.86     23721\n",
      "weighted avg       0.94      0.93      0.93     23721\n",
      "\n",
      "\n",
      "---------------------------------------------------------------\n",
      "\n",
      "Data was loaded from 'reviews_Review_Label_TreebankWordTokenizer_nltk.df'\n",
      "_tokenizer='TreebankWordTokenizer', stopwords=nltk\n",
      "data.shape=(90646, 2)\n",
      "\n",
      "CountVectorizer:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.75      0.70      2979\n",
      "           2       0.96      0.94      0.95     20742\n",
      "\n",
      "    accuracy                           0.92     23721\n",
      "   macro avg       0.81      0.85      0.83     23721\n",
      "weighted avg       0.93      0.92      0.92     23721\n",
      "\n",
      "\n",
      "TfidfVectorizer:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.88      0.73      2979\n",
      "           2       0.98      0.92      0.95     20742\n",
      "\n",
      "    accuracy                           0.92     23721\n",
      "   macro avg       0.80      0.90      0.84     23721\n",
      "weighted avg       0.94      0.92      0.92     23721\n",
      "\n",
      "\n",
      "---------------------------------------------------------------\n",
      "\n",
      "Data was loaded from 'reviews_Review_Label_TreebankWordTokenizer_spacy.df'\n",
      "_tokenizer='TreebankWordTokenizer', stopwords=spacy\n",
      "data.shape=(90646, 2)\n",
      "\n",
      "CountVectorizer:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.75      0.69      2979\n",
      "           2       0.96      0.94      0.95     20742\n",
      "\n",
      "    accuracy                           0.92     23721\n",
      "   macro avg       0.80      0.84      0.82     23721\n",
      "weighted avg       0.92      0.92      0.92     23721\n",
      "\n",
      "\n",
      "TfidfVectorizer:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.87      0.71      2979\n",
      "           2       0.98      0.92      0.95     20742\n",
      "\n",
      "    accuracy                           0.91     23721\n",
      "   macro avg       0.79      0.89      0.83     23721\n",
      "weighted avg       0.93      0.91      0.92     23721\n",
      "\n",
      "\n",
      "---------------------------------------------------------------\n",
      "\n",
      "Data was loaded from 'reviews_Review_Label_TreebankWordTokenizer_third_party_nltk.df'\n",
      "_tokenizer='TreebankWordTokenizer', stopwords=third_party_nltk\n",
      "data.shape=(90646, 2)\n",
      "\n",
      "CountVectorizer:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.75      0.70      2979\n",
      "           2       0.96      0.94      0.95     20742\n",
      "\n",
      "    accuracy                           0.92     23721\n",
      "   macro avg       0.81      0.85      0.83     23721\n",
      "weighted avg       0.92      0.92      0.92     23721\n",
      "\n",
      "\n",
      "TfidfVectorizer:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.88      0.72      2979\n",
      "           2       0.98      0.92      0.95     20742\n",
      "\n",
      "    accuracy                           0.92     23721\n",
      "   macro avg       0.80      0.90      0.84     23721\n",
      "weighted avg       0.94      0.92      0.92     23721\n",
      "\n",
      "\n",
      "---------------------------------------------------------------\n",
      "\n",
      "Data was loaded from 'reviews_Review_Label_rutokenizer_nltk.df'\n",
      "_tokenizer='rutokenizer', stopwords=nltk\n",
      "data.shape=(90646, 2)\n",
      "\n",
      "CountVectorizer:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.79      0.75      2979\n",
      "           2       0.97      0.95      0.96     20742\n",
      "\n",
      "    accuracy                           0.93     23721\n",
      "   macro avg       0.84      0.87      0.85     23721\n",
      "weighted avg       0.94      0.93      0.93     23721\n",
      "\n",
      "\n",
      "TfidfVectorizer:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.90      0.76      2979\n",
      "           2       0.98      0.93      0.96     20742\n",
      "\n",
      "    accuracy                           0.93     23721\n",
      "   macro avg       0.82      0.92      0.86     23721\n",
      "weighted avg       0.94      0.93      0.93     23721\n",
      "\n",
      "\n",
      "---------------------------------------------------------------\n",
      "\n",
      "Data was loaded from 'reviews_Review_Label_rutokenizer_spacy.df'\n",
      "_tokenizer='rutokenizer', stopwords=spacy\n",
      "data.shape=(90646, 2)\n",
      "\n",
      "CountVectorizer:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.78      0.74      2979\n",
      "           2       0.97      0.95      0.96     20742\n",
      "\n",
      "    accuracy                           0.93     23721\n",
      "   macro avg       0.83      0.87      0.85     23721\n",
      "weighted avg       0.93      0.93      0.93     23721\n",
      "\n",
      "\n",
      "TfidfVectorizer:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.89      0.75      2979\n",
      "           2       0.98      0.93      0.96     20742\n",
      "\n",
      "    accuracy                           0.92     23721\n",
      "   macro avg       0.81      0.91      0.85     23721\n",
      "weighted avg       0.94      0.92      0.93     23721\n",
      "\n",
      "\n",
      "---------------------------------------------------------------\n",
      "\n",
      "Data was loaded from 'reviews_Review_Label_rutokenizer_third_party_nltk.df'\n",
      "_tokenizer='rutokenizer', stopwords=third_party_nltk\n",
      "data.shape=(90646, 2)\n",
      "\n",
      "CountVectorizer:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.78      0.74      2979\n",
      "           2       0.97      0.95      0.96     20742\n",
      "\n",
      "    accuracy                           0.93     23721\n",
      "   macro avg       0.83      0.87      0.85     23721\n",
      "weighted avg       0.93      0.93      0.93     23721\n",
      "\n",
      "\n",
      "TfidfVectorizer:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.89      0.76      2979\n",
      "           2       0.98      0.93      0.96     20742\n",
      "\n",
      "    accuracy                           0.93     23721\n",
      "   macro avg       0.82      0.91      0.86     23721\n",
      "weighted avg       0.94      0.93      0.93     23721\n",
      "\n",
      "\n",
      "---------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for _tokenizer in ['razdel', 'TreebankWordTokenizer', 'rutokenizer']:\n",
    "    for i, _stopwords in enumerate(['fictitious', 'stopwords', 'list']):        \n",
    "        i_to_sw_name = {0: 'nltk', 1: 'spacy', 2: 'third_party_nltk'}\n",
    "        \n",
    "        with open(f'reviews_Review_Label_{_tokenizer}_{i_to_sw_name[i]}.df', 'rb') as file:\n",
    "            data = dill.load(file)\n",
    "            print(f\"Data was loaded from '{file.name}'\")\n",
    "        \n",
    "        print(f'{_tokenizer=}, stopwords={i_to_sw_name[i]}')\n",
    "        print(f'{data.shape=}\\n')\n",
    "        \n",
    "        \n",
    "        # Basic preprocessing\n",
    "        label_encoding = {\n",
    "            'POSITIVE': 2,\n",
    "            'NEUTRAL': 1,\n",
    "            'NEGATIVE': 0\n",
    "        }\n",
    "\n",
    "        data.label = data.label.apply(lambda label: label_encoding[label])\n",
    "        data = data[data.label != 1].reset_index().drop(columns=['index'])\n",
    "        train, test = train_test_split(data, test_size=0.3, random_state=42)\n",
    "        \n",
    "        \n",
    "        print('CountVectorizer:')\n",
    "        cnt_vec = CountVectorizer(tokenizer=WhitespaceTokenizer().tokenize, max_df=0.6, max_features=10000)\n",
    "        X_train = cnt_vec.fit_transform(train.review)\n",
    "        X_test  = cnt_vec.transform(test.review)\n",
    "\n",
    "        clf = LogisticRegression(max_iter=200, n_jobs=-1, class_weight='balanced')\n",
    "        clf.fit(X_train, train.label)\n",
    "        pred = clf.predict(X_test)\n",
    "\n",
    "        print(classification_report(test.label, pred))\n",
    "        \n",
    "        \n",
    "        print('\\nTfidfVectorizer:')\n",
    "        cnt_vec = TfidfVectorizer(tokenizer=WhitespaceTokenizer().tokenize, max_df=0.6, max_features=10000)\n",
    "        X_train = cnt_vec.fit_transform(train.review)\n",
    "        X_test  = cnt_vec.transform(test.review)\n",
    "\n",
    "        clf = LogisticRegression(max_iter=200, n_jobs=-1, class_weight='balanced')\n",
    "        clf.fit(X_train, train.label)\n",
    "        pred = clf.predict(X_test)\n",
    "\n",
    "        print(classification_report(test.label, pred))\n",
    "        \n",
    "        print('\\n---------------------------------------------------------------\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "590a9284",
   "metadata": {},
   "source": [
    "### Experiment 4\n",
    "\n",
    "**Tokenizer:** [`razdel`, `TreebankWordTokenizer`, `rutokenizer`]\n",
    "\n",
    "**Stopwords:** [`nltk`, `spacy`, custom_list]\n",
    "\n",
    "**Model:** `LogisticRegression`\n",
    "\n",
    "**LogReg params**: \n",
    "* **class_weight =** 'balanced'\n",
    "* **solver =** 'saga'\n",
    "\n",
    "**Vectorizer:** `CountVectorizer`, `TfidfVectorizer`\n",
    "\n",
    "**Comments:** Before balancing training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5abbc313",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data was loaded from 'reviews_Review_Label_razdel_nltk.df'\n",
      "_tokenizer='razdel', stopwords=nltk\n",
      "data.shape=(90646, 2)\n",
      "\n",
      "CountVectorizer:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.88      0.79      2979\n",
      "           2       0.98      0.95      0.97     20742\n",
      "\n",
      "    accuracy                           0.94     23721\n",
      "   macro avg       0.85      0.92      0.88     23721\n",
      "weighted avg       0.95      0.94      0.94     23721\n",
      "\n",
      "\n",
      "TfidfVectorizer:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.90      0.77      2979\n",
      "           2       0.99      0.94      0.96     20742\n",
      "\n",
      "    accuracy                           0.93     23721\n",
      "   macro avg       0.83      0.92      0.86     23721\n",
      "weighted avg       0.95      0.93      0.94     23721\n",
      "\n",
      "\n",
      "---------------------------------------------------------------\n",
      "\n",
      "Data was loaded from 'reviews_Review_Label_razdel_spacy.df'\n",
      "_tokenizer='razdel', stopwords=spacy\n",
      "data.shape=(90646, 2)\n",
      "\n",
      "CountVectorizer:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.87      0.78      2979\n",
      "           2       0.98      0.95      0.96     20742\n",
      "\n",
      "    accuracy                           0.94     23721\n",
      "   macro avg       0.84      0.91      0.87     23721\n",
      "weighted avg       0.95      0.94      0.94     23721\n",
      "\n",
      "\n",
      "TfidfVectorizer:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.90      0.76      2979\n",
      "           2       0.98      0.93      0.96     20742\n",
      "\n",
      "    accuracy                           0.93     23721\n",
      "   macro avg       0.82      0.92      0.86     23721\n",
      "weighted avg       0.94      0.93      0.93     23721\n",
      "\n",
      "\n",
      "---------------------------------------------------------------\n",
      "\n",
      "Data was loaded from 'reviews_Review_Label_razdel_third_party_nltk.df'\n",
      "_tokenizer='razdel', stopwords=third_party_nltk\n",
      "data.shape=(90646, 2)\n",
      "\n",
      "CountVectorizer:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.88      0.78      2979\n",
      "           2       0.98      0.95      0.96     20742\n",
      "\n",
      "    accuracy                           0.94     23721\n",
      "   macro avg       0.84      0.91      0.87     23721\n",
      "weighted avg       0.95      0.94      0.94     23721\n",
      "\n",
      "\n",
      "TfidfVectorizer:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.90      0.77      2979\n",
      "           2       0.98      0.94      0.96     20742\n",
      "\n",
      "    accuracy                           0.93     23721\n",
      "   macro avg       0.83      0.92      0.86     23721\n",
      "weighted avg       0.95      0.93      0.94     23721\n",
      "\n",
      "\n",
      "---------------------------------------------------------------\n",
      "\n",
      "Data was loaded from 'reviews_Review_Label_TreebankWordTokenizer_nltk.df'\n",
      "_tokenizer='TreebankWordTokenizer', stopwords=nltk\n",
      "data.shape=(90646, 2)\n",
      "\n",
      "CountVectorizer:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.81      0.76      2979\n",
      "           2       0.97      0.95      0.96     20742\n",
      "\n",
      "    accuracy                           0.94     23721\n",
      "   macro avg       0.84      0.88      0.86     23721\n",
      "weighted avg       0.94      0.94      0.94     23721\n",
      "\n",
      "\n",
      "TfidfVectorizer:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.87      0.74      2979\n",
      "           2       0.98      0.93      0.95     20742\n",
      "\n",
      "    accuracy                           0.92     23721\n",
      "   macro avg       0.81      0.90      0.85     23721\n",
      "weighted avg       0.94      0.92      0.93     23721\n",
      "\n",
      "\n",
      "---------------------------------------------------------------\n",
      "\n",
      "Data was loaded from 'reviews_Review_Label_TreebankWordTokenizer_spacy.df'\n",
      "_tokenizer='TreebankWordTokenizer', stopwords=spacy\n",
      "data.shape=(90646, 2)\n",
      "\n",
      "CountVectorizer:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.80      0.75      2979\n",
      "           2       0.97      0.95      0.96     20742\n",
      "\n",
      "    accuracy                           0.93     23721\n",
      "   macro avg       0.84      0.88      0.86     23721\n",
      "weighted avg       0.94      0.93      0.94     23721\n",
      "\n",
      "\n",
      "TfidfVectorizer:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.87      0.73      2979\n",
      "           2       0.98      0.93      0.95     20742\n",
      "\n",
      "    accuracy                           0.92     23721\n",
      "   macro avg       0.80      0.90      0.84     23721\n",
      "weighted avg       0.94      0.92      0.92     23721\n",
      "\n",
      "\n",
      "---------------------------------------------------------------\n",
      "\n",
      "Data was loaded from 'reviews_Review_Label_TreebankWordTokenizer_third_party_nltk.df'\n",
      "_tokenizer='TreebankWordTokenizer', stopwords=third_party_nltk\n",
      "data.shape=(90646, 2)\n",
      "\n",
      "CountVectorizer:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.80      0.75      2979\n",
      "           2       0.97      0.95      0.96     20742\n",
      "\n",
      "    accuracy                           0.93     23721\n",
      "   macro avg       0.84      0.88      0.86     23721\n",
      "weighted avg       0.94      0.93      0.93     23721\n",
      "\n",
      "\n",
      "TfidfVectorizer:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.87      0.73      2979\n",
      "           2       0.98      0.93      0.95     20742\n",
      "\n",
      "    accuracy                           0.92     23721\n",
      "   macro avg       0.81      0.90      0.84     23721\n",
      "weighted avg       0.94      0.92      0.93     23721\n",
      "\n",
      "\n",
      "---------------------------------------------------------------\n",
      "\n",
      "Data was loaded from 'reviews_Review_Label_rutokenizer_nltk.df'\n",
      "_tokenizer='rutokenizer', stopwords=nltk\n",
      "data.shape=(90646, 2)\n",
      "\n",
      "CountVectorizer:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.86      0.79      2979\n",
      "           2       0.98      0.95      0.97     20742\n",
      "\n",
      "    accuracy                           0.94     23721\n",
      "   macro avg       0.85      0.91      0.88     23721\n",
      "weighted avg       0.95      0.94      0.94     23721\n",
      "\n",
      "\n",
      "TfidfVectorizer:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.90      0.76      2979\n",
      "           2       0.99      0.93      0.96     20742\n",
      "\n",
      "    accuracy                           0.93     23721\n",
      "   macro avg       0.82      0.92      0.86     23721\n",
      "weighted avg       0.94      0.93      0.93     23721\n",
      "\n",
      "\n",
      "---------------------------------------------------------------\n",
      "\n",
      "Data was loaded from 'reviews_Review_Label_rutokenizer_spacy.df'\n",
      "_tokenizer='rutokenizer', stopwords=spacy\n",
      "data.shape=(90646, 2)\n",
      "\n",
      "CountVectorizer:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.85      0.78      2979\n",
      "           2       0.98      0.95      0.96     20742\n",
      "\n",
      "    accuracy                           0.94     23721\n",
      "   macro avg       0.85      0.90      0.87     23721\n",
      "weighted avg       0.94      0.94      0.94     23721\n",
      "\n",
      "\n",
      "TfidfVectorizer:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.89      0.75      2979\n",
      "           2       0.98      0.93      0.96     20742\n",
      "\n",
      "    accuracy                           0.93     23721\n",
      "   macro avg       0.82      0.91      0.86     23721\n",
      "weighted avg       0.94      0.93      0.93     23721\n",
      "\n",
      "\n",
      "---------------------------------------------------------------\n",
      "\n",
      "Data was loaded from 'reviews_Review_Label_rutokenizer_third_party_nltk.df'\n",
      "_tokenizer='rutokenizer', stopwords=third_party_nltk\n",
      "data.shape=(90646, 2)\n",
      "\n",
      "CountVectorizer:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.85      0.78      2979\n",
      "           2       0.98      0.95      0.97     20742\n",
      "\n",
      "    accuracy                           0.94     23721\n",
      "   macro avg       0.85      0.90      0.87     23721\n",
      "weighted avg       0.95      0.94      0.94     23721\n",
      "\n",
      "\n",
      "TfidfVectorizer:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.90      0.77      2979\n",
      "           2       0.98      0.94      0.96     20742\n",
      "\n",
      "    accuracy                           0.93     23721\n",
      "   macro avg       0.83      0.92      0.86     23721\n",
      "weighted avg       0.94      0.93      0.94     23721\n",
      "\n",
      "\n",
      "---------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for _tokenizer in ['razdel', 'TreebankWordTokenizer', 'rutokenizer']:\n",
    "    for i, _stopwords in enumerate(['fictitious', 'stopwords', 'list']):        \n",
    "        i_to_sw_name = {0: 'nltk', 1: 'spacy', 2: 'third_party_nltk'}\n",
    "        \n",
    "        with open(f'reviews_Review_Label_{_tokenizer}_{i_to_sw_name[i]}.df', 'rb') as file:\n",
    "            data = dill.load(file)\n",
    "            print(f\"Data was loaded from '{file.name}'\")\n",
    "        \n",
    "        print(f'{_tokenizer=}, stopwords={i_to_sw_name[i]}')\n",
    "        print(f'{data.shape=}\\n')\n",
    "        \n",
    "        \n",
    "        # Basic preprocessing\n",
    "        label_encoding = {\n",
    "            'POSITIVE': 2,\n",
    "            'NEUTRAL': 1,\n",
    "            'NEGATIVE': 0\n",
    "        }\n",
    "\n",
    "        data.label = data.label.apply(lambda label: label_encoding[label])\n",
    "        data = data[data.label != 1].reset_index().drop(columns=['index'])\n",
    "        train, test = train_test_split(data, test_size=0.3, random_state=42)\n",
    "        \n",
    "        \n",
    "        print('CountVectorizer:')\n",
    "        cnt_vec = CountVectorizer(tokenizer=WhitespaceTokenizer().tokenize)\n",
    "        X_train = cnt_vec.fit_transform(train.review)\n",
    "        X_test  = cnt_vec.transform(test.review)\n",
    "\n",
    "        clf = LogisticRegression(max_iter=3000, n_jobs=-1, class_weight='balanced', solver='saga')\n",
    "        clf.fit(X_train, train.label)\n",
    "        pred = clf.predict(X_test)\n",
    "\n",
    "        print(classification_report(test.label, pred))\n",
    "        \n",
    "        \n",
    "        print('\\nTfidfVectorizer:')\n",
    "        cnt_vec = TfidfVectorizer(tokenizer=WhitespaceTokenizer().tokenize)\n",
    "        X_train = cnt_vec.fit_transform(train.review)\n",
    "        X_test  = cnt_vec.transform(test.review)\n",
    "\n",
    "        clf = LogisticRegression(max_iter=200, n_jobs=-1, class_weight='balanced', solver='saga')\n",
    "        clf.fit(X_train, train.label)\n",
    "        pred = clf.predict(X_test)\n",
    "\n",
    "        print(classification_report(test.label, pred))\n",
    "        \n",
    "        print('\\n---------------------------------------------------------------\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1310157",
   "metadata": {},
   "source": [
    "### Experiment 5\n",
    "\n",
    "**Tokenizer:** [`razdel`, `TreebankWordTokenizer`, `rutokenizer`]\n",
    "\n",
    "**Stopwords:** [`nltk`, `spacy`, custom_list]\n",
    "\n",
    "**Model:** `LogisticRegression`\n",
    "\n",
    "**LogReg params**: \n",
    "* **solver =** 'liblinear'\n",
    "\n",
    "**Vectorizer:** `CountVectorizer`, `TfidfVectorizer`\n",
    "\n",
    "**Comments:** Before balancing training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c0ddfd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data was loaded from 'reviews_Review_Label_razdel_nltk.df'\n",
      "_tokenizer='razdel', stopwords=nltk\n",
      "data.shape=(90646, 2)\n",
      "\n",
      "CountVectorizer:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1523: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.75      0.78      2979\n",
      "           2       0.96      0.97      0.97     20742\n",
      "\n",
      "    accuracy                           0.95     23721\n",
      "   macro avg       0.89      0.86      0.87     23721\n",
      "weighted avg       0.94      0.95      0.95     23721\n",
      "\n",
      "\n",
      "TfidfVectorizer:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1523: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.55      0.69      2979\n",
      "           2       0.94      0.99      0.96     20742\n",
      "\n",
      "    accuracy                           0.94     23721\n",
      "   macro avg       0.92      0.77      0.83     23721\n",
      "weighted avg       0.94      0.94      0.93     23721\n",
      "\n",
      "\n",
      "---------------------------------------------------------------\n",
      "\n",
      "Data was loaded from 'reviews_Review_Label_razdel_spacy.df'\n",
      "_tokenizer='razdel', stopwords=spacy\n",
      "data.shape=(90646, 2)\n",
      "\n",
      "CountVectorizer:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1523: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.74      0.77      2979\n",
      "           2       0.96      0.97      0.97     20742\n",
      "\n",
      "    accuracy                           0.94     23721\n",
      "   macro avg       0.88      0.86      0.87     23721\n",
      "weighted avg       0.94      0.94      0.94     23721\n",
      "\n",
      "\n",
      "TfidfVectorizer:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1523: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.53      0.67      2979\n",
      "           2       0.94      0.99      0.96     20742\n",
      "\n",
      "    accuracy                           0.93     23721\n",
      "   macro avg       0.92      0.76      0.82     23721\n",
      "weighted avg       0.93      0.93      0.93     23721\n",
      "\n",
      "\n",
      "---------------------------------------------------------------\n",
      "\n",
      "Data was loaded from 'reviews_Review_Label_razdel_third_party_nltk.df'\n",
      "_tokenizer='razdel', stopwords=third_party_nltk\n",
      "data.shape=(90646, 2)\n",
      "\n",
      "CountVectorizer:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1523: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.75      0.78      2979\n",
      "           2       0.96      0.97      0.97     20742\n",
      "\n",
      "    accuracy                           0.95     23721\n",
      "   macro avg       0.89      0.86      0.87     23721\n",
      "weighted avg       0.94      0.95      0.95     23721\n",
      "\n",
      "\n",
      "TfidfVectorizer:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1523: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.54      0.68      2979\n",
      "           2       0.94      0.99      0.96     20742\n",
      "\n",
      "    accuracy                           0.94     23721\n",
      "   macro avg       0.92      0.77      0.82     23721\n",
      "weighted avg       0.93      0.94      0.93     23721\n",
      "\n",
      "\n",
      "---------------------------------------------------------------\n",
      "\n",
      "Data was loaded from 'reviews_Review_Label_TreebankWordTokenizer_nltk.df'\n",
      "_tokenizer='TreebankWordTokenizer', stopwords=nltk\n",
      "data.shape=(90646, 2)\n",
      "\n",
      "CountVectorizer:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1523: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.70      0.75      2979\n",
      "           2       0.96      0.98      0.97     20742\n",
      "\n",
      "    accuracy                           0.94     23721\n",
      "   macro avg       0.89      0.84      0.86     23721\n",
      "weighted avg       0.94      0.94      0.94     23721\n",
      "\n",
      "\n",
      "TfidfVectorizer:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1523: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.50      0.64      2979\n",
      "           2       0.93      0.99      0.96     20742\n",
      "\n",
      "    accuracy                           0.93     23721\n",
      "   macro avg       0.91      0.75      0.80     23721\n",
      "weighted avg       0.93      0.93      0.92     23721\n",
      "\n",
      "\n",
      "---------------------------------------------------------------\n",
      "\n",
      "Data was loaded from 'reviews_Review_Label_TreebankWordTokenizer_spacy.df'\n",
      "_tokenizer='TreebankWordTokenizer', stopwords=spacy\n",
      "data.shape=(90646, 2)\n",
      "\n",
      "CountVectorizer:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1523: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.68      0.73      2979\n",
      "           2       0.95      0.98      0.97     20742\n",
      "\n",
      "    accuracy                           0.94     23721\n",
      "   macro avg       0.88      0.83      0.85     23721\n",
      "weighted avg       0.94      0.94      0.94     23721\n",
      "\n",
      "\n",
      "TfidfVectorizer:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1523: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.46      0.61      2979\n",
      "           2       0.93      0.99      0.96     20742\n",
      "\n",
      "    accuracy                           0.93     23721\n",
      "   macro avg       0.91      0.72      0.78     23721\n",
      "weighted avg       0.92      0.93      0.91     23721\n",
      "\n",
      "\n",
      "---------------------------------------------------------------\n",
      "\n",
      "Data was loaded from 'reviews_Review_Label_TreebankWordTokenizer_third_party_nltk.df'\n",
      "_tokenizer='TreebankWordTokenizer', stopwords=third_party_nltk\n",
      "data.shape=(90646, 2)\n",
      "\n",
      "CountVectorizer:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1523: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.69      0.74      2979\n",
      "           2       0.96      0.98      0.97     20742\n",
      "\n",
      "    accuracy                           0.94     23721\n",
      "   macro avg       0.88      0.83      0.85     23721\n",
      "weighted avg       0.94      0.94      0.94     23721\n",
      "\n",
      "\n",
      "TfidfVectorizer:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1523: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.48      0.62      2979\n",
      "           2       0.93      0.99      0.96     20742\n",
      "\n",
      "    accuracy                           0.93     23721\n",
      "   macro avg       0.91      0.73      0.79     23721\n",
      "weighted avg       0.93      0.93      0.92     23721\n",
      "\n",
      "\n",
      "---------------------------------------------------------------\n",
      "\n",
      "Data was loaded from 'reviews_Review_Label_rutokenizer_nltk.df'\n",
      "_tokenizer='rutokenizer', stopwords=nltk\n",
      "data.shape=(90646, 2)\n",
      "\n",
      "CountVectorizer:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1523: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.74      0.77      2979\n",
      "           2       0.96      0.97      0.97     20742\n",
      "\n",
      "    accuracy                           0.94     23721\n",
      "   macro avg       0.88      0.86      0.87     23721\n",
      "weighted avg       0.94      0.94      0.94     23721\n",
      "\n",
      "\n",
      "TfidfVectorizer:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1523: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.55      0.69      2979\n",
      "           2       0.94      0.99      0.97     20742\n",
      "\n",
      "    accuracy                           0.94     23721\n",
      "   macro avg       0.93      0.77      0.83     23721\n",
      "weighted avg       0.94      0.94      0.93     23721\n",
      "\n",
      "\n",
      "---------------------------------------------------------------\n",
      "\n",
      "Data was loaded from 'reviews_Review_Label_rutokenizer_spacy.df'\n",
      "_tokenizer='rutokenizer', stopwords=spacy\n",
      "data.shape=(90646, 2)\n",
      "\n",
      "CountVectorizer:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1523: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.73      0.77      2979\n",
      "           2       0.96      0.98      0.97     20742\n",
      "\n",
      "    accuracy                           0.94     23721\n",
      "   macro avg       0.89      0.85      0.87     23721\n",
      "weighted avg       0.94      0.94      0.94     23721\n",
      "\n",
      "\n",
      "TfidfVectorizer:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1523: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.52      0.67      2979\n",
      "           2       0.94      0.99      0.96     20742\n",
      "\n",
      "    accuracy                           0.93     23721\n",
      "   macro avg       0.93      0.76      0.81     23721\n",
      "weighted avg       0.93      0.93      0.93     23721\n",
      "\n",
      "\n",
      "---------------------------------------------------------------\n",
      "\n",
      "Data was loaded from 'reviews_Review_Label_rutokenizer_third_party_nltk.df'\n",
      "_tokenizer='rutokenizer', stopwords=third_party_nltk\n",
      "data.shape=(90646, 2)\n",
      "\n",
      "CountVectorizer:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1523: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.74      0.77      2979\n",
      "           2       0.96      0.97      0.97     20742\n",
      "\n",
      "    accuracy                           0.94     23721\n",
      "   macro avg       0.88      0.86      0.87     23721\n",
      "weighted avg       0.94      0.94      0.94     23721\n",
      "\n",
      "\n",
      "TfidfVectorizer:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1523: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.54      0.67      2979\n",
      "           2       0.94      0.99      0.96     20742\n",
      "\n",
      "    accuracy                           0.94     23721\n",
      "   macro avg       0.92      0.76      0.82     23721\n",
      "weighted avg       0.93      0.94      0.93     23721\n",
      "\n",
      "\n",
      "---------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for _tokenizer in ['razdel', 'TreebankWordTokenizer', 'rutokenizer']:\n",
    "    for i, _stopwords in enumerate(['fictitious', 'stopwords', 'list']):        \n",
    "        i_to_sw_name = {0: 'nltk', 1: 'spacy', 2: 'third_party_nltk'}\n",
    "        \n",
    "        with open(f'reviews_Review_Label_{_tokenizer}_{i_to_sw_name[i]}.df', 'rb') as file:\n",
    "            data = dill.load(file)\n",
    "            print(f\"Data was loaded from '{file.name}'\")\n",
    "        \n",
    "        print(f'{_tokenizer=}, stopwords={i_to_sw_name[i]}')\n",
    "        print(f'{data.shape=}\\n')\n",
    "        \n",
    "        \n",
    "        # Basic preprocessing\n",
    "        label_encoding = {\n",
    "            'POSITIVE': 2,\n",
    "            'NEUTRAL': 1,\n",
    "            'NEGATIVE': 0\n",
    "        }\n",
    "\n",
    "        data.label = data.label.apply(lambda label: label_encoding[label])\n",
    "        data = data[data.label != 1].reset_index().drop(columns=['index'])\n",
    "        train, test = train_test_split(data, test_size=0.3, random_state=42)\n",
    "        \n",
    "        \n",
    "        print('CountVectorizer:')\n",
    "        cnt_vec = CountVectorizer(tokenizer=WhitespaceTokenizer().tokenize)\n",
    "        X_train = cnt_vec.fit_transform(train.review)\n",
    "        X_test  = cnt_vec.transform(test.review)\n",
    "\n",
    "        clf = LogisticRegression(max_iter=200, n_jobs=-1, solver='liblinear')\n",
    "        clf.fit(X_train, train.label)\n",
    "        pred = clf.predict(X_test)\n",
    "\n",
    "        print(classification_report(test.label, pred))\n",
    "        \n",
    "        \n",
    "        print('\\nTfidfVectorizer:')\n",
    "        cnt_vec = TfidfVectorizer(tokenizer=WhitespaceTokenizer().tokenize)\n",
    "        X_train = cnt_vec.fit_transform(train.review)\n",
    "        X_test  = cnt_vec.transform(test.review)\n",
    "\n",
    "        clf = LogisticRegression(max_iter=200, n_jobs=-1, solver='liblinear')\n",
    "        clf.fit(X_train, train.label)\n",
    "        pred = clf.predict(X_test)\n",
    "\n",
    "        print(classification_report(test.label, pred))\n",
    "        \n",
    "        print('\\n---------------------------------------------------------------\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5a4e44",
   "metadata": {},
   "source": [
    "### Experiment 6\n",
    "\n",
    "**Tokenizer:** [`razdel`, `rutokenizer`]\n",
    "\n",
    "**Stopwords:** [`[]`]\n",
    "\n",
    "**Model:** `LogisticRegression`\n",
    "\n",
    "**LogReg params**: \n",
    "* **class_weight =** 'balanced'\n",
    "\n",
    "**Vectorizer:** `CountVectorizer`, `TfidfVectorizer`\n",
    "\n",
    "**Comments:** Before balancing training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482d383c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data was loaded from 'reviews_Review_Label_razdel_no.df'\n",
      "_tokenizer='razdel', stopwords=no\n",
      "data.shape=(90646, 2)\n",
      "\n",
      "CountVectorizer:\n",
      "34118    только недавно удаться посмотреть мультфильм «...\n",
      "Name: review, dtype: object\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.85      0.79      2979\n",
      "           2       0.98      0.96      0.97     20742\n",
      "\n",
      "    accuracy                           0.94     23721\n",
      "   macro avg       0.86      0.90      0.88     23721\n",
      "weighted avg       0.95      0.94      0.94     23721\n",
      "\n",
      "\n",
      "TfidfVectorizer:\n"
     ]
    }
   ],
   "source": [
    "for _tokenizer in ['razdel', 'rutokenizer']:\n",
    "    for i, _stopwords in enumerate([[]]):        \n",
    "        i_to_sw_name = {0: 'no'}\n",
    "        \n",
    "        with open(f'reviews_Review_Label_{_tokenizer}_{i_to_sw_name[i]}.df', 'rb') as file:\n",
    "            data = dill.load(file)\n",
    "            print(f\"Data was loaded from '{file.name}'\")\n",
    "        \n",
    "        print(f'{_tokenizer=}, stopwords={i_to_sw_name[i]}')\n",
    "        print(f'{data.shape=}\\n')\n",
    "        \n",
    "        \n",
    "        # Basic preprocessing\n",
    "        label_encoding = {\n",
    "            'POSITIVE': 2,\n",
    "            'NEUTRAL': 1,\n",
    "            'NEGATIVE': 0\n",
    "        }\n",
    "\n",
    "        data.label = data.label.apply(lambda label: label_encoding[label])\n",
    "        data = data[data.label != 1].reset_index().drop(columns=['index'])\n",
    "        train, test = train_test_split(data, test_size=0.3, random_state=42)\n",
    "        \n",
    "        \n",
    "        print(train.review.sample())\n",
    "        print('CountVectorizer:')\n",
    "        cnt_vec = CountVectorizer(tokenizer=WhitespaceTokenizer().tokenize)\n",
    "        X_train = cnt_vec.fit_transform(train.review)\n",
    "        X_test  = cnt_vec.transform(test.review)\n",
    "\n",
    "        clf = LogisticRegression(max_iter=200, n_jobs=-1, class_weight='balanced', random_state=42)\n",
    "        clf.fit(X_train, train.label)\n",
    "        pred = clf.predict(X_test)\n",
    "\n",
    "        print(classification_report(test.label, pred))\n",
    "        \n",
    "        \n",
    "        print('\\nTfidfVectorizer:')\n",
    "        cnt_vec = TfidfVectorizer(tokenizer=WhitespaceTokenizer().tokenize)\n",
    "        X_train = cnt_vec.fit_transform(train.review)\n",
    "        X_test  = cnt_vec.transform(test.review)\n",
    "\n",
    "        clf = LogisticRegression(max_iter=200, n_jobs=-1, class_weight='balanced', random_state=42)\n",
    "        clf.fit(X_train, train.label)\n",
    "        pred = clf.predict(X_test)\n",
    "\n",
    "        print(classification_report(test.label, pred))\n",
    "        \n",
    "        print('\\n---------------------------------------------------------------\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca05d650",
   "metadata": {},
   "source": [
    "## Balancing dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caeeb00e",
   "metadata": {},
   "source": [
    "[SMOTE: метод увеличения числа примеров миноритарного класса](https://medium.com/nuances-of-programming/smote-%D0%BC%D0%B5%D1%82%D0%BE%D0%B4-%D1%83%D0%B2%D0%B5%D0%BB%D0%B8%D1%87%D0%B5%D0%BD%D0%B8%D1%8F-%D1%87%D0%B8%D1%81%D0%BB%D0%B0-%D0%BF%D1%80%D0%B8%D0%BC%D0%B5%D1%80%D0%BE%D0%B2-%D0%BC%D0%B8%D0%BD%D0%BE%D1%80%D0%B8%D1%82%D0%B0%D1%80%D0%BD%D0%BE%D0%B3%D0%BE-%D0%BA%D0%BB%D0%B0%D1%81%D1%81%D0%B0-da91a62f9914)\n",
    "> Другим вариантом является увеличение примеров миноритарного класса. Иными словами, случайным образом дублируются образцы миноритарного класса. Проблема этого подхода заключается в том, что он приводит к чрезмерному обучению, поскольку модель обучается на одних и тех же примерах."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8394fa79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    48477\n",
       "0     6869\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "21da6a68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>54700</th>\n",
       "      <td>фильм стоить выходить предел великобритания . ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67873</th>\n",
       "      <td>это самый впечатляющий по-настоящему жуткий фи...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44030</th>\n",
       "      <td>первый часть ' чужой ' свой время произвести в...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21503</th>\n",
       "      <td>история начинающий барабанщик эндрю зародиться...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75163</th>\n",
       "      <td>&lt; b &gt; дождаться . прокат выйти новый кинолента...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59219</th>\n",
       "      <td>&lt; i &gt; - хотеть нормальный ? наоборот . &lt; / i &gt;...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70598</th>\n",
       "      <td>фильм однозначный , отношение двоякий . нарком...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6477</th>\n",
       "      <td>, прийти пора пропеть очередной песня славный ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58139</th>\n",
       "      <td>начать , пожалуй , , фильм пойти , прочитать к...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7387</th>\n",
       "      <td>специфический мультфильм , который категоричес...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>96846 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review  label\n",
       "54700  фильм стоить выходить предел великобритания . ...      0\n",
       "67873  это самый впечатляющий по-настоящему жуткий фи...      2\n",
       "44030  первый часть ' чужой ' свой время произвести в...      2\n",
       "21503  история начинающий барабанщик эндрю зародиться...      2\n",
       "75163  < b > дождаться . прокат выйти новый кинолента...      2\n",
       "...                                                  ...    ...\n",
       "59219  < i > - хотеть нормальный ? наоборот . < / i >...      0\n",
       "70598  фильм однозначный , отношение двоякий . нарком...      0\n",
       "6477   , прийти пора пропеть очередной песня славный ...      0\n",
       "58139  начать , пожалуй , , фильм пойти , прочитать к...      0\n",
       "7387   специфический мультфильм , который категоричес...      0\n",
       "\n",
       "[96846 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.concat([train, resample(train[train.label == 0], n_samples=41500, random_state=42)])\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b2fe5c87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    48477\n",
       "0    48369\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.label.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec5b8c25",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb8303fa",
   "metadata": {},
   "source": [
    "## Serial classification experiments (after balancing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7e1698",
   "metadata": {},
   "source": [
    "### Experiment 1\n",
    "\n",
    "**Tokenizer:** [`razdel`, `TreebankWordTokenizer`, `rutokenizer`]\n",
    "\n",
    "**Stopwords:** [`nltk`, `spacy`, custom_list]\n",
    "\n",
    "**Model:** `LogisticRegression`\n",
    "\n",
    "**Vectorizer:** `CountVectorizer`, `TfidfVectorizer`\n",
    "\n",
    "**Comments:** After balancing training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e08c17e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data was loaded from 'reviews_Review_Label_razdel_nltk.df'\n",
      "_tokenizer='razdel', stopwords=nltk\n",
      "data.shape=(90646, 2)\n",
      "\n",
      "train.shape=(96846, 2)\n",
      "CountVectorizer:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.82      0.78      2979\n",
      "           2       0.97      0.96      0.97     20742\n",
      "\n",
      "    accuracy                           0.94     23721\n",
      "   macro avg       0.86      0.89      0.87     23721\n",
      "weighted avg       0.95      0.94      0.94     23721\n",
      "\n",
      "\n",
      "TfidfVectorizer:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.90      0.78      2979\n",
      "           2       0.98      0.94      0.96     20742\n",
      "\n",
      "    accuracy                           0.94     23721\n",
      "   macro avg       0.84      0.92      0.87     23721\n",
      "weighted avg       0.95      0.94      0.94     23721\n",
      "\n",
      "\n",
      "---------------------------------------------------------------\n",
      "\n",
      "Data was loaded from 'reviews_Review_Label_razdel_spacy.df'\n",
      "_tokenizer='razdel', stopwords=spacy\n",
      "data.shape=(90646, 2)\n",
      "\n",
      "train.shape=(96846, 2)\n",
      "CountVectorizer:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.81      0.77      2979\n",
      "           2       0.97      0.96      0.97     20742\n",
      "\n",
      "    accuracy                           0.94     23721\n",
      "   macro avg       0.86      0.88      0.87     23721\n",
      "weighted avg       0.94      0.94      0.94     23721\n",
      "\n",
      "\n",
      "TfidfVectorizer:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.89      0.77      2979\n",
      "           2       0.98      0.94      0.96     20742\n",
      "\n",
      "    accuracy                           0.93     23721\n",
      "   macro avg       0.83      0.92      0.87     23721\n",
      "weighted avg       0.95      0.93      0.94     23721\n",
      "\n",
      "\n",
      "---------------------------------------------------------------\n",
      "\n",
      "Data was loaded from 'reviews_Review_Label_razdel_third_party_nltk.df'\n",
      "_tokenizer='razdel', stopwords=third_party_nltk\n",
      "data.shape=(90646, 2)\n",
      "\n",
      "train.shape=(96846, 2)\n",
      "CountVectorizer:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.80      0.78      2979\n",
      "           2       0.97      0.96      0.97     20742\n",
      "\n",
      "    accuracy                           0.94     23721\n",
      "   macro avg       0.87      0.88      0.87     23721\n",
      "weighted avg       0.94      0.94      0.94     23721\n",
      "\n",
      "\n",
      "TfidfVectorizer:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.89      0.78      2979\n",
      "           2       0.98      0.94      0.96     20742\n",
      "\n",
      "    accuracy                           0.94     23721\n",
      "   macro avg       0.84      0.92      0.87     23721\n",
      "weighted avg       0.95      0.94      0.94     23721\n",
      "\n",
      "\n",
      "---------------------------------------------------------------\n",
      "\n",
      "Data was loaded from 'reviews_Review_Label_TreebankWordTokenizer_nltk.df'\n",
      "_tokenizer='TreebankWordTokenizer', stopwords=nltk\n",
      "data.shape=(90646, 2)\n",
      "\n",
      "train.shape=(96846, 2)\n",
      "CountVectorizer:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.75      0.75      2979\n",
      "           2       0.96      0.97      0.97     20742\n",
      "\n",
      "    accuracy                           0.94     23721\n",
      "   macro avg       0.86      0.86      0.86     23721\n",
      "weighted avg       0.94      0.94      0.94     23721\n",
      "\n",
      "\n",
      "TfidfVectorizer:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.86      0.75      2979\n",
      "           2       0.98      0.94      0.96     20742\n",
      "\n",
      "    accuracy                           0.93     23721\n",
      "   macro avg       0.82      0.90      0.85     23721\n",
      "weighted avg       0.94      0.93      0.93     23721\n",
      "\n",
      "\n",
      "---------------------------------------------------------------\n",
      "\n",
      "Data was loaded from 'reviews_Review_Label_TreebankWordTokenizer_spacy.df'\n",
      "_tokenizer='TreebankWordTokenizer', stopwords=spacy\n",
      "data.shape=(90646, 2)\n",
      "\n",
      "train.shape=(96846, 2)\n",
      "CountVectorizer:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.73      0.74      2979\n",
      "           2       0.96      0.96      0.96     20742\n",
      "\n",
      "    accuracy                           0.93     23721\n",
      "   macro avg       0.85      0.85      0.85     23721\n",
      "weighted avg       0.93      0.93      0.93     23721\n",
      "\n",
      "\n",
      "TfidfVectorizer:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.85      0.74      2979\n",
      "           2       0.98      0.93      0.96     20742\n",
      "\n",
      "    accuracy                           0.92     23721\n",
      "   macro avg       0.82      0.89      0.85     23721\n",
      "weighted avg       0.94      0.92      0.93     23721\n",
      "\n",
      "\n",
      "---------------------------------------------------------------\n",
      "\n",
      "Data was loaded from 'reviews_Review_Label_TreebankWordTokenizer_third_party_nltk.df'\n",
      "_tokenizer='TreebankWordTokenizer', stopwords=third_party_nltk\n",
      "data.shape=(90646, 2)\n",
      "\n",
      "train.shape=(96846, 2)\n",
      "CountVectorizer:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.74      0.74      2979\n",
      "           2       0.96      0.96      0.96     20742\n",
      "\n",
      "    accuracy                           0.93     23721\n",
      "   macro avg       0.85      0.85      0.85     23721\n",
      "weighted avg       0.94      0.93      0.93     23721\n",
      "\n",
      "\n",
      "TfidfVectorizer:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.86      0.75      2979\n",
      "           2       0.98      0.94      0.96     20742\n",
      "\n",
      "    accuracy                           0.93     23721\n",
      "   macro avg       0.82      0.90      0.85     23721\n",
      "weighted avg       0.94      0.93      0.93     23721\n",
      "\n",
      "\n",
      "---------------------------------------------------------------\n",
      "\n",
      "Data was loaded from 'reviews_Review_Label_rutokenizer_nltk.df'\n",
      "_tokenizer='rutokenizer', stopwords=nltk\n",
      "data.shape=(90646, 2)\n",
      "\n",
      "train.shape=(96846, 2)\n",
      "CountVectorizer:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.79      0.77      2979\n",
      "           2       0.97      0.96      0.97     20742\n",
      "\n",
      "    accuracy                           0.94     23721\n",
      "   macro avg       0.86      0.88      0.87     23721\n",
      "weighted avg       0.94      0.94      0.94     23721\n",
      "\n",
      "\n",
      "TfidfVectorizer:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\anaconda3\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py:702: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.89      0.77      2979\n",
      "           2       0.98      0.94      0.96     20742\n",
      "\n",
      "    accuracy                           0.93     23721\n",
      "   macro avg       0.83      0.92      0.87     23721\n",
      "weighted avg       0.95      0.93      0.94     23721\n",
      "\n",
      "\n",
      "---------------------------------------------------------------\n",
      "\n",
      "Data was loaded from 'reviews_Review_Label_rutokenizer_spacy.df'\n",
      "_tokenizer='rutokenizer', stopwords=spacy\n",
      "data.shape=(90646, 2)\n",
      "\n",
      "train.shape=(96846, 2)\n",
      "CountVectorizer:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.81      0.76      2979\n",
      "           2       0.97      0.95      0.96     20742\n",
      "\n",
      "    accuracy                           0.94     23721\n",
      "   macro avg       0.85      0.88      0.86     23721\n",
      "weighted avg       0.94      0.94      0.94     23721\n",
      "\n",
      "\n",
      "TfidfVectorizer:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.89      0.77      2979\n",
      "           2       0.98      0.94      0.96     20742\n",
      "\n",
      "    accuracy                           0.93     23721\n",
      "   macro avg       0.83      0.91      0.87     23721\n",
      "weighted avg       0.94      0.93      0.94     23721\n",
      "\n",
      "\n",
      "---------------------------------------------------------------\n",
      "\n",
      "Data was loaded from 'reviews_Review_Label_rutokenizer_third_party_nltk.df'\n",
      "_tokenizer='rutokenizer', stopwords=third_party_nltk\n",
      "data.shape=(90646, 2)\n",
      "\n",
      "train.shape=(96846, 2)\n",
      "CountVectorizer:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.82      0.78      2979\n",
      "           2       0.97      0.96      0.97     20742\n",
      "\n",
      "    accuracy                           0.94     23721\n",
      "   macro avg       0.86      0.89      0.87     23721\n",
      "weighted avg       0.95      0.94      0.94     23721\n",
      "\n",
      "\n",
      "TfidfVectorizer:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.89      0.77      2979\n",
      "           2       0.98      0.94      0.96     20742\n",
      "\n",
      "    accuracy                           0.93     23721\n",
      "   macro avg       0.83      0.92      0.87     23721\n",
      "weighted avg       0.95      0.93      0.94     23721\n",
      "\n",
      "\n",
      "---------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for _tokenizer in ['razdel', 'TreebankWordTokenizer', 'rutokenizer']:\n",
    "    for i, _stopwords in enumerate(['fictitious', 'stopwords', 'list']):        \n",
    "        i_to_sw_name = {0: 'nltk', 1: 'spacy', 2: 'third_party_nltk'}\n",
    "        \n",
    "        with open(f'reviews_Review_Label_{_tokenizer}_{i_to_sw_name[i]}.df', 'rb') as file:\n",
    "            data = dill.load(file)\n",
    "            print(f\"Data was loaded from '{file.name}'\")\n",
    "        \n",
    "        print(f'{_tokenizer=}, stopwords={i_to_sw_name[i]}')\n",
    "        print(f'{data.shape=}\\n')\n",
    "        \n",
    "        \n",
    "        # Basic preprocessing\n",
    "        label_encoding = {\n",
    "            'POSITIVE': 2,\n",
    "            'NEUTRAL': 1,\n",
    "            'NEGATIVE': 0\n",
    "        }\n",
    "\n",
    "        data.label = data.label.apply(lambda label: label_encoding[label])\n",
    "        data = data[data.label != 1].reset_index().drop(columns=['index'])\n",
    "        train, test = train_test_split(data, test_size=0.3, random_state=42)\n",
    "                       \n",
    "        # Balancing dataset\n",
    "        train = pd.concat([train, resample(train[train.label == 0], n_samples=41500, random_state=42)])\n",
    "        print(f'{train.shape=}')\n",
    "        \n",
    "        \n",
    "        print('CountVectorizer:')\n",
    "        cnt_vec = CountVectorizer(tokenizer=WhitespaceTokenizer().tokenize)\n",
    "        X_train = cnt_vec.fit_transform(train.review)\n",
    "        X_test  = cnt_vec.transform(test.review)\n",
    "\n",
    "        clf = LogisticRegression(max_iter=200, n_jobs=-1)\n",
    "        clf.fit(X_train, train.label)\n",
    "        pred = clf.predict(X_test)\n",
    "\n",
    "        print(classification_report(test.label, pred))\n",
    "        \n",
    "        \n",
    "        print('\\nTfidfVectorizer:')\n",
    "        cnt_vec = TfidfVectorizer(tokenizer=WhitespaceTokenizer().tokenize)\n",
    "        X_train = cnt_vec.fit_transform(train.review)\n",
    "        X_test  = cnt_vec.transform(test.review)\n",
    "\n",
    "        clf = LogisticRegression(max_iter=200, n_jobs=-1)\n",
    "        clf.fit(X_train, train.label)\n",
    "        pred = clf.predict(X_test)\n",
    "\n",
    "        print(classification_report(test.label, pred))\n",
    "        \n",
    "        print('\\n---------------------------------------------------------------\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed097718",
   "metadata": {},
   "source": [
    "### Experiment 2\n",
    "\n",
    "**Tokenizer:** [`razdel`, `TreebankWordTokenizer`, `rutokenizer`]\n",
    "\n",
    "**Stopwords:** [`nltk`, `spacy`, custom_list]\n",
    "\n",
    "**Model:** `LogisticRegression`\n",
    "\n",
    "**LogReg params**: \n",
    "* **class_weight =** 'balanced'\n",
    "\n",
    "**Vectorizer:** `CountVectorizer`, `TfidfVectorizer`\n",
    "\n",
    "**Comments:** After balancing training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a245cd09",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data was loaded from 'reviews_Review_Label_razdel_nltk.df'\n",
      "_tokenizer='razdel', stopwords=nltk\n",
      "data.shape=(90646, 2)\n",
      "\n",
      "train.shape=(96846, 2)\n",
      "CountVectorizer:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.82      0.79      2979\n",
      "           2       0.97      0.96      0.97     20742\n",
      "\n",
      "    accuracy                           0.94     23721\n",
      "   macro avg       0.86      0.89      0.88     23721\n",
      "weighted avg       0.95      0.94      0.94     23721\n",
      "\n",
      "\n",
      "TfidfVectorizer:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.90      0.78      2979\n",
      "           2       0.98      0.94      0.96     20742\n",
      "\n",
      "    accuracy                           0.94     23721\n",
      "   macro avg       0.84      0.92      0.87     23721\n",
      "weighted avg       0.95      0.94      0.94     23721\n",
      "\n",
      "\n",
      "---------------------------------------------------------------\n",
      "\n",
      "Data was loaded from 'reviews_Review_Label_razdel_spacy.df'\n",
      "_tokenizer='razdel', stopwords=spacy\n",
      "data.shape=(90646, 2)\n",
      "\n",
      "train.shape=(96846, 2)\n",
      "CountVectorizer:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.83      0.77      2979\n",
      "           2       0.97      0.95      0.96     20742\n",
      "\n",
      "    accuracy                           0.94     23721\n",
      "   macro avg       0.85      0.89      0.87     23721\n",
      "weighted avg       0.94      0.94      0.94     23721\n",
      "\n",
      "\n",
      "TfidfVectorizer:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.89      0.77      2979\n",
      "           2       0.98      0.94      0.96     20742\n",
      "\n",
      "    accuracy                           0.93     23721\n",
      "   macro avg       0.83      0.92      0.87     23721\n",
      "weighted avg       0.95      0.93      0.94     23721\n",
      "\n",
      "\n",
      "---------------------------------------------------------------\n",
      "\n",
      "Data was loaded from 'reviews_Review_Label_razdel_third_party_nltk.df'\n",
      "_tokenizer='razdel', stopwords=third_party_nltk\n",
      "data.shape=(90646, 2)\n",
      "\n",
      "train.shape=(96846, 2)\n",
      "CountVectorizer:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.83      0.78      2979\n",
      "           2       0.97      0.96      0.97     20742\n",
      "\n",
      "    accuracy                           0.94     23721\n",
      "   macro avg       0.85      0.89      0.87     23721\n",
      "weighted avg       0.94      0.94      0.94     23721\n",
      "\n",
      "\n",
      "TfidfVectorizer:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.89      0.78      2979\n",
      "           2       0.98      0.94      0.96     20742\n",
      "\n",
      "    accuracy                           0.94     23721\n",
      "   macro avg       0.84      0.92      0.87     23721\n",
      "weighted avg       0.95      0.94      0.94     23721\n",
      "\n",
      "\n",
      "---------------------------------------------------------------\n",
      "\n",
      "Data was loaded from 'reviews_Review_Label_TreebankWordTokenizer_nltk.df'\n",
      "_tokenizer='TreebankWordTokenizer', stopwords=nltk\n",
      "data.shape=(90646, 2)\n",
      "\n",
      "train.shape=(96846, 2)\n",
      "CountVectorizer:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.75      0.75      2979\n",
      "           2       0.96      0.96      0.96     20742\n",
      "\n",
      "    accuracy                           0.94     23721\n",
      "   macro avg       0.86      0.86      0.86     23721\n",
      "weighted avg       0.94      0.94      0.94     23721\n",
      "\n",
      "\n",
      "TfidfVectorizer:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.86      0.75      2979\n",
      "           2       0.98      0.94      0.96     20742\n",
      "\n",
      "    accuracy                           0.93     23721\n",
      "   macro avg       0.82      0.90      0.85     23721\n",
      "weighted avg       0.94      0.93      0.93     23721\n",
      "\n",
      "\n",
      "---------------------------------------------------------------\n",
      "\n",
      "Data was loaded from 'reviews_Review_Label_TreebankWordTokenizer_spacy.df'\n",
      "_tokenizer='TreebankWordTokenizer', stopwords=spacy\n",
      "data.shape=(90646, 2)\n",
      "\n",
      "train.shape=(96846, 2)\n",
      "CountVectorizer:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.72      0.74      2979\n",
      "           2       0.96      0.97      0.96     20742\n",
      "\n",
      "    accuracy                           0.94     23721\n",
      "   macro avg       0.86      0.84      0.85     23721\n",
      "weighted avg       0.93      0.94      0.94     23721\n",
      "\n",
      "\n",
      "TfidfVectorizer:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.85      0.74      2979\n",
      "           2       0.98      0.93      0.96     20742\n",
      "\n",
      "    accuracy                           0.92     23721\n",
      "   macro avg       0.82      0.89      0.85     23721\n",
      "weighted avg       0.94      0.92      0.93     23721\n",
      "\n",
      "\n",
      "---------------------------------------------------------------\n",
      "\n",
      "Data was loaded from 'reviews_Review_Label_TreebankWordTokenizer_third_party_nltk.df'\n",
      "_tokenizer='TreebankWordTokenizer', stopwords=third_party_nltk\n",
      "data.shape=(90646, 2)\n",
      "\n",
      "train.shape=(96846, 2)\n",
      "CountVectorizer:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.73      0.74      2979\n",
      "           2       0.96      0.97      0.96     20742\n",
      "\n",
      "    accuracy                           0.94     23721\n",
      "   macro avg       0.86      0.85      0.85     23721\n",
      "weighted avg       0.94      0.94      0.94     23721\n",
      "\n",
      "\n",
      "TfidfVectorizer:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.86      0.75      2979\n",
      "           2       0.98      0.94      0.96     20742\n",
      "\n",
      "    accuracy                           0.93     23721\n",
      "   macro avg       0.82      0.90      0.85     23721\n",
      "weighted avg       0.94      0.93      0.93     23721\n",
      "\n",
      "\n",
      "---------------------------------------------------------------\n",
      "\n",
      "Data was loaded from 'reviews_Review_Label_rutokenizer_nltk.df'\n",
      "_tokenizer='rutokenizer', stopwords=nltk\n",
      "data.shape=(90646, 2)\n",
      "\n",
      "train.shape=(96846, 2)\n",
      "CountVectorizer:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.80      0.78      2979\n",
      "           2       0.97      0.96      0.97     20742\n",
      "\n",
      "    accuracy                           0.94     23721\n",
      "   macro avg       0.86      0.88      0.87     23721\n",
      "weighted avg       0.94      0.94      0.94     23721\n",
      "\n",
      "\n",
      "TfidfVectorizer:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.89      0.77      2979\n",
      "           2       0.98      0.94      0.96     20742\n",
      "\n",
      "    accuracy                           0.93     23721\n",
      "   macro avg       0.83      0.92      0.87     23721\n",
      "weighted avg       0.95      0.93      0.94     23721\n",
      "\n",
      "\n",
      "---------------------------------------------------------------\n",
      "\n",
      "Data was loaded from 'reviews_Review_Label_rutokenizer_spacy.df'\n",
      "_tokenizer='rutokenizer', stopwords=spacy\n",
      "data.shape=(90646, 2)\n",
      "\n",
      "train.shape=(96846, 2)\n",
      "CountVectorizer:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.81      0.76      2979\n",
      "           2       0.97      0.95      0.96     20742\n",
      "\n",
      "    accuracy                           0.94     23721\n",
      "   macro avg       0.85      0.88      0.86     23721\n",
      "weighted avg       0.94      0.94      0.94     23721\n",
      "\n",
      "\n",
      "TfidfVectorizer:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.89      0.77      2979\n",
      "           2       0.98      0.94      0.96     20742\n",
      "\n",
      "    accuracy                           0.93     23721\n",
      "   macro avg       0.83      0.91      0.87     23721\n",
      "weighted avg       0.94      0.93      0.94     23721\n",
      "\n",
      "\n",
      "---------------------------------------------------------------\n",
      "\n",
      "Data was loaded from 'reviews_Review_Label_rutokenizer_third_party_nltk.df'\n",
      "_tokenizer='rutokenizer', stopwords=third_party_nltk\n",
      "data.shape=(90646, 2)\n",
      "\n",
      "train.shape=(96846, 2)\n",
      "CountVectorizer:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.81      0.78      2979\n",
      "           2       0.97      0.96      0.97     20742\n",
      "\n",
      "    accuracy                           0.94     23721\n",
      "   macro avg       0.86      0.88      0.87     23721\n",
      "weighted avg       0.94      0.94      0.94     23721\n",
      "\n",
      "\n",
      "TfidfVectorizer:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.89      0.77      2979\n",
      "           2       0.98      0.94      0.96     20742\n",
      "\n",
      "    accuracy                           0.93     23721\n",
      "   macro avg       0.83      0.92      0.87     23721\n",
      "weighted avg       0.95      0.93      0.94     23721\n",
      "\n",
      "\n",
      "---------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for _tokenizer in ['razdel', 'TreebankWordTokenizer', 'rutokenizer']:\n",
    "    for i, _stopwords in enumerate(['fictitious', 'stopwords', 'list']):        \n",
    "        i_to_sw_name = {0: 'nltk', 1: 'spacy', 2: 'third_party_nltk'}\n",
    "        \n",
    "        with open(f'reviews_Review_Label_{_tokenizer}_{i_to_sw_name[i]}.df', 'rb') as file:\n",
    "            data = dill.load(file)\n",
    "            print(f\"Data was loaded from '{file.name}'\")\n",
    "        \n",
    "        print(f'{_tokenizer=}, stopwords={i_to_sw_name[i]}')\n",
    "        print(f'{data.shape=}\\n')\n",
    "        \n",
    "        \n",
    "        # Basic preprocessing\n",
    "        label_encoding = {\n",
    "            'POSITIVE': 2,\n",
    "            'NEUTRAL': 1,\n",
    "            'NEGATIVE': 0\n",
    "        }\n",
    "\n",
    "        data.label = data.label.apply(lambda label: label_encoding[label])\n",
    "        data = data[data.label != 1].reset_index().drop(columns=['index'])\n",
    "        train, test = train_test_split(data, test_size=0.3, random_state=42)\n",
    "            \n",
    "        # Balancing dataset\n",
    "        train = pd.concat([train, resample(train[train.label == 0], n_samples=41500, random_state=42)])\n",
    "        print(f'{train.shape=}')\n",
    "        \n",
    "        \n",
    "        print('CountVectorizer:')\n",
    "        cnt_vec = CountVectorizer(tokenizer=WhitespaceTokenizer().tokenize)\n",
    "        X_train = cnt_vec.fit_transform(train.review)\n",
    "        X_test  = cnt_vec.transform(test.review)\n",
    "\n",
    "        clf = LogisticRegression(max_iter=200, n_jobs=-1, class_weight='balanced')\n",
    "        clf.fit(X_train, train.label)\n",
    "        pred = clf.predict(X_test)\n",
    "\n",
    "        print(classification_report(test.label, pred))\n",
    "        \n",
    "        \n",
    "        print('\\nTfidfVectorizer:')\n",
    "        cnt_vec = TfidfVectorizer(tokenizer=WhitespaceTokenizer().tokenize)\n",
    "        X_train = cnt_vec.fit_transform(train.review)\n",
    "        X_test  = cnt_vec.transform(test.review)\n",
    "\n",
    "        clf = LogisticRegression(max_iter=200, n_jobs=-1, class_weight='balanced')\n",
    "        clf.fit(X_train, train.label)\n",
    "        pred = clf.predict(X_test)\n",
    "\n",
    "        print(classification_report(test.label, pred))\n",
    "        \n",
    "        print('\\n---------------------------------------------------------------\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d19d59",
   "metadata": {},
   "source": [
    "### Experiment 3\n",
    "\n",
    "**Tokenizer:** [`razdel`, `TreebankWordTokenizer`, `rutokenizer`]\n",
    "\n",
    "**Stopwords:** [`nltk`, `spacy`, custom_list]\n",
    "\n",
    "**Model:** `LogisticRegression`\n",
    "\n",
    "**Vectorizer:** `CountVectorizer`, `TfidfVectorizer`\n",
    "\n",
    "**Vectorizer params**: \n",
    "* **max_df =** $0.6$\n",
    "* **max_features  =** $10000$\n",
    "\n",
    "**Comments:** After balancing training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ccaad09d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data was loaded from 'reviews_Review_Label_razdel_nltk.df'\n",
      "_tokenizer='razdel', stopwords=nltk\n",
      "data.shape=(90646, 2)\n",
      "\n",
      "train.shape=(96846, 2)\n",
      "CountVectorizer:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.78      0.76      2979\n",
      "           2       0.97      0.96      0.96     20742\n",
      "\n",
      "    accuracy                           0.94     23721\n",
      "   macro avg       0.85      0.87      0.86     23721\n",
      "weighted avg       0.94      0.94      0.94     23721\n",
      "\n",
      "\n",
      "TfidfVectorizer:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.89      0.77      2979\n",
      "           2       0.98      0.94      0.96     20742\n",
      "\n",
      "    accuracy                           0.93     23721\n",
      "   macro avg       0.83      0.92      0.87     23721\n",
      "weighted avg       0.95      0.93      0.94     23721\n",
      "\n",
      "\n",
      "---------------------------------------------------------------\n",
      "\n",
      "Data was loaded from 'reviews_Review_Label_razdel_spacy.df'\n",
      "_tokenizer='razdel', stopwords=spacy\n",
      "data.shape=(90646, 2)\n",
      "\n",
      "train.shape=(96846, 2)\n",
      "CountVectorizer:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.78      0.75      2979\n",
      "           2       0.97      0.96      0.96     20742\n",
      "\n",
      "    accuracy                           0.94     23721\n",
      "   macro avg       0.85      0.87      0.86     23721\n",
      "weighted avg       0.94      0.94      0.94     23721\n",
      "\n",
      "\n",
      "TfidfVectorizer:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.89      0.76      2979\n",
      "           2       0.98      0.94      0.96     20742\n",
      "\n",
      "    accuracy                           0.93     23721\n",
      "   macro avg       0.83      0.91      0.86     23721\n",
      "weighted avg       0.94      0.93      0.93     23721\n",
      "\n",
      "\n",
      "---------------------------------------------------------------\n",
      "\n",
      "Data was loaded from 'reviews_Review_Label_razdel_third_party_nltk.df'\n",
      "_tokenizer='razdel', stopwords=third_party_nltk\n",
      "data.shape=(90646, 2)\n",
      "\n",
      "train.shape=(96846, 2)\n",
      "CountVectorizer:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.78      0.75      2979\n",
      "           2       0.97      0.96      0.96     20742\n",
      "\n",
      "    accuracy                           0.94     23721\n",
      "   macro avg       0.85      0.87      0.86     23721\n",
      "weighted avg       0.94      0.94      0.94     23721\n",
      "\n",
      "\n",
      "TfidfVectorizer:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.89      0.77      2979\n",
      "           2       0.98      0.94      0.96     20742\n",
      "\n",
      "    accuracy                           0.93     23721\n",
      "   macro avg       0.83      0.91      0.87     23721\n",
      "weighted avg       0.95      0.93      0.94     23721\n",
      "\n",
      "\n",
      "---------------------------------------------------------------\n",
      "\n",
      "Data was loaded from 'reviews_Review_Label_TreebankWordTokenizer_nltk.df'\n",
      "_tokenizer='TreebankWordTokenizer', stopwords=nltk\n",
      "data.shape=(90646, 2)\n",
      "\n",
      "train.shape=(96846, 2)\n",
      "CountVectorizer:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.74      0.71      2979\n",
      "           2       0.96      0.95      0.96     20742\n",
      "\n",
      "    accuracy                           0.92     23721\n",
      "   macro avg       0.82      0.85      0.83     23721\n",
      "weighted avg       0.93      0.92      0.92     23721\n",
      "\n",
      "\n",
      "TfidfVectorizer:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.87      0.74      2979\n",
      "           2       0.98      0.93      0.95     20742\n",
      "\n",
      "    accuracy                           0.92     23721\n",
      "   macro avg       0.81      0.90      0.84     23721\n",
      "weighted avg       0.94      0.92      0.93     23721\n",
      "\n",
      "\n",
      "---------------------------------------------------------------\n",
      "\n",
      "Data was loaded from 'reviews_Review_Label_TreebankWordTokenizer_spacy.df'\n",
      "_tokenizer='TreebankWordTokenizer', stopwords=spacy\n",
      "data.shape=(90646, 2)\n",
      "\n",
      "train.shape=(96846, 2)\n",
      "CountVectorizer:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.73      0.69      2979\n",
      "           2       0.96      0.94      0.95     20742\n",
      "\n",
      "    accuracy                           0.92     23721\n",
      "   macro avg       0.81      0.84      0.82     23721\n",
      "weighted avg       0.92      0.92      0.92     23721\n",
      "\n",
      "\n",
      "TfidfVectorizer:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.86      0.72      2979\n",
      "           2       0.98      0.92      0.95     20742\n",
      "\n",
      "    accuracy                           0.92     23721\n",
      "   macro avg       0.80      0.89      0.84     23721\n",
      "weighted avg       0.93      0.92      0.92     23721\n",
      "\n",
      "\n",
      "---------------------------------------------------------------\n",
      "\n",
      "Data was loaded from 'reviews_Review_Label_TreebankWordTokenizer_third_party_nltk.df'\n",
      "_tokenizer='TreebankWordTokenizer', stopwords=third_party_nltk\n",
      "data.shape=(90646, 2)\n",
      "\n",
      "train.shape=(96846, 2)\n",
      "CountVectorizer:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.74      0.70      2979\n",
      "           2       0.96      0.95      0.95     20742\n",
      "\n",
      "    accuracy                           0.92     23721\n",
      "   macro avg       0.81      0.84      0.83     23721\n",
      "weighted avg       0.92      0.92      0.92     23721\n",
      "\n",
      "\n",
      "TfidfVectorizer:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.87      0.73      2979\n",
      "           2       0.98      0.93      0.95     20742\n",
      "\n",
      "    accuracy                           0.92     23721\n",
      "   macro avg       0.81      0.90      0.84     23721\n",
      "weighted avg       0.94      0.92      0.93     23721\n",
      "\n",
      "\n",
      "---------------------------------------------------------------\n",
      "\n",
      "Data was loaded from 'reviews_Review_Label_rutokenizer_nltk.df'\n",
      "_tokenizer='rutokenizer', stopwords=nltk\n",
      "data.shape=(90646, 2)\n",
      "\n",
      "train.shape=(96846, 2)\n",
      "CountVectorizer:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.78      0.75      2979\n",
      "           2       0.97      0.96      0.96     20742\n",
      "\n",
      "    accuracy                           0.93     23721\n",
      "   macro avg       0.84      0.87      0.85     23721\n",
      "weighted avg       0.94      0.93      0.93     23721\n",
      "\n",
      "\n",
      "TfidfVectorizer:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.89      0.77      2979\n",
      "           2       0.98      0.94      0.96     20742\n",
      "\n",
      "    accuracy                           0.93     23721\n",
      "   macro avg       0.83      0.91      0.86     23721\n",
      "weighted avg       0.94      0.93      0.94     23721\n",
      "\n",
      "\n",
      "---------------------------------------------------------------\n",
      "\n",
      "Data was loaded from 'reviews_Review_Label_rutokenizer_spacy.df'\n",
      "_tokenizer='rutokenizer', stopwords=spacy\n",
      "data.shape=(90646, 2)\n",
      "\n",
      "train.shape=(96846, 2)\n",
      "CountVectorizer:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.77      0.74      2979\n",
      "           2       0.97      0.95      0.96     20742\n",
      "\n",
      "    accuracy                           0.93     23721\n",
      "   macro avg       0.84      0.86      0.85     23721\n",
      "weighted avg       0.93      0.93      0.93     23721\n",
      "\n",
      "\n",
      "TfidfVectorizer:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.88      0.76      2979\n",
      "           2       0.98      0.94      0.96     20742\n",
      "\n",
      "    accuracy                           0.93     23721\n",
      "   macro avg       0.82      0.91      0.86     23721\n",
      "weighted avg       0.94      0.93      0.93     23721\n",
      "\n",
      "\n",
      "---------------------------------------------------------------\n",
      "\n",
      "Data was loaded from 'reviews_Review_Label_rutokenizer_third_party_nltk.df'\n",
      "_tokenizer='rutokenizer', stopwords=third_party_nltk\n",
      "data.shape=(90646, 2)\n",
      "\n",
      "train.shape=(96846, 2)\n",
      "CountVectorizer:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.77      0.74      2979\n",
      "           2       0.97      0.95      0.96     20742\n",
      "\n",
      "    accuracy                           0.93     23721\n",
      "   macro avg       0.84      0.86      0.85     23721\n",
      "weighted avg       0.93      0.93      0.93     23721\n",
      "\n",
      "\n",
      "TfidfVectorizer:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.89      0.76      2979\n",
      "           2       0.98      0.94      0.96     20742\n",
      "\n",
      "    accuracy                           0.93     23721\n",
      "   macro avg       0.83      0.91      0.86     23721\n",
      "weighted avg       0.94      0.93      0.94     23721\n",
      "\n",
      "\n",
      "---------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for _tokenizer in ['razdel', 'TreebankWordTokenizer', 'rutokenizer']:\n",
    "    for i, _stopwords in enumerate(['fictitious', 'stopwords', 'list']):        \n",
    "        i_to_sw_name = {0: 'nltk', 1: 'spacy', 2: 'third_party_nltk'}\n",
    "        \n",
    "        with open(f'reviews_Review_Label_{_tokenizer}_{i_to_sw_name[i]}.df', 'rb') as file:\n",
    "            data = dill.load(file)\n",
    "            print(f\"Data was loaded from '{file.name}'\")\n",
    "        \n",
    "        print(f'{_tokenizer=}, stopwords={i_to_sw_name[i]}')\n",
    "        print(f'{data.shape=}\\n')\n",
    "        \n",
    "        \n",
    "        # Basic preprocessing\n",
    "        label_encoding = {\n",
    "            'POSITIVE': 2,\n",
    "            'NEUTRAL': 1,\n",
    "            'NEGATIVE': 0\n",
    "        }\n",
    "\n",
    "        data.label = data.label.apply(lambda label: label_encoding[label])\n",
    "        data = data[data.label != 1].reset_index().drop(columns=['index'])\n",
    "        train, test = train_test_split(data, test_size=0.3, random_state=42)\n",
    "        \n",
    "        # Balancing dataset\n",
    "        train = pd.concat([train, resample(train[train.label == 0], n_samples=41500, random_state=42)])\n",
    "        print(f'{train.shape=}')\n",
    "        \n",
    "        \n",
    "        print('CountVectorizer:')\n",
    "        cnt_vec = CountVectorizer(tokenizer=WhitespaceTokenizer().tokenize, max_df=0.6, max_features=10000)\n",
    "        X_train = cnt_vec.fit_transform(train.review)\n",
    "        X_test  = cnt_vec.transform(test.review)\n",
    "\n",
    "        clf = LogisticRegression(max_iter=200, n_jobs=-1)\n",
    "        clf.fit(X_train, train.label)\n",
    "        pred = clf.predict(X_test)\n",
    "\n",
    "        print(classification_report(test.label, pred))\n",
    "        \n",
    "        \n",
    "        print('\\nTfidfVectorizer:')\n",
    "        cnt_vec = TfidfVectorizer(tokenizer=WhitespaceTokenizer().tokenize, max_df=0.6, max_features=10000)\n",
    "        X_train = cnt_vec.fit_transform(train.review)\n",
    "        X_test  = cnt_vec.transform(test.review)\n",
    "\n",
    "        clf = LogisticRegression(max_iter=200, n_jobs=-1)\n",
    "        clf.fit(X_train, train.label)\n",
    "        pred = clf.predict(X_test)\n",
    "\n",
    "        print(classification_report(test.label, pred))\n",
    "        \n",
    "        print('\\n---------------------------------------------------------------\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c48cc1eb",
   "metadata": {},
   "source": [
    "### Experiment 4\n",
    "\n",
    "**Tokenizer:** [`razdel`, `TreebankWordTokenizer`, `rutokenizer`]\n",
    "\n",
    "**Stopwords:** [`nltk`, `spacy`, custom_list]\n",
    "\n",
    "**Model:** `LogisticRegression`\n",
    "\n",
    "**LogReg params**: \n",
    "* **solver =** 'saga'\n",
    "\n",
    "**Vectorizer:** `CountVectorizer`, `TfidfVectorizer`\n",
    "\n",
    "**Comments:** After balancing training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fdd768da",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data was loaded from 'reviews_Review_Label_razdel_nltk.df'\n",
      "_tokenizer='razdel', stopwords=nltk\n",
      "data.shape=(90646, 2)\n",
      "\n",
      "train.shape=(96846, 2)\n",
      "CountVectorizer:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.87      0.79      2979\n",
      "           2       0.98      0.95      0.97     20742\n",
      "\n",
      "    accuracy                           0.94     23721\n",
      "   macro avg       0.85      0.91      0.88     23721\n",
      "weighted avg       0.95      0.94      0.94     23721\n",
      "\n",
      "\n",
      "TfidfVectorizer:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.90      0.78      2979\n",
      "           2       0.98      0.94      0.96     20742\n",
      "\n",
      "    accuracy                           0.94     23721\n",
      "   macro avg       0.84      0.92      0.87     23721\n",
      "weighted avg       0.95      0.94      0.94     23721\n",
      "\n",
      "\n",
      "---------------------------------------------------------------\n",
      "\n",
      "Data was loaded from 'reviews_Review_Label_razdel_spacy.df'\n",
      "_tokenizer='razdel', stopwords=spacy\n",
      "data.shape=(90646, 2)\n",
      "\n",
      "train.shape=(96846, 2)\n",
      "CountVectorizer:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.86      0.78      2979\n",
      "           2       0.98      0.95      0.96     20742\n",
      "\n",
      "    accuracy                           0.94     23721\n",
      "   macro avg       0.85      0.91      0.87     23721\n",
      "weighted avg       0.95      0.94      0.94     23721\n",
      "\n",
      "\n",
      "TfidfVectorizer:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.89      0.77      2979\n",
      "           2       0.98      0.94      0.96     20742\n",
      "\n",
      "    accuracy                           0.93     23721\n",
      "   macro avg       0.83      0.92      0.87     23721\n",
      "weighted avg       0.95      0.93      0.94     23721\n",
      "\n",
      "\n",
      "---------------------------------------------------------------\n",
      "\n",
      "Data was loaded from 'reviews_Review_Label_razdel_third_party_nltk.df'\n",
      "_tokenizer='razdel', stopwords=third_party_nltk\n",
      "data.shape=(90646, 2)\n",
      "\n",
      "train.shape=(96846, 2)\n",
      "CountVectorizer:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.86      0.79      2979\n",
      "           2       0.98      0.95      0.97     20742\n",
      "\n",
      "    accuracy                           0.94     23721\n",
      "   macro avg       0.85      0.91      0.88     23721\n",
      "weighted avg       0.95      0.94      0.94     23721\n",
      "\n",
      "\n",
      "TfidfVectorizer:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.89      0.78      2979\n",
      "           2       0.98      0.94      0.96     20742\n",
      "\n",
      "    accuracy                           0.94     23721\n",
      "   macro avg       0.84      0.92      0.87     23721\n",
      "weighted avg       0.95      0.94      0.94     23721\n",
      "\n",
      "\n",
      "---------------------------------------------------------------\n",
      "\n",
      "Data was loaded from 'reviews_Review_Label_TreebankWordTokenizer_nltk.df'\n",
      "_tokenizer='TreebankWordTokenizer', stopwords=nltk\n",
      "data.shape=(90646, 2)\n",
      "\n",
      "train.shape=(96846, 2)\n",
      "CountVectorizer:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.79      0.76      2979\n",
      "           2       0.97      0.96      0.96     20742\n",
      "\n",
      "    accuracy                           0.94     23721\n",
      "   macro avg       0.85      0.88      0.86     23721\n",
      "weighted avg       0.94      0.94      0.94     23721\n",
      "\n",
      "\n",
      "TfidfVectorizer:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.86      0.75      2979\n",
      "           2       0.98      0.94      0.96     20742\n",
      "\n",
      "    accuracy                           0.93     23721\n",
      "   macro avg       0.82      0.90      0.85     23721\n",
      "weighted avg       0.94      0.93      0.93     23721\n",
      "\n",
      "\n",
      "---------------------------------------------------------------\n",
      "\n",
      "Data was loaded from 'reviews_Review_Label_TreebankWordTokenizer_spacy.df'\n",
      "_tokenizer='TreebankWordTokenizer', stopwords=spacy\n",
      "data.shape=(90646, 2)\n",
      "\n",
      "train.shape=(96846, 2)\n",
      "CountVectorizer:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.78      0.75      2979\n",
      "           2       0.97      0.96      0.96     20742\n",
      "\n",
      "    accuracy                           0.93     23721\n",
      "   macro avg       0.85      0.87      0.86     23721\n",
      "weighted avg       0.94      0.93      0.94     23721\n",
      "\n",
      "\n",
      "TfidfVectorizer:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.85      0.74      2979\n",
      "           2       0.98      0.93      0.96     20742\n",
      "\n",
      "    accuracy                           0.92     23721\n",
      "   macro avg       0.82      0.89      0.85     23721\n",
      "weighted avg       0.94      0.92      0.93     23721\n",
      "\n",
      "\n",
      "---------------------------------------------------------------\n",
      "\n",
      "Data was loaded from 'reviews_Review_Label_TreebankWordTokenizer_third_party_nltk.df'\n",
      "_tokenizer='TreebankWordTokenizer', stopwords=third_party_nltk\n",
      "data.shape=(90646, 2)\n",
      "\n",
      "train.shape=(96846, 2)\n",
      "CountVectorizer:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.78      0.75      2979\n",
      "           2       0.97      0.96      0.96     20742\n",
      "\n",
      "    accuracy                           0.94     23721\n",
      "   macro avg       0.85      0.87      0.86     23721\n",
      "weighted avg       0.94      0.94      0.94     23721\n",
      "\n",
      "\n",
      "TfidfVectorizer:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.86      0.75      2979\n",
      "           2       0.98      0.94      0.96     20742\n",
      "\n",
      "    accuracy                           0.93     23721\n",
      "   macro avg       0.82      0.90      0.85     23721\n",
      "weighted avg       0.94      0.93      0.93     23721\n",
      "\n",
      "\n",
      "---------------------------------------------------------------\n",
      "\n",
      "Data was loaded from 'reviews_Review_Label_rutokenizer_nltk.df'\n",
      "_tokenizer='rutokenizer', stopwords=nltk\n",
      "data.shape=(90646, 2)\n",
      "\n",
      "train.shape=(96846, 2)\n",
      "CountVectorizer:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.84      0.79      2979\n",
      "           2       0.98      0.96      0.97     20742\n",
      "\n",
      "    accuracy                           0.94     23721\n",
      "   macro avg       0.86      0.90      0.88     23721\n",
      "weighted avg       0.95      0.94      0.94     23721\n",
      "\n",
      "\n",
      "TfidfVectorizer:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.89      0.77      2979\n",
      "           2       0.98      0.94      0.96     20742\n",
      "\n",
      "    accuracy                           0.93     23721\n",
      "   macro avg       0.83      0.92      0.87     23721\n",
      "weighted avg       0.95      0.93      0.94     23721\n",
      "\n",
      "\n",
      "---------------------------------------------------------------\n",
      "\n",
      "Data was loaded from 'reviews_Review_Label_rutokenizer_spacy.df'\n",
      "_tokenizer='rutokenizer', stopwords=spacy\n",
      "data.shape=(90646, 2)\n",
      "\n",
      "train.shape=(96846, 2)\n",
      "CountVectorizer:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.83      0.77      2979\n",
      "           2       0.98      0.95      0.96     20742\n",
      "\n",
      "    accuracy                           0.94     23721\n",
      "   macro avg       0.85      0.89      0.87     23721\n",
      "weighted avg       0.94      0.94      0.94     23721\n",
      "\n",
      "\n",
      "TfidfVectorizer:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.89      0.77      2979\n",
      "           2       0.98      0.94      0.96     20742\n",
      "\n",
      "    accuracy                           0.93     23721\n",
      "   macro avg       0.83      0.91      0.87     23721\n",
      "weighted avg       0.94      0.93      0.94     23721\n",
      "\n",
      "\n",
      "---------------------------------------------------------------\n",
      "\n",
      "Data was loaded from 'reviews_Review_Label_rutokenizer_third_party_nltk.df'\n",
      "_tokenizer='rutokenizer', stopwords=third_party_nltk\n",
      "data.shape=(90646, 2)\n",
      "\n",
      "train.shape=(96846, 2)\n",
      "CountVectorizer:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.83      0.78      2979\n",
      "           2       0.98      0.96      0.97     20742\n",
      "\n",
      "    accuracy                           0.94     23721\n",
      "   macro avg       0.85      0.89      0.87     23721\n",
      "weighted avg       0.95      0.94      0.94     23721\n",
      "\n",
      "\n",
      "TfidfVectorizer:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.89      0.77      2979\n",
      "           2       0.98      0.94      0.96     20742\n",
      "\n",
      "    accuracy                           0.93     23721\n",
      "   macro avg       0.83      0.92      0.87     23721\n",
      "weighted avg       0.95      0.93      0.94     23721\n",
      "\n",
      "\n",
      "---------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for _tokenizer in ['razdel', 'TreebankWordTokenizer', 'rutokenizer']:\n",
    "    for i, _stopwords in enumerate(['fictitious', 'stopwords', 'list']):        \n",
    "        i_to_sw_name = {0: 'nltk', 1: 'spacy', 2: 'third_party_nltk'}\n",
    "        \n",
    "        with open(f'reviews_Review_Label_{_tokenizer}_{i_to_sw_name[i]}.df', 'rb') as file:\n",
    "            data = dill.load(file)\n",
    "            print(f\"Data was loaded from '{file.name}'\")\n",
    "        \n",
    "        print(f'{_tokenizer=}, stopwords={i_to_sw_name[i]}')\n",
    "        print(f'{data.shape=}\\n')\n",
    "        \n",
    "        \n",
    "        # Basic preprocessing\n",
    "        label_encoding = {\n",
    "            'POSITIVE': 2,\n",
    "            'NEUTRAL': 1,\n",
    "            'NEGATIVE': 0\n",
    "        }\n",
    "\n",
    "        data.label = data.label.apply(lambda label: label_encoding[label])\n",
    "        data = data[data.label != 1].reset_index().drop(columns=['index'])\n",
    "        train, test = train_test_split(data, test_size=0.3, random_state=42)\n",
    "        \n",
    "        # Balancing dataset\n",
    "        train = pd.concat([train, resample(train[train.label == 0], n_samples=41500, random_state=42)])\n",
    "        print(f'{train.shape=}')\n",
    "        \n",
    "        \n",
    "        print('CountVectorizer:')\n",
    "        cnt_vec = CountVectorizer(tokenizer=WhitespaceTokenizer().tokenize)\n",
    "        X_train = cnt_vec.fit_transform(train.review)\n",
    "        X_test  = cnt_vec.transform(test.review)\n",
    "\n",
    "        clf = LogisticRegression(max_iter=3000, n_jobs=-1, solver='saga')\n",
    "        clf.fit(X_train, train.label)\n",
    "        pred = clf.predict(X_test)\n",
    "\n",
    "        print(classification_report(test.label, pred))\n",
    "        \n",
    "        \n",
    "        print('\\nTfidfVectorizer:')\n",
    "        cnt_vec = TfidfVectorizer(tokenizer=WhitespaceTokenizer().tokenize)\n",
    "        X_train = cnt_vec.fit_transform(train.review)\n",
    "        X_test  = cnt_vec.transform(test.review)\n",
    "\n",
    "        clf = LogisticRegression(max_iter=200, n_jobs=-1, solver='saga')\n",
    "        clf.fit(X_train, train.label)\n",
    "        pred = clf.predict(X_test)\n",
    "\n",
    "        print(classification_report(test.label, pred))\n",
    "        \n",
    "        print('\\n---------------------------------------------------------------\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f48ba39c",
   "metadata": {},
   "source": [
    "### Experiment 5\n",
    "\n",
    "**Tokenizer:** [`razdel`, `TreebankWordTokenizer`, `rutokenizer`]\n",
    "\n",
    "**Stopwords:** [`nltk`, `spacy`, custom_list]\n",
    "\n",
    "**Model:** `LogisticRegression`\n",
    "\n",
    "**LogReg params**: \n",
    "* **solver =** 'liblinear'\n",
    "\n",
    "**Vectorizer:** `CountVectorizer`, `TfidfVectorizer`\n",
    "\n",
    "**Comments:** After balancing training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9fc83172",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data was loaded from 'reviews_Review_Label_razdel_nltk.df'\n",
      "_tokenizer='razdel', stopwords=nltk\n",
      "data.shape=(90646, 2)\n",
      "\n",
      "train.shape=(96846, 2)\n",
      "CountVectorizer:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1523: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.80      0.78      2979\n",
      "           2       0.97      0.96      0.97     20742\n",
      "\n",
      "    accuracy                           0.94     23721\n",
      "   macro avg       0.86      0.88      0.87     23721\n",
      "weighted avg       0.94      0.94      0.94     23721\n",
      "\n",
      "\n",
      "TfidfVectorizer:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1523: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.90      0.78      2979\n",
      "           2       0.98      0.94      0.96     20742\n",
      "\n",
      "    accuracy                           0.94     23721\n",
      "   macro avg       0.84      0.92      0.87     23721\n",
      "weighted avg       0.95      0.94      0.94     23721\n",
      "\n",
      "\n",
      "---------------------------------------------------------------\n",
      "\n",
      "Data was loaded from 'reviews_Review_Label_razdel_spacy.df'\n",
      "_tokenizer='razdel', stopwords=spacy\n",
      "data.shape=(90646, 2)\n",
      "\n",
      "train.shape=(96846, 2)\n",
      "CountVectorizer:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1523: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.79      0.77      2979\n",
      "           2       0.97      0.96      0.97     20742\n",
      "\n",
      "    accuracy                           0.94     23721\n",
      "   macro avg       0.86      0.87      0.87     23721\n",
      "weighted avg       0.94      0.94      0.94     23721\n",
      "\n",
      "\n",
      "TfidfVectorizer:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1523: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.89      0.77      2979\n",
      "           2       0.98      0.94      0.96     20742\n",
      "\n",
      "    accuracy                           0.93     23721\n",
      "   macro avg       0.83      0.92      0.87     23721\n",
      "weighted avg       0.95      0.93      0.94     23721\n",
      "\n",
      "\n",
      "---------------------------------------------------------------\n",
      "\n",
      "Data was loaded from 'reviews_Review_Label_razdel_third_party_nltk.df'\n",
      "_tokenizer='razdel', stopwords=third_party_nltk\n",
      "data.shape=(90646, 2)\n",
      "\n",
      "train.shape=(96846, 2)\n",
      "CountVectorizer:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1523: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.80      0.78      2979\n",
      "           2       0.97      0.96      0.97     20742\n",
      "\n",
      "    accuracy                           0.94     23721\n",
      "   macro avg       0.86      0.88      0.87     23721\n",
      "weighted avg       0.94      0.94      0.94     23721\n",
      "\n",
      "\n",
      "TfidfVectorizer:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1523: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.89      0.78      2979\n",
      "           2       0.98      0.94      0.96     20742\n",
      "\n",
      "    accuracy                           0.94     23721\n",
      "   macro avg       0.84      0.92      0.87     23721\n",
      "weighted avg       0.95      0.94      0.94     23721\n",
      "\n",
      "\n",
      "---------------------------------------------------------------\n",
      "\n",
      "Data was loaded from 'reviews_Review_Label_TreebankWordTokenizer_nltk.df'\n",
      "_tokenizer='TreebankWordTokenizer', stopwords=nltk\n",
      "data.shape=(90646, 2)\n",
      "\n",
      "train.shape=(96846, 2)\n",
      "CountVectorizer:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1523: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.76      0.75      2979\n",
      "           2       0.96      0.96      0.96     20742\n",
      "\n",
      "    accuracy                           0.94     23721\n",
      "   macro avg       0.86      0.86      0.86     23721\n",
      "weighted avg       0.94      0.94      0.94     23721\n",
      "\n",
      "\n",
      "TfidfVectorizer:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1523: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.86      0.75      2979\n",
      "           2       0.98      0.94      0.96     20742\n",
      "\n",
      "    accuracy                           0.93     23721\n",
      "   macro avg       0.82      0.90      0.85     23721\n",
      "weighted avg       0.94      0.93      0.93     23721\n",
      "\n",
      "\n",
      "---------------------------------------------------------------\n",
      "\n",
      "Data was loaded from 'reviews_Review_Label_TreebankWordTokenizer_spacy.df'\n",
      "_tokenizer='TreebankWordTokenizer', stopwords=spacy\n",
      "data.shape=(90646, 2)\n",
      "\n",
      "train.shape=(96846, 2)\n",
      "CountVectorizer:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1523: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.75      0.74      2979\n",
      "           2       0.96      0.96      0.96     20742\n",
      "\n",
      "    accuracy                           0.94     23721\n",
      "   macro avg       0.85      0.85      0.85     23721\n",
      "weighted avg       0.94      0.94      0.94     23721\n",
      "\n",
      "\n",
      "TfidfVectorizer:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1523: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.85      0.74      2979\n",
      "           2       0.98      0.93      0.96     20742\n",
      "\n",
      "    accuracy                           0.92     23721\n",
      "   macro avg       0.82      0.89      0.85     23721\n",
      "weighted avg       0.94      0.92      0.93     23721\n",
      "\n",
      "\n",
      "---------------------------------------------------------------\n",
      "\n",
      "Data was loaded from 'reviews_Review_Label_TreebankWordTokenizer_third_party_nltk.df'\n",
      "_tokenizer='TreebankWordTokenizer', stopwords=third_party_nltk\n",
      "data.shape=(90646, 2)\n",
      "\n",
      "train.shape=(96846, 2)\n",
      "CountVectorizer:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1523: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.75      0.75      2979\n",
      "           2       0.96      0.97      0.96     20742\n",
      "\n",
      "    accuracy                           0.94     23721\n",
      "   macro avg       0.86      0.86      0.86     23721\n",
      "weighted avg       0.94      0.94      0.94     23721\n",
      "\n",
      "\n",
      "TfidfVectorizer:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1523: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.86      0.75      2979\n",
      "           2       0.98      0.94      0.96     20742\n",
      "\n",
      "    accuracy                           0.93     23721\n",
      "   macro avg       0.82      0.90      0.85     23721\n",
      "weighted avg       0.94      0.93      0.93     23721\n",
      "\n",
      "\n",
      "---------------------------------------------------------------\n",
      "\n",
      "Data was loaded from 'reviews_Review_Label_rutokenizer_nltk.df'\n",
      "_tokenizer='rutokenizer', stopwords=nltk\n",
      "data.shape=(90646, 2)\n",
      "\n",
      "train.shape=(96846, 2)\n",
      "CountVectorizer:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1523: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.79      0.77      2979\n",
      "           2       0.97      0.96      0.97     20742\n",
      "\n",
      "    accuracy                           0.94     23721\n",
      "   macro avg       0.86      0.88      0.87     23721\n",
      "weighted avg       0.94      0.94      0.94     23721\n",
      "\n",
      "\n",
      "TfidfVectorizer:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1523: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.89      0.77      2979\n",
      "           2       0.98      0.94      0.96     20742\n",
      "\n",
      "    accuracy                           0.93     23721\n",
      "   macro avg       0.83      0.92      0.87     23721\n",
      "weighted avg       0.95      0.93      0.94     23721\n",
      "\n",
      "\n",
      "---------------------------------------------------------------\n",
      "\n",
      "Data was loaded from 'reviews_Review_Label_rutokenizer_spacy.df'\n",
      "_tokenizer='rutokenizer', stopwords=spacy\n",
      "data.shape=(90646, 2)\n",
      "\n",
      "train.shape=(96846, 2)\n",
      "CountVectorizer:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1523: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.78      0.76      2979\n",
      "           2       0.97      0.96      0.96     20742\n",
      "\n",
      "    accuracy                           0.94     23721\n",
      "   macro avg       0.86      0.87      0.86     23721\n",
      "weighted avg       0.94      0.94      0.94     23721\n",
      "\n",
      "\n",
      "TfidfVectorizer:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1523: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.89      0.77      2979\n",
      "           2       0.98      0.94      0.96     20742\n",
      "\n",
      "    accuracy                           0.93     23721\n",
      "   macro avg       0.83      0.91      0.87     23721\n",
      "weighted avg       0.94      0.93      0.94     23721\n",
      "\n",
      "\n",
      "---------------------------------------------------------------\n",
      "\n",
      "Data was loaded from 'reviews_Review_Label_rutokenizer_third_party_nltk.df'\n",
      "_tokenizer='rutokenizer', stopwords=third_party_nltk\n",
      "data.shape=(90646, 2)\n",
      "\n",
      "train.shape=(96846, 2)\n",
      "CountVectorizer:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1523: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.78      0.77      2979\n",
      "           2       0.97      0.96      0.97     20742\n",
      "\n",
      "    accuracy                           0.94     23721\n",
      "   macro avg       0.86      0.87      0.87     23721\n",
      "weighted avg       0.94      0.94      0.94     23721\n",
      "\n",
      "\n",
      "TfidfVectorizer:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1523: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.89      0.77      2979\n",
      "           2       0.98      0.94      0.96     20742\n",
      "\n",
      "    accuracy                           0.93     23721\n",
      "   macro avg       0.83      0.92      0.87     23721\n",
      "weighted avg       0.95      0.93      0.94     23721\n",
      "\n",
      "\n",
      "---------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for _tokenizer in ['razdel', 'TreebankWordTokenizer', 'rutokenizer']:\n",
    "    for i, _stopwords in enumerate(['fictitious', 'stopwords', 'list']):        \n",
    "        i_to_sw_name = {0: 'nltk', 1: 'spacy', 2: 'third_party_nltk'}\n",
    "        \n",
    "        with open(f'reviews_Review_Label_{_tokenizer}_{i_to_sw_name[i]}.df', 'rb') as file:\n",
    "            data = dill.load(file)\n",
    "            print(f\"Data was loaded from '{file.name}'\")\n",
    "        \n",
    "        print(f'{_tokenizer=}, stopwords={i_to_sw_name[i]}')\n",
    "        print(f'{data.shape=}\\n')\n",
    "        \n",
    "        \n",
    "        # Basic preprocessing\n",
    "        label_encoding = {\n",
    "            'POSITIVE': 2,\n",
    "            'NEUTRAL': 1,\n",
    "            'NEGATIVE': 0\n",
    "        }\n",
    "\n",
    "        data.label = data.label.apply(lambda label: label_encoding[label])\n",
    "        data = data[data.label != 1].reset_index().drop(columns=['index'])\n",
    "        train, test = train_test_split(data, test_size=0.3, random_state=42)\n",
    "        \n",
    "        # Balancing dataset\n",
    "        train = pd.concat([train, resample(train[train.label == 0], n_samples=41500, random_state=42)])\n",
    "        print(f'{train.shape=}')\n",
    "        \n",
    "        \n",
    "        print('CountVectorizer:')\n",
    "        cnt_vec = CountVectorizer(tokenizer=WhitespaceTokenizer().tokenize)\n",
    "        X_train = cnt_vec.fit_transform(train.review)\n",
    "        X_test  = cnt_vec.transform(test.review)\n",
    "\n",
    "        clf = LogisticRegression(max_iter=200, n_jobs=-1, solver='liblinear')\n",
    "        clf.fit(X_train, train.label)\n",
    "        pred = clf.predict(X_test)\n",
    "\n",
    "        print(classification_report(test.label, pred))\n",
    "        \n",
    "        \n",
    "        print('\\nTfidfVectorizer:')\n",
    "        cnt_vec = TfidfVectorizer(tokenizer=WhitespaceTokenizer().tokenize)\n",
    "        X_train = cnt_vec.fit_transform(train.review)\n",
    "        X_test  = cnt_vec.transform(test.review)\n",
    "\n",
    "        clf = LogisticRegression(max_iter=200, n_jobs=-1, solver='liblinear')\n",
    "        clf.fit(X_train, train.label)\n",
    "        pred = clf.predict(X_test)\n",
    "\n",
    "        print(classification_report(test.label, pred))\n",
    "        \n",
    "        print('\\n---------------------------------------------------------------\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4656dbe5",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46936faf",
   "metadata": {},
   "source": [
    "## Exploration of best configuration:\n",
    "**Model:** `LogisticRegression`\n",
    "\n",
    "**LogReg params**: \n",
    "* **class_weight =** 'balanced'\n",
    "\n",
    "**Vectorizer:** `CountVectorizer`\n",
    "\n",
    "**Comments:** Before balancing training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c3a003e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count vectorizing...\n",
      "Training logreg...\n",
      "Metrics:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.82      0.79      2979\n",
      "           2       0.97      0.96      0.97     20742\n",
      "\n",
      "    accuracy                           0.94     23721\n",
      "   macro avg       0.86      0.89      0.88     23721\n",
      "weighted avg       0.95      0.94      0.94     23721\n",
      "\n",
      "Wall time: 1min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "print('Count vectorizing...')\n",
    "cnt_vec = CountVectorizer(tokenizer=WhitespaceTokenizer().tokenize)\n",
    "X_train = cnt_vec.fit_transform(train.review)\n",
    "X_test  = cnt_vec.transform(test.review)\n",
    "\n",
    "print('Training logreg...')\n",
    "clf = LogisticRegression(max_iter=200, n_jobs=-1, class_weight='balanced')\n",
    "clf.fit(X_train, train.label)\n",
    "pred = clf.predict(X_test)\n",
    "\n",
    "print('Metrics:')\n",
    "print(classification_report(test.label, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "99640bcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "156990\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['!', '!!', '!!!', '!!!!', '!!!!!', '!!!!!!', '!!!!!!!', '!!!!!!!!',\n",
       "       '!!!.', '!!!..', '!!!...', '!!!?', '!!!???', '!!!…', '!!..',\n",
       "       '!!...', '!!?', '!!??', '!!???', '!!…', '!.', '!..', '!...', '!?',\n",
       "       '!?!', '!?!?', '!?..', '!?...', '!??', '!…'], dtype=object)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(cnt_vec.get_feature_names_out()))\n",
    "cnt_vec.get_feature_names_out()[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "64766f46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -1.72729855,   9.92304738,   8.13565024,  17.76516573,\n",
       "        11.65439003,   6.15047599,  14.63212419,  24.03645396,\n",
       "       -11.79088365,  11.54557455])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Just watching...\n",
    "clf.decision_function(X_train[:10])  # Confidence scores for each sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4f2e2912",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['одновременно', '100', 'поздний', 'превзойти', 'артур',\n",
       "       'невероятный', 'отличный', 'd', 'великолепно', 'довольный',\n",
       "       'редко', '10', 'безупречный', 'приятно', 'идеально', 'дыхание',\n",
       "       'высота', 'удивительно', 'темп', 'превосходный', 'впервые',\n",
       "       'оторваться', 'браво', 'бесподобный', '7', 'потрясать',\n",
       "       'однозначно', '9', '8', 'вера'], dtype=object)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt_vec.get_feature_names_out()[np.argpartition(clf.coef_[0], -30)[-30:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6f489674",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['недоумение', 'нелепо', 'разочаровать', 'неинтересный', 'увы',\n",
       "       'откровенно', 'разочарование', 'скучно', 'примитивный',\n",
       "       'досмотреть', 'фальшивый', 'скучный', 'бездарный', 'дешёвый',\n",
       "       'отвратительный', 'нудный', 'посредственный', 'унылый',\n",
       "       'восторженный', 'плоский', 'неприятно', 'переоценить', 'пустой',\n",
       "       '5', '0', '6', 'бред', 'глупо', '4', 'сожаление'], dtype=object)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt_vec.get_feature_names_out()[np.argpartition(clf.coef_[0], 30)[:30]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fd4b6487",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(156990,)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = np.array(np.sum(X_train, axis=0))[0]\n",
    "s.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1f905e3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.sort(s)[::-1][5000:])\n",
    "plt.xlabel('Token index in sorted feature list')\n",
    "plt.ylabel('The number of tokens in whole corpus')\n",
    "plt.title(\"Zipf's law illustration\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d9a0ad5",
   "metadata": {},
   "source": [
    "## What if binary encoding chosen?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dc6ddd8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count vectorizing...\n",
      "Training logreg...\n",
      "Metrics:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.79      0.78      2979\n",
      "           2       0.97      0.97      0.97     20742\n",
      "\n",
      "    accuracy                           0.94     23721\n",
      "   macro avg       0.87      0.88      0.87     23721\n",
      "weighted avg       0.94      0.94      0.94     23721\n",
      "\n",
      "Wall time: 49.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "with open(f'reviews_Review_Label_razdel_spacy.df', 'rb') as file:\n",
    "    data = dill.load(file)\n",
    "\n",
    "print('Count vectorizing...')\n",
    "cnt_vec = CountVectorizer(tokenizer=WhitespaceTokenizer().tokenize, binary=True)\n",
    "X_train = cnt_vec.fit_transform(train.review)\n",
    "X_test  = cnt_vec.transform(test.review)\n",
    "\n",
    "print('Training logreg...')\n",
    "clf = LogisticRegression(max_iter=200, n_jobs=-1, class_weight='balanced')\n",
    "clf.fit(X_train, train.label)\n",
    "pred = clf.predict(X_test)\n",
    "\n",
    "print('Metrics:')\n",
    "print(classification_report(test.label, pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
