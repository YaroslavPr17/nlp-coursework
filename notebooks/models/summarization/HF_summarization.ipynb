{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26b9aaa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/pristalovya/Документы/nlp-coursework\n"
     ]
    }
   ],
   "source": [
    "%cd ../.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da81c5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets_ import DatasetLoader\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from nltk.tokenize import WhitespaceTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a77cc8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/pristalovya/Документы/nlp-coursework/data/reviews_Review_FilmId.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>film_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>70061</th>\n",
       "      <td>Совсем недавно с удовольствием были просмотрен...</td>\n",
       "      <td>Майор Гром: Чумной Доктор</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47745</th>\n",
       "      <td>Очень давно хотелось посмотреть какое-нибудь о...</td>\n",
       "      <td>Пролетая над гнездом кукушки</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11306</th>\n",
       "      <td>&lt;b&gt;«&lt;i&gt;На данный момент мой адрес – это корабл...</td>\n",
       "      <td>Титаник</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24359</th>\n",
       "      <td>Отличная история в духе Диккинса, Фиджеральда ...</td>\n",
       "      <td>Престиж</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68937</th>\n",
       "      <td>Давно не смотрела таких фильмов: приключенческ...</td>\n",
       "      <td>Принц Персии: Пески времени</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6265</th>\n",
       "      <td>Искренность и непринуждённость '1+1' притягива...</td>\n",
       "      <td>1+1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54886</th>\n",
       "      <td>Давно хотела ознакомиться с жанром Кукольной а...</td>\n",
       "      <td>Остров собак</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76820</th>\n",
       "      <td>«Я должен верить в тот мир, который создает мо...</td>\n",
       "      <td>Мементо</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>Я не люблю фильмы о войне, но наверное нужно и...</td>\n",
       "      <td>Список Шиндлера</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15795</th>\n",
       "      <td>- Magical  Emma Watson\\r\\n\\r\\nВот и вышла в св...</td>\n",
       "      <td>Гарри Поттер и Дары Смерти: Часть II</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>77049 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review  \\\n",
       "70061  Совсем недавно с удовольствием были просмотрен...   \n",
       "47745  Очень давно хотелось посмотреть какое-нибудь о...   \n",
       "11306  <b>«<i>На данный момент мой адрес – это корабл...   \n",
       "24359  Отличная история в духе Диккинса, Фиджеральда ...   \n",
       "68937  Давно не смотрела таких фильмов: приключенческ...   \n",
       "...                                                  ...   \n",
       "6265   Искренность и непринуждённость '1+1' притягива...   \n",
       "54886  Давно хотела ознакомиться с жанром Кукольной а...   \n",
       "76820  «Я должен верить в тот мир, который создает мо...   \n",
       "860    Я не люблю фильмы о войне, но наверное нужно и...   \n",
       "15795  - Magical  Emma Watson\\r\\n\\r\\nВот и вышла в св...   \n",
       "\n",
       "                                    film_id  \n",
       "70061             Майор Гром: Чумной Доктор  \n",
       "47745          Пролетая над гнездом кукушки  \n",
       "11306                               Титаник  \n",
       "24359                               Престиж  \n",
       "68937           Принц Персии: Пески времени  \n",
       "...                                     ...  \n",
       "6265                                    1+1  \n",
       "54886                          Остров собак  \n",
       "76820                               Мементо  \n",
       "860                         Список Шиндлера  \n",
       "15795  Гарри Поттер и Дары Смерти: Часть II  \n",
       "\n",
       "[77049 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, test = DatasetLoader.load_reviews_Review_FilmId_dataset(\n",
    "    train_test_split=True,\n",
    "    test_size=0.15,\n",
    "    show_path=True\n",
    ")\n",
    "\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "41ab1386",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Майор Гром: Чумной Доктор', 'Пролетая над гнездом кукушки', 'Титаник', 'Престиж', 'Принц Персии: Пески времени', 'Криминальное чтиво', 'Дело храбрых', 'Вверх', 'Брат', 'Великий Гэтсби', 'Амели', 'Гарри Поттер и Принц-полукровка', 'Алиса в Стране чудес', 'Во тьме', 'Ученик чудовища', 'Звёздные войны: Эпизод 3 — Месть ситхов', 'Остров проклятых', 'Драйв', 'Начало', 'Револьвер', 'Мстители', 'Мгла', 'Привидение', 'Форрест Гамп', 'Вечное сияние чистого разума', 'Гарри Поттер и философский камень', 'Балто', 'Дэдпул', 'Сумерки', 'Темный рыцарь', 'Джентльмены', 'Королевство полной луны', 'Город героев', 'Молчание ягнят', 'Мать', 'Чернобыль', 'Бесславные ублюдки', 'Темный рыцарь: Возрождение легенды', 'Джокер', 'Оружейный барон', 'Человек-паук: Нет пути домой', 'Отец', '12 разгневанных мужчин', 'Ирония судьбы, или С легким паром!', '...А зори здесь тихие', 'Аватар', 'Олдбой', 'Лев', 'Дневник памяти', 'Помощники', 'Брестская крепость', 'Шоу Трумана', 'Бегущий по лезвию 2049', 'Догвилль', 'Достучаться до небес', 'Любовь и голуби', 'Дом, который построил Джек', 'Семь жизней', 'Довод', 'Хранители снов', 'Хатико: Самый верный друг', 'О чём говорят мужчины', 'Господин Никто', 'Король говорит!', 'Одаренная', 'Стражи Галактики. Часть 2', 'Очень страшное кино', 'Малышка на миллион', 'Трансформеры', 'Игра в имитацию', 'Интерстеллар', 'Изгой', 'Лига справедливости Зака Снайдера', 'Невидимая сторона', 'Общество мертвых поэтов', 'Игра на понижение', 'Американская история X', 'Лучшее предложение', 'Остров собак', 'Зверополис', 'История игрушек: Большой побег', 'Сплит', 'Мост в Терабитию', 'Старикам тут не место', 'Кавказская пленница, или Новые приключения Шурика', 'Отступники', 'Шрэк 2', 'Время', 'До встречи с тобой', 'Гарри Поттер и Орден Феникса', 'Чебурашка', 'Запах женщины', 'Собачье сердце', 'Гарри Поттер и Дары Смерти: Часть I', 'Леди и бродяга', 'Социальная сеть', 'Игры разума', 'Ледниковый период', 'Мстители: Война бесконечности', 'Паразиты', 'Список Шиндлера', 'Карнавальная ночь', 'Реквием по мечте', 'Как приручить дракона 2', 'Милые кости', '1+1', 'Однажды в… Голливуде', 'Большой куш', 'Исчезнувшая', 'Американский психопат', 'Как украсть миллион', 'Фантастические твари: Преступления Грин-де-Вальда', 'Зеленая миля', 'Легенда №17', 'В погоне за счастьем', 'Гарри Поттер и Дары Смерти: Часть II', 'Мальчишник в Вегасе', 'Одержимость', 'Остров сокровищ', 'Унесённые ветром', 'Военный ныряльщик', 'Головоломка', 'Кислота', 'Бэтмен', 'Гравити Фолз', 'Солнцестояние', 'Бойцовский клуб', 'Собор Парижской Богоматери', 'Аладдин', 'Гордость и предубеждение', 'Двухсотлетний человек', 'Ключ от всех дверей', 'Пианист', 'Ла-Ла Ленд', 'Бесстыжие', 'Заклятие', 'Знакомьтесь, Джо Блэк', 'Один дома', 'Рапунцель: Запутанная история', 'Поймай меня, если сможешь', 'Джанго освобожденный', 'Дьявол носит Prada', 'Моана', 'Пятьдесят оттенков серого', 'Война', 'Прислуга', 'Назад в будущее 3', 'Хоббит: Нежданное путешествие', 'Хоббит: Пустошь Смауга', 'Твоё имя', 'Леон', 'Ходячий замок', 'Рататуй', 'Быть человеком', 'Kingsman: Секретная служба', 'Братья по оружию', 'Летят журавли', 'Гладиатор', 'Храброе сердце', 'Области тьмы', 'Скиф', 'По соображениям совести', 'Москва слезам не верит', 'Дурак', 'Хороший, плохой, злой', 'Счастье в конверте', 'Алиса в Зазеркалье', 'Законопослушный гражданин', 'Человек-паук: Через вселенные', 'Люди в чёрном', 'Стражи Галактики', 'Брат 2', 'Белое солнце пустыни', 'Железный человек', 'Пленницы', 'Жизнь других', 'Волк с Уолл-стрит', 'Побег из Шоушенка', 'Игра престолов', 'Тебе стоило уйти', 'Человек, который изменил всё', 'Корпорация монстров', 'Назад в будущее', 'Загадочная история Бенджамина Баттона', 'Холодное сердце', 'Дикие истории', 'Глубокое синее море 2', 'Шрэк', 'Тот самый Мюнхгаузен', 'Стекло', 'Семь', 'Властелин колец: Возвращение короля', 'Залечь на дно в Брюгге', 'Zолушка', 'Счастливое число Слевина', 'Алеша Попович и Тугарин Змей', 'Пираты Карибского моря: Проклятие Черной жемчужины', 'Анастасия', 'Карты, деньги, два ствола', 'Формула любви', 'Властелин колец: Братство Кольца', 'Факультет', 'Ведьмина служба доставки', 'Алиса в городах', 'Джон Уик', 'Оторви и выбрось', 'Пираты Карибского моря: Сундук мертвеца', 'Песнь моря', 'Элвис', 'Как приручить дракона', 'Поиск', 'Она', 'Шестое чувство', 'Терминатор 2: Судный день', 'Билет на Vegas', 'Огонь', 'Шерлок Холмс и доктор Ватсон: Двадцатый век начинается', 'Омерзительная восьмерка', 'Круэлла', 'Апгрейд', 'Оно', 'ВАЛЛ·И', 'Психопаты', 'Миротворец', 'Лекарь: Ученик Авиценны', 'Джон Уик 2', 'Гарри Поттер и Тайная комната', 'Зеленая книга', 'Космос: Пространство и время', 'Тачки', 'Хоббит: Битва пяти воинств', 'Клуб Винкс — Школа волшебниц', 'Доктор Дулиттл 2', 'Мой сосед Тоторо', 'Крестный отец', 'Офицеры', 'Маленький принц', 'Вторая жизнь Уве', 'Отель «Гранд Будапешт»', 'Крым', 'Алиса', 'Реинкарнация', 'Гарри Поттер и узник Азкабана', 'Фантастические твари и где они обитают', 'Красное уведомление', 'Огни большого города', 'Вечные', 'Красотка', 'Мементо', 'Отпуск по обмену', 'Приключения Паддингтона 2', 'Жизнь прекрасна', 'Назад в будущее 2', 'Тайна Коко', 'Никто', 'В бой идут одни «старики»', '28 дней спустя', 'King’s Man: Начало', 'Родные', 'Иван Васильевич меняет профессию', 'Холодное сердце 2', 'Пираты Карибского моря: На краю света', 'Звёздные войны: Эпизод 5 — Империя наносит ответный удар', 'Чужие', 'Белый Бим Черное ухо', 'Душа', 'Семь психопатов', 'Белорусский вокзал', 'Песня остаётся всё такой же', 'Навсикая из долины ветров', 'Семнадцать мгновений весны', 'Варвар', 'Веном 2', 'Не смотрите наверх', 'Гамильтон', 'Скрытые фигуры', 'Пассажиры', 'Кролик Джоджо', 'Мстители: Финал', '101 далматинец', 'Терминал', 'Не может быть!', 'Человеческая многоножка', 'Крепкий орешек', 'Убойные каникулы', 'Русалочка', 'Человек дождя', 'Принцесса Мононоке', 'Батя', 'Крик', 'Эрнест и Селестина: Приключения мышки и медведя', 'Красавица и чудовище', 'Король Лев', 'Кошмар перед Рождеством', 'Как назвать эту любовь?', 'Прочь', 'Девчата', 'Приходи на меня посмотреть', 'Мулан', 'Игра', 'Путешествие к бессмертию', 'Максим Перепелица', 'Достать ножи', 'Славные парни', 'Пятый элемент', 'Нодамэ Кантабиле', 'Пункт назначения', 'Робокоп 3', 'Подольские курсанты', 'Гарри Поттер и Кубок огня', 'Мумия', 'Унесённые призраками', 'Дитя тьмы', 'Кин-дза-дза!', 'Невероятный мир глазами Энцо', 'Звёздные войны: Эпизод 6 — Возвращение Джедая', 'День сурка', 'Алиса знает, что делать!', 'Главный герой', 'Приключения Рокки и Буллвинкля', 'Большая игра', 'Мальчик в полосатой пижаме', 'Фабельманы', 'Чудо', 'Дьявол всегда здесь', 'Годзилла против Мегалона', 'Призрачная красота', 'Аватар: Легенда об Аанге', 'Дети кукурузы', 'Грязь', 'Алиса в стране чудес', 'Матрица', 'Гнев человеческий', 'RRR: Рядом ревёт революция', 'Двуязычный любовник', 'Стальной алхимик: Братство', 'Джон Уик 3', 'Молодой человек', 'Кит', 'Машина смерти', 'Ford против Ferrari', 'Образцовый самец', 'Аватар: Путь воды', 'Ханс Циммер: Live on Tour', 'Теория большого взрыва', 'Вавилон', 'Падал прошлогодний снег', 'Дитя тьмы: Первая жертва', 'Гарри Поттер 20 лет спустя: Возвращение в Хогвартс', 'Холодное лето пятьдесят третьего...', 'Последний танец', 'Сахар и перец', 'Дадли Справедливый', 'Не беспокойся, дорогая', 'Топ Ган: Мэверик', 'Анна', 'Папа, сдохни', 'В джазе только девушки', 'Астрал', 'Укрощение строптивого', 'Спасти рядового Райана', 'Пеле: Рождение легенды', 'Алиса знает, что делать! Зеленая месть', 'День курка', 'В поисках Немо', 'Вечера на хуторе близ Диканьки', 'Треугольник печали', 'Крестный отец 2', '12 стульев', 'Леший', 'Облачно с прояснениями', 'Тренер Картер', 'Мимино', 'Затемненная комната', 'Звёздные войны: Эпизод 1 — Скрытая угроза', 'Сядь за руль моей машины', 'Последний богатырь: Посланник Тьмы', 'Сердце пармы', 'Кот в сапогах', 'Чернобыль: Зона отчуждения. Финал', 'Судьба человека', 'Служебный роман', 'Земля будущего', 'Пара из будущего', 'Властелин колец: Две крепости', 'Операция «Ы» и другие приключения Шурика', 'Добро пожаловать, или Посторонним вход воспрещен', '1917', 'Жестокий романс', 'Игрушки', 'Убрать Картера', 'Спирит: Душа прерий', 'Падение Луны', 'Лило и Стич', 'Человек с бульвара Капуцинов', 'Кошки против собак', 'LEGO Супергерои Marvel: Мстители. Снова в сборе', 'Джентльмены удачи', 'Берегись автомобиля', 'Обыкновенное чудо', 'Мачеха', 'Елена в ящике', 'Бешенство', 'Алиса здесь больше не живет', 'Загадочное ночное убийство собаки', 'Ламборгини: Человек-легенда', 'Освобождение: Огненная дуга', 'Лето', 'Серый человек', 'О чём говорят мужчины. Простые удовольствия', 'Green Day: Пуля в Библии', 'Бриллиантовая рука', 'Они сражались за Родину', 'Живые твари', 'Морбиус', 'Платформа', 'Джузеппе Москати: Исцеляющая любовь', 'Берсерк', 'Аты-баты, шли солдаты...', 'Дюна', 'Трое из Простоквашино', 'Иди и смотри', 'Корабль смерти', 'Питер Пэн и Алиса в стране чудес', 'Праздника не будет', 'Райя и последний дракон', 'Шерлок Холмс и доктор Ватсон: Знакомство', 'Взаперти', 'Поднять Титаник', 'Таксист', 'Невыразимый ужас 2: Показания Рэндольфа Картера', 'Лэйк Плэсид: Озеро страха', 'Легенда', 'Реальные упыри', 'Возвращение в Салем', 'Доктор Лиза', 'Великая война', 'Самая обаятельная и привлекательная', 'Энканто', 'Моцарт. Рок-опера', 'Алиса и три медведя', 'Старые шишки', 'Огонь из преисподней', 'Лис и пёс', 'Собачья жизнь', 'За пивом!', 'Дальний космос', 'Черный ящик', 'Святой архипелаг', 'Каникулы', 'Не/смотря ни на что', 'Баллада Бастера Скраггса', 'Тар', 'Приключения Шерлока Холмса и доктора Ватсона: Собака Баскервилей', 'Замёрзший поцелуй', 'Один дома 2: Затерянный в Нью-Йорке', 'Бладшот', 'Герои Энвелла', 'В августе 44-го', 'Жил-был пёс', 'Рио Браво', 'Шазам!', 'Уиллард', 'Вам и не снилось...', 'Невидимый гость', 'Мужики!..', 'Многоэтажка', 'Точка кипения', 'Сестрёнка', 'Всё везде и сразу', 'Анчартед: На картах не значится', 'BBC: Планета Земля', 'Убийство на яхте', 'Алиса в Стране Чудес', 'Волки', 'Зверопой 2', 'Покровские ворота', 'Любовь напрокат', 'Я краснею', 'Чёрная Пантера: Ваканда навеки', 'Брошенный кролик', 'Коты-аристократы', 'Лулу и Бриггс', 'Идиократия', 'Сатанинские обряды Дракулы', 'Малышарики', 'Палмер', 'Мадагаскар', 'Никки, дьявол младший', 'Счастливые люди', 'Киборг 3: Переработчик', 'Истории в кино: Однажды в парке', 'Зависнуть в Палм-Спрингс', 'Мира', 'Черная вдова', 'Маленькие пальчики', 'Удача', 'Цирк «Бабочка»', 'Неувольняемый', 'Эксперимент Уиджи', 'Клубничная поляна', 'Волшебство Queen в Будапеште', 'Приключения Джо Грязнули', 'Лакричная пицца', 'Список Ланъя', 'Моя пиратская свадьба', 'Кот в сапогах 2: Последнее желание', 'Приключения Шерлока Холмса и доктора Ватсона: Охота на тигра', 'CODA: Ребенок глухих родителей', 'Алиса в Пограничье', 'Турбулентность 2: Страх полетов', 'Подельники', 'М3ГАН', 'Алиса, или Последний побег', 'Нюрнберг', 'Извержение', 'Алиса во дворце', 'Молчание ветчины', 'Камон Камон', 'Жаркое американское лето', 'Разборы фильмов от КиноПоиска', 'Решение уйти', 'Цена страха', 'Знакомство родителей', 'Кошмары', 'Робин Гуд', 'В диких условиях', 'Затерянный мир', 'Конец Евангелиона', 'Лучший друг человека', 'Голубая планета', 'Малиса в стране чудес', 'Человек-муравей и Оса: Квантомания', '365 дней', 'Говорят женщины', 'Его доисторическое прошлое', 'Маньяк-полицейский 2', 'Преступления будущего', 'После Янга', 'Сын', 'Смех и горе у Бела моря', 'Невыносимая тяжесть огромного таланта', 'Один настоящий день', 'Чёрный Адам', 'Африка', 'Нанятые для убийства', 'Queen: Дни наших жизней', 'Улыбка', 'Оклахома!', 'Крошка Молли', 'Вышка', 'Укрась прощальное утро цветами обещания', 'Призрак оперы в Королевском Алберт-холле', 'Черви', 'Меню', 'Банши Инишерина', 'Дом Франкенштейна', 'Творение Господне', 'Нет пути назад', 'Клаус', 'Гордость и предрассудки', 'На войне как на войне', 'Казнь', 'Между двумя ливнями', 'Две жизни Грея Эванса', 'Возмездие Макса Кибла', 'Монстры на каникулах: Трансформания', 'Джейн Эйр', 'Дебаг', 'КьюАй. Весьма интересно', 'Потрошитель разума', 'Эскортницы', 'Затерянный город', 'Мартовские иды', 'Там, где раки поют', 'Эра драконов', 'Голубая планета 2', 'Песок', 'Стальной рассвет', 'Южени', 'Алиса из Чхондама', 'Астероид', 'Молитва о гетмане Мазепе', 'Мальчик-оборотень и волшебный автобус', 'Эти муки любви', 'Романовы', 'Амазонки и гладиаторы', 'Коварный план Сюзан', 'Избранные', 'Эскортница', 'Конго', 'Headspace: Руководство по медитации', 'Страх «Икс»', 'Люби их всех', 'Последний клиент', 'Пропавшая', 'Елена и мужчины', 'Атлант расправил плечи: Часть 3', 'Аудиенция', 'Суббота, 14-е', 'Заложники', 'Рой', 'Смертельная игра', 'Дух Франкенштейна', 'Спокойной ночи, малыши', 'Море дьявола', 'Спермула', 'Осторожно! Дети играют', 'Приходящая няня', 'Отверженные: 25-ая годовщина мюзикла', '1:42:08: Человек и его автомобиль', 'Шоу Грязного Фрэнка', 'Страх как он есть', 'Сирена', 'Бродяга', 'Веселящий газ', 'Она обошлась с ним нечестно', 'Неумершие: Хроники боли', 'Планета Земля 2', 'Я на перемотке!', 'Подземелье', 'Яйцеголовые', 'Киборг', 'Боевой континент', 'Алиса и привидения', 'Чудеса с небес', 'Шерлок Холмс и доктор Ватсон: Сокровища Агры', 'Цена выживания', 'Крик 6', 'Святой', 'Повелитель кукол 5: Последняя глава', 'Исследуя секс', 'Алиса в стране кислоты', 'Три тысячи лет желаний', 'Джимми Нейтрон: Мальчик-гений', 'Могучие рейнджеры: Р.П.М.', 'Незваный гость', 'Создание игры «The Last of Us»', 'Табу', 'Здрасьте, я ваш папа!', 'Здоровый человек', 'Блич: Тысячелетняя кровавая война', 'Солнце моё', 'Улица полумесяца', 'Белка и Стрелка: Тайны космоса', 'Нерка. Рыба красная', 'Hot Wheels. За гранью воображения', 'Профиль', 'Крестный отец: Новелла для телевидения', 'Миссис Птеродактиль', 'Невозмутимые джентльмены', 'Поезд в ад', 'Алиса и букинист', 'Игра в убийство', 'Людское семя', 'Гранд тур', 'Пустошь', 'Клипмейкеры', 'Я — Грета', 'Амфибия', 'Болеро', 'Я предпочитаю рай', 'Внутренний страх', 'Американский огурчик', 'Ад кромешный', 'Марлоу', 'Алиса на море', 'Флот МакХэйла', 'Без обратного пути', 'Лорды раздевалки', 'Ханжа', 'Больные на голову', 'Выбор за нами', 'Алиса: Волнение', 'Посетитель', 'Счастливая любовь', 'Винни Пух и день забот', '13 жизней', 'Крутой район', 'Бадди Хатчинс', 'Хочу все знать!', 'На грани безумия', 'Планеты', 'Скажи, что это не так', 'У нас привидение!', 'Киберджек', 'Один из двух', 'Атака титанов: Выбор без сожалений', 'Плохие парни', 'Алиса в стране убийств', 'Тринадцать лун', 'Железное сердце', 'Маленький Никита', 'Столкновение', 'Российская империя', 'Жена богача', 'Аферисты', 'Река большого каймана', 'Французские секс-убийства', 'Эрнест едет в лагерь', 'Волшебное Рождество', 'Свободные отношения', 'Охотник на акул', 'Три ниндзя: Костяшки вверх', 'Врачебная мудрость', 'Наша планета', 'Лето в Коста-Рике', 'Земля: Один потрясающий день', 'Белки в деле', 'Под откос', 'Дикарь', 'Мэйбл за рулем', 'Умар ибн аль-Хаттаб', 'Кокаиновый медведь', 'Фантастические твари: Тайны Дамблдора', 'BBC: Замерзшая планета', 'Путеводитель по любви', 'Легенда о Лайле Клэр', 'Крид 3', 'Целуя Джессику Стейн', 'Я был коммунистом для ФБР', 'Алиса в стране Чудес', 'Дьявольское отродье', 'Принц и серфер', 'Москит', 'Лебединое озеро', 'Проигравший', 'Мертвые дети', 'Молодожены', 'Алиса и мэр', 'Безрассудная', 'Алиса в стране порночудес', 'Амазонки', 'Округ Мэдисон', 'Лекс и Плу: Космические таксисты', 'Большое похищение Парсонсов', 'Доктор Стрэндж: В мультивселенной безумия', 'Поехавшая', 'Освобождение: Последний штурм', 'Хроника затмения', 'Бегущий человек', 'Комната 205', 'Пусть они будут нежными (Распутница 2)', 'Не оглядываясь назад', 'На краю', 'Отцы и сыновья', 'Гарвардская тусовка', 'Последний из достойнейших', 'Озарение', 'Срочное погружение 2', 'Звери в миниатюре', 'Винни-Пух: Кровь и мёд', 'Алиса на рыбалке', 'Робот против мумии ацтеков', 'Джерри и Том', 'Ферма Кларксона', 'Стол для пятерых', 'Алиса вверх тормашками', 'Черная дыра', 'Реквием мафии', 'Могучие рейнджеры: Космический патруль Дельта', 'Теперь ты на флоте', 'Морлоки', 'Демон снов', 'ЦРУ: Операция «Алекса»', 'Дом на 92-ой улице', 'Ласточки Христовы']\n"
     ]
    }
   ],
   "source": [
    "print(train.film_id.unique().tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e78f57a0",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1e34e7b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following encoder weights were not tied to the decoder ['bert/pooler']\n",
      "The following encoder weights were not tied to the decoder ['bert/pooler']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\" зеленая миля \", или что смотреть в новом фильме\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "MODEL_NAME = \"dmitry-vorobiev/rubert_ria_headlines\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(MODEL_NAME)\n",
    "\n",
    "text = \"Период конца девяностых годов-начало двухтысячных подарил нам большое количество великолепных и качественных кинолент, которые до сегодняшнего дня мы пересматриваем и каждый раз получаем удовольствие, 'Зелёная миля' режиссёра Фрэнка Дарабонта как раз из тех фильмов, и который я также совсем недавно пересмотрел. Фильм снят по мотивам романа Стивена Кинга 'Зеленая Миля'. \\r\\n\\r\\n   Главную роль исполнил легендарный Том Хэнкс, который давно уже вошёл в список Голливуда как один из лучших харизматичных и талантливых актёров. События в картине разворачиваются в 1935 году, Том иполнил роля начальника тюремного блока смертников по имени Пол Эджкомб. Работа не самая приятная, так как каждый день приходится иметь дело с омерзительными личностями, сидящими в тюремных камерах, хотя не все эти личности и омерзительные, некоторые из выглядят вполне нормальными людьми, но никогда не знаешь о чём они думают, ведь всё же эти люди совершили убийства, а у Пола также есть проблем со здоровьем. \\r\\n\\r\\nВсё меняется, когда в один из дней в тюрьму привозят гиганта Джона Коффи (Майкл Кларк Дункан), и с того самого момента для Пола и его коллег по работе много в жизни изменится.\\r\\n\\r\\nАтмосфера фильма выдержана на высоком уровне, тюремный блок, камеры, заключенные - вс по минимуму, но это и придаёт фильму свою мрачную атмосферу. \\r\\n\\r\\n Фильм можно отнести к драме, к более глубокой и осмысленной драме, так как фильм затрагивает несколько важных жизненных аспектов, в фильме также имеются и смешные моменты, и грустные моменты, и неприятные моменты. Каждый персонаж обладает своим уникальным характером, в особенности тюремщики. Из них отмечу Майкла Кларка Дункана (покойся  миром), Майкла Джитера, исполнивший роль Эдуарда Делокруа, приручившего ручного мышонка, Сэма Рокуэлла.  \\r\\n\\r\\nСреди надзирателей, это конечно же Том Хэнкс, Том - великолпный актёр, ни раз я в этом убеждаюсь. В этом фильме он имел особую связь с Джоном Коффи, в к нему в напарниках были: Дэвид Морс, Барри Пеппер, Джеффри ДеМанн, Джеймс Кромуэлл, и конечно же самый противный персонаж - это персонаж Перси, роль которого исполнил Даг Хатчисон. Среди женского состава - Бонни Хант, исполнившая роль жены Пола и Патришиа Кларксон, которая сыграл роль больной жены начальника тюрьмы (Джеймс Кромуэлл).\\r\\n\\r\\n   Несмотря на очень долгую продолжительность фильма, фильм не кажется затянутым и смотрится на одном дыхании и держит в напряжении, за персонажами интересно наблюдать.\\r\\n\\r\\n Концовка фильма тоже заставляет о многом задуматься и оставляет после себя немало размышлений, и в тоже время заставляет немного ужаснуться. \\r\\n\\r\\n   'Зелёная миля' - шедевр, которого уже никогда не будет, фильм, занесённый в золотой список кинематографа.\"\n",
    "\n",
    "encoded_batch = tokenizer.prepare_seq2seq_batch(\n",
    "    [text, text, text],\n",
    "    return_tensors=\"pt\",\n",
    "    padding=\"max_length\",\n",
    "    truncation=True,\n",
    "    max_length=512)\n",
    "\n",
    "output_ids = model.generate(\n",
    "    input_ids=encoded_batch[\"input_ids\"],\n",
    "    max_length=100,\n",
    "    no_repeat_ngram_size=3,\n",
    "    num_beams=5,\n",
    "    top_k=0\n",
    ")\n",
    "\n",
    "headline = tokenizer.decode(output_ids[0], \n",
    "                            skip_special_tokens=True, \n",
    "                            clean_up_tokenization_spaces=False)\n",
    "print(headline)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dd89424a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id=435, reviews.shape=(474,)\n",
      "\" зеленая миля \" дарабонта о \" зеленои миле \"\n",
      "id=329, reviews.shape=(420,)\n",
      "\" список шиндлера \"\n",
      "id=326, reviews.shape=(590,)\n",
      "\" побег из шоушенка \" : надежда, надежда и надежда\n",
      "id=32898, reviews.shape=(592,)\n",
      "\" достучаться до небес \". треилер фильма о мечте\n",
      "id=448, reviews.shape=(500,)\n",
      "форрест гамп'наивен\n",
      "id=679486, reviews.shape=(151,)\n",
      "что смотреть в день мертвых. треилер фильма \" оскар \"\n",
      "id=3498, reviews.shape=(245,)\n",
      "\" ты - репортер \" : \" ты – репортер \"\n",
      "id=258687, reviews.shape=(1254,)\n",
      "интерстеллар. фильм интерстелля\n",
      "id=342, reviews.shape=(329,)\n",
      "криминальное чтиво. треилер фильма тарантино\n",
      "id=476, reviews.shape=(206,)\n",
      "\" назад в будущее \" роберта земекиса\n",
      "id=328, reviews.shape=(270,)\n",
      "\" властелин колец \" и \" властелина колец \"\n",
      "id=361, reviews.shape=(742,)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilm_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mreviews\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m=}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(reviews)\n\u001b[0;32m----> 5\u001b[0m encoded_batch \u001b[38;5;241m=\u001b[39m \u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprepare_seq2seq_batch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_length\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtruncation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m512\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m output_ids \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mgenerate(\n\u001b[1;32m     13\u001b[0m     input_ids\u001b[38;5;241m=\u001b[39mencoded_batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     14\u001b[0m     max_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     17\u001b[0m     top_k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     18\u001b[0m )\n\u001b[1;32m     20\u001b[0m headline \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mdecode(output_ids[\u001b[38;5;241m0\u001b[39m], \n\u001b[1;32m     21\u001b[0m                             skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \n\u001b[1;32m     22\u001b[0m                             clean_up_tokenization_spaces\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/Inter/linux_packages/anaconda3/envs/nlp/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3713\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.prepare_seq2seq_batch\u001b[0;34m(self, src_texts, tgt_texts, max_length, max_target_length, padding, return_tensors, truncation, **kwargs)\u001b[0m\n\u001b[1;32m   3711\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m max_length \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3712\u001b[0m     max_length \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_max_length\n\u001b[0;32m-> 3713\u001b[0m model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3714\u001b[0m \u001b[43m    \u001b[49m\u001b[43msrc_texts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3715\u001b[0m \u001b[43m    \u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   3716\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3717\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3718\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3719\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtruncation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtruncation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3720\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3721\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3722\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tgt_texts \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3723\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model_inputs\n",
      "File \u001b[0;32m~/Inter/linux_packages/anaconda3/envs/nlp/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2523\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.__call__\u001b[0;34m(self, text, text_pair, text_target, text_pair_target, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2521\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_in_target_context_manager:\n\u001b[1;32m   2522\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_switch_to_input_mode()\n\u001b[0;32m-> 2523\u001b[0m     encodings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_one\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_pair\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext_pair\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mall_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m text_target \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2525\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_switch_to_target_mode()\n",
      "File \u001b[0;32m~/Inter/linux_packages/anaconda3/envs/nlp/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2609\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase._call_one\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2604\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2605\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch length of `text`: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(text)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not match batch length of `text_pair`:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2606\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(text_pair)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2607\u001b[0m         )\n\u001b[1;32m   2608\u001b[0m     batch_text_or_text_pairs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(text, text_pair)) \u001b[38;5;28;01mif\u001b[39;00m text_pair \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m text\n\u001b[0;32m-> 2609\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_encode_plus\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2610\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_text_or_text_pairs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_text_or_text_pairs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2611\u001b[0m \u001b[43m        \u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madd_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2612\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2613\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtruncation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtruncation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2614\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2615\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstride\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2616\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_split_into_words\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_split_into_words\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2617\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2618\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2619\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2620\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2621\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2622\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2623\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2624\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2625\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2626\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2627\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2628\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2629\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencode_plus(\n\u001b[1;32m   2630\u001b[0m         text\u001b[38;5;241m=\u001b[39mtext,\n\u001b[1;32m   2631\u001b[0m         text_pair\u001b[38;5;241m=\u001b[39mtext_pair,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2647\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   2648\u001b[0m     )\n",
      "File \u001b[0;32m~/Inter/linux_packages/anaconda3/envs/nlp/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2800\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.batch_encode_plus\u001b[0;34m(self, batch_text_or_text_pairs, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2790\u001b[0m \u001b[38;5;66;03m# Backward compatibility for 'truncation_strategy', 'pad_to_max_length'\u001b[39;00m\n\u001b[1;32m   2791\u001b[0m padding_strategy, truncation_strategy, max_length, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_padding_truncation_strategies(\n\u001b[1;32m   2792\u001b[0m     padding\u001b[38;5;241m=\u001b[39mpadding,\n\u001b[1;32m   2793\u001b[0m     truncation\u001b[38;5;241m=\u001b[39mtruncation,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2797\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   2798\u001b[0m )\n\u001b[0;32m-> 2800\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_batch_encode_plus\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2801\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_text_or_text_pairs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_text_or_text_pairs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2802\u001b[0m \u001b[43m    \u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madd_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2803\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpadding_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2804\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtruncation_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtruncation_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2805\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2806\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstride\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2807\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_split_into_words\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_split_into_words\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2808\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2809\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2810\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2811\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2812\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2813\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2814\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2815\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2816\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2817\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2818\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Inter/linux_packages/anaconda3/envs/nlp/lib/python3.10/site-packages/transformers/tokenization_utils_fast.py:429\u001b[0m, in \u001b[0;36mPreTrainedTokenizerFast._batch_encode_plus\u001b[0;34m(self, batch_text_or_text_pairs, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose)\u001b[0m\n\u001b[1;32m    420\u001b[0m \u001b[38;5;66;03m# Set the truncation and padding strategy and restore the initial configuration\u001b[39;00m\n\u001b[1;32m    421\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_truncation_and_padding(\n\u001b[1;32m    422\u001b[0m     padding_strategy\u001b[38;5;241m=\u001b[39mpadding_strategy,\n\u001b[1;32m    423\u001b[0m     truncation_strategy\u001b[38;5;241m=\u001b[39mtruncation_strategy,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    426\u001b[0m     pad_to_multiple_of\u001b[38;5;241m=\u001b[39mpad_to_multiple_of,\n\u001b[1;32m    427\u001b[0m )\n\u001b[0;32m--> 429\u001b[0m encodings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode_batch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    430\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_text_or_text_pairs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    431\u001b[0m \u001b[43m    \u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madd_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    432\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_pretokenized\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_split_into_words\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    433\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    435\u001b[0m \u001b[38;5;66;03m# Convert encoding to dict\u001b[39;00m\n\u001b[1;32m    436\u001b[0m \u001b[38;5;66;03m# `Tokens` has type: Tuple[\u001b[39;00m\n\u001b[1;32m    437\u001b[0m \u001b[38;5;66;03m#                       List[Dict[str, List[List[int]]]] or List[Dict[str, 2D-Tensor]],\u001b[39;00m\n\u001b[1;32m    438\u001b[0m \u001b[38;5;66;03m#                       List[EncodingFast]\u001b[39;00m\n\u001b[1;32m    439\u001b[0m \u001b[38;5;66;03m#                    ]\u001b[39;00m\n\u001b[1;32m    440\u001b[0m \u001b[38;5;66;03m# with nested dimensions corresponding to batch, overflows, sequence length\u001b[39;00m\n\u001b[1;32m    441\u001b[0m tokens_and_encodings \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    442\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_encoding(\n\u001b[1;32m    443\u001b[0m         encoding\u001b[38;5;241m=\u001b[39mencoding,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    452\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m encoding \u001b[38;5;129;01min\u001b[39;00m encodings\n\u001b[1;32m    453\u001b[0m ]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for film_id in data.film_id.unique():\n",
    "    reviews = data[data.film_id == film_id].review\n",
    "    print(f'id={film_id}, {reviews.shape=}')\n",
    "    text = ' '.join(reviews)\n",
    "    encoded_batch = tokenizer.prepare_seq2seq_batch(\n",
    "        [text],\n",
    "        return_tensors=\"pt\",\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=512)\n",
    "\n",
    "    output_ids = model.generate(\n",
    "        input_ids=encoded_batch[\"input_ids\"],\n",
    "        max_length=100,\n",
    "        no_repeat_ngram_size=3,\n",
    "        num_beams=5,\n",
    "        top_k=0\n",
    "    )\n",
    "\n",
    "    headline = tokenizer.decode(output_ids[0], \n",
    "                                skip_special_tokens=True, \n",
    "                                clean_up_tokenization_spaces=False)\n",
    "    print(headline)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef29482",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9b0c5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, T5ForConditionalGeneration\n",
    "\n",
    "model_name = \"IlyaGusev/rut5_base_headline_gen_telegram\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "366e4238",
   "metadata": {},
   "outputs": [],
   "source": [
    "# article_text = \"Период конца девяностых годов-начало двухтысячных подарил нам большое количество великолепных и качественных кинолент, которые до сегодняшнего дня мы пересматриваем и каждый раз получаем удовольствие, 'Зелёная миля' режиссёра Фрэнка Дарабонта как раз из тех фильмов, и который я также совсем недавно пересмотрел. Фильм снят по мотивам романа Стивена Кинга 'Зеленая Миля'. \\r\\n\\r\\n   Главную роль исполнил легендарный Том Хэнкс, который давно уже вошёл в список Голливуда как один из лучших харизматичных и талантливых актёров. События в картине разворачиваются в 1935 году, Том иполнил роля начальника тюремного блока смертников по имени Пол Эджкомб. Работа не самая приятная, так как каждый день приходится иметь дело с омерзительными личностями, сидящими в тюремных камерах, хотя не все эти личности и омерзительные, некоторые из выглядят вполне нормальными людьми, но никогда не знаешь о чём они думают, ведь всё же эти люди совершили убийства, а у Пола также есть проблем со здоровьем. \\r\\n\\r\\nВсё меняется, когда в один из дней в тюрьму привозят гиганта Джона Коффи (Майкл Кларк Дункан), и с того самого момента для Пола и его коллег по работе много в жизни изменится.\\r\\n\\r\\nАтмосфера фильма выдержана на высоком уровне, тюремный блок, камеры, заключенные - вс по минимуму, но это и придаёт фильму свою мрачную атмосферу. \\r\\n\\r\\n Фильм можно отнести к драме, к более глубокой и осмысленной драме, так как фильм затрагивает несколько важных жизненных аспектов, в фильме также имеются и смешные моменты, и грустные моменты, и неприятные моменты. Каждый персонаж обладает своим уникальным характером, в особенности тюремщики. Из них отмечу Майкла Кларка Дункана (покойся  миром), Майкла Джитера, исполнивший роль Эдуарда Делокруа, приручившего ручного мышонка, Сэма Рокуэлла.  \\r\\n\\r\\nСреди надзирателей, это конечно же Том Хэнкс, Том - великолпный актёр, ни раз я в этом убеждаюсь. В этом фильме он имел особую связь с Джоном Коффи, в к нему в напарниках были: Дэвид Морс, Барри Пеппер, Джеффри ДеМанн, Джеймс Кромуэлл, и конечно же самый противный персонаж - это персонаж Перси, роль которого исполнил Даг Хатчисон. Среди женского состава - Бонни Хант, исполнившая роль жены Пола и Патришиа Кларксон, которая сыграл роль больной жены начальника тюрьмы (Джеймс Кромуэлл).\\r\\n\\r\\n   Несмотря на очень долгую продолжительность фильма, фильм не кажется затянутым и смотрится на одном дыхании и держит в напряжении, за персонажами интересно наблюдать.\\r\\n\\r\\n Концовка фильма тоже заставляет о многом задуматься и оставляет после себя немало размышлений, и в тоже время заставляет немного ужаснуться. \\r\\n\\r\\n   'Зелёная миля' - шедевр, которого уже никогда не будет, фильм, занесённый в золотой список кинематографа.\"\n",
    "\n",
    "# input_ids = tokenizer(\n",
    "#     [article_text],\n",
    "#     max_length=600,\n",
    "#     add_special_tokens=True,\n",
    "#     padding=\"max_length\",\n",
    "#     truncation=True,\n",
    "#     return_tensors=\"pt\"\n",
    "# )[\"input_ids\"]\n",
    "\n",
    "# output_ids = model.generate(\n",
    "#     input_ids=input_ids\n",
    "# )[0]\n",
    "\n",
    "# headline = tokenizer.decode(output_ids, skip_special_tokens=True)\n",
    "# print(headline)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "649241e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id=435, reviews.shape=(474,)\n",
      "tensor([[    2,   475,  5121,   685,   261,   259,  2385,   259,   396,   259,\n",
      "         14852,   308,   475,  2662,  6090,   259,   279,   388,  4892,     1],\n",
      "        [    2,   430,  5121,   685,   261,   259,  2385,   259,   396,   259,\n",
      "         14852,   308,   475,  2662,  6090,   259,   279,   388,  4892,     1],\n",
      "        [    2,   475,  5121,   685,   261,   259,  2385,   259,   396,   259,\n",
      "         14852,   308,   475,  2662,  6090,     1,     0,     0,     0,     0]])\n",
      "<unk> 10 фильмов, которые я смотрела 10 лет назад и сейчас</s>\n",
      "<unk> 5 фильмов, которые я смотрела 10 лет назад и сейчас</s>\n",
      "<unk> 10 фильмов, которые я смотрела 10 лет назад</s><pad><pad><pad><pad>\n",
      "id=329, reviews.shape=(420,)\n",
      "tensor([[    2,   259, 11886, 11262,   992,  5779,  5121,   433,   404,  1032,\n",
      "          8175,  1172, 23236,   902, 20485,   436,     1,     0,     0],\n",
      "        [    2,   259, 11886, 11262,   992,  5779,  5121,   433,   607,  2202,\n",
      "             1,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [    2,   259, 11886, 11262,   992,  5779,  5121,   433,   404,  1032,\n",
      "          8175,  1172, 23236,   902, 20485,   436,   607,  2202,     1]])\n",
      "<unk> Лучшие военные фильмы «Список Шиндлера»</s><pad><pad>\n",
      "<unk> Лучшие военные фильмы 2019 года</s><pad><pad><pad><pad><pad><pad><pad><pad>\n",
      "<unk> Лучшие военные фильмы «Список Шиндлера» 2019 года</s>\n",
      "id=326, reviews.shape=(590,)\n",
      "tensor([[    2,   404,  4229, 13261,   729, 10748, 13047, 15359,   436,   322,\n",
      "           475,   259,  4979,   777,  5121,   685,   374,   315, 10097,  4497,\n",
      "           748],\n",
      "        [    2,   404,  4229, 13261,   729, 10748, 13047, 15359,   436,   322,\n",
      "           259,  4979,  1004,  5121,   374,   315, 10097,  4497,   748, 29462,\n",
      "           308],\n",
      "        [    2,   475,   259,  4979,   777,  5121,   685,   374,   315, 10097,\n",
      "          4497,   748, 29462,   308,     1,     0,     0,     0,     0,     0,\n",
      "             0]])\n",
      "<unk> «Побег из Шоушенка» – 10 лучших фильмов за всю историю\n",
      "<unk> «Побег из Шоушенка» – лучший фильм за всю историю кинематографа\n",
      "<unk> 10 лучших фильмов за всю историю кинематографа</s><pad><pad><pad><pad><pad><pad>\n",
      "id=32898, reviews.shape=(592,)\n",
      "tensor([[    2,   430,  5121,   685,   261,   259,  2385,  9568,  3891,   992,\n",
      "          2542,  3703,   893,   259, 15952,  1674,   259,   279,  1029,  1802,\n",
      "             1],\n",
      "        [    2,   259, 16257,   259,   411, 16345,   324,   261,   259,   411,\n",
      "          6258,   324,   261,   259,   411,  6258,   324,   261,   259,   411,\n",
      "          6258],\n",
      "        [    2,   404, 10073,  7066,  1582,  2451,   610, 21213,   436,   661,\n",
      "          5121,   259,   411, 16345,   324,   261,   259,   411,  6258,   324,\n",
      "           261]])\n",
      "<unk> 5 фильмов, которые спасают во время особого уныния и тоски</s>\n",
      "<unk> Фильм о мечте, о свободе, о свободе, о свобод\n",
      "<unk> «Достучаться до небес» — фильм о мечте, о свободе,\n",
      "id=448, reviews.shape=(500,)\n",
      "tensor([[    2,   404, 24446, 19588, 26531,   995,   436,   661,   259,  4979,\n",
      "          1004,  5121,   374,  1229,   748, 16233, 17993,   259,   279, 25004,\n",
      "         17668],\n",
      "        [    2,   259, 16257,   404, 24446, 19588, 26531,   995,   436,   661,\n",
      "           259,  4979,  1004,  5121,   374,  1229,   748, 16233, 17993,   259,\n",
      "           279],\n",
      "        [    2,   404, 24446, 19588, 26531,   995,   436,   661,   259,  4979,\n",
      "          1004,  5121,   259,   735,  1132,   605,     1,     0,     0,     0,\n",
      "             0]])\n",
      "<unk> «Форрест Гамп» — лучший фильм за свою искренность и неподдель\n",
      "<unk> Фильм «Форрест Гамп» — лучший фильм за свою искренность и\n",
      "<unk> «Форрест Гамп» — лучший фильм для всех</s><pad><pad><pad><pad>\n",
      "id=679486, reviews.shape=(151,)\n",
      "tensor([[    2, 12805,  3706,   259,   507, 20108,   685,   261,   259,  2385,\n",
      "           259,   396,   259, 14852,   308,   374,  5449,  1275,   401,  3742,\n",
      "          2662],\n",
      "        [    2, 12805,  3285,   259,  4979,   777,   259,   507, 20108,   685,\n",
      "           261,   259,  2385,   259,   396,   259, 14852,   308,   374,  5449,\n",
      "          1275],\n",
      "        [    2,   259, 20757,  3706,   259,  4979,   777,   259,   507, 20108,\n",
      "           685, 12542,   279,   259,   277,   559,  2517,   372,   277,     1,\n",
      "             0]])\n",
      "<unk> Топ-10 мультфильмов, которые я смотрела за последние несколько лет\n",
      "<unk> Топ-5 лучших мультфильмов, которые я смотрела за последние\n",
      "<unk> ТОП-10 лучших мультфильмов студии 'Pixar'</s><pad>\n",
      "id=3498, reviews.shape=(245,)\n",
      "tensor([[    2,   259, 13192,   259, 11346,   259,   277, 20864,  9094,   558,\n",
      "          9562,  1438,   277,  3472,   401,   374, 14489,  2058,     1,     0],\n",
      "        [    2,   259, 13192,   259, 11346,   259,   277, 20864,  9094,   558,\n",
      "          9562,  1438,   277,  3472,   401,   374, 14489,  2058,   291,     1],\n",
      "        [    2,   259, 13192,   259, 11346,   259,   277, 20864,  9094,   558,\n",
      "          9562,  1438,  2311,  3472,   401,   374, 14489,  2058,     1,     0]])\n",
      "<unk> Почему история 'Властелина колец' меня не зацепила</s><pad>\n",
      "<unk> Почему история 'Властелина колец' меня не зацепила?</s>\n",
      "<unk> Почему история 'Властелина колец'' меня не зацепила</s><pad>\n",
      "id=258687, reviews.shape=(1254,)\n",
      "tensor([[    2,   430,   259,  4979,   777,  5121,   685,  1894, 12271,   261,\n",
      "           259,  2385,   259,   396,   259, 14852,   630,  2662,  6090,     1,\n",
      "             0],\n",
      "        [    2,   430,   259,  4979,   777,  5121,   685,  1894, 12271,   261,\n",
      "           259,  2385,   259,   396,   259, 14852,   315,  3216,  1296,  1151,\n",
      "             1],\n",
      "        [    2,   430,   259,  4979,   777,  5121,   685,  1894, 12271,   261,\n",
      "           259,  2385,   259,   396,   401,   259, 14852,   630,  2662,  6090,\n",
      "             1]])\n",
      "<unk> 5 лучших фильмов Нолана, которые я смотрел 8 лет назад</s><pad>\n",
      "<unk> 5 лучших фильмов Нолана, которые я смотрел в первый раз</s>\n",
      "<unk> 5 лучших фильмов Нолана, которые я не смотрел 8 лет назад</s>\n",
      "id=342, reviews.shape=(329,)\n",
      "tensor([[    2,  1019, 28200, 11341, 15794, 19738,   259,   264, 25525,  6393,\n",
      "          5121,   261,  1458,  1296, 21313,  1451,  1019,  4288,  9644, 14424,\n",
      "         11662],\n",
      "        [    2,  1019, 28200, 11341, 15794, 19738,   259,   264, 25525,  6393,\n",
      "          5121,   261,  1458,  1296, 21313,  1451, 14424, 11662,   616,   259,\n",
      "           279],\n",
      "        [    2,  1019, 28200, 11341, 15794, 19738,   259,   264, 25525,  6393,\n",
      "          5121,   261,  1458,  1296, 21313,  1451, 14424, 11662,   616,     1,\n",
      "             0]])\n",
      "<unk> Криминальное чтиво - культовый фильм, который прославил Квентина Таранти\n",
      "<unk> Криминальное чтиво - культовый фильм, который прославил Тарантино и\n",
      "<unk> Криминальное чтиво - культовый фильм, который прославил Тарантино</s><pad>\n",
      "id=476, reviews.shape=(206,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for film_id in data.film_id.unique():\n",
    "    reviews = data[data.film_id == film_id].review\n",
    "    print(f'id={film_id}, {reviews.shape=}')\n",
    "    article_text = ' '.join(reviews[:100])\n",
    "    input_ids = tokenizer(\n",
    "        [article_text],\n",
    "        max_length=1024,\n",
    "        add_special_tokens=True,\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        return_tensors=\"pt\"\n",
    "    )[\"input_ids\"]\n",
    "    \n",
    "    # print(tokenizer.tokenize(article_text))\n",
    "\n",
    "    output_ids = model.generate(\n",
    "        input_ids=input_ids,\n",
    "        max_new_tokens=20,\n",
    "        num_return_sequences=3,\n",
    "        min_new_tokens=8,\n",
    "    )\n",
    "    \n",
    "    print(output_ids)\n",
    "\n",
    "    for sequence in output_ids:\n",
    "        headline = tokenizer.decode(sequence, skip_special_tokens=False)\n",
    "        print(headline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ebeeeca",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id=435\n",
      "«Зеленую милю» невозможно экранизировать\n",
      "«Зеленая миля» Дарабонта. Что я смотрела 10 лет назад\n",
      "«Зеленую милю» невозможно экранизировать. Что я смотрела 10 лет\n",
      "\n",
      "\n",
      "id=329\n",
      "Лучшие военные фильмы «Список Шиндлера»\n",
      "«Список Шиндлера» – лучший военный фильм\n",
      "Фильм «Список Шиндлера» – лучший военный фильм\n",
      "\n",
      "\n",
      "id=326\n",
      "«Надежда сбывается, когда её уже не ждут»\n",
      "«Надежда сбывается, когда её уже не ждут» – лучш\n",
      "«Надежда сбывается, когда её уже не ждут»: лучший\n",
      "\n",
      "\n",
      "id=32898\n",
      "«Достучаться до небес» — фильм о мечте, о свободе,\n",
      "Фильмы о мечте, о свободе, о свободе, о\n",
      "«Достучаться до небес» — фильм о мечте, о свободе \n",
      "\n",
      "\n",
      "id=448\n",
      "«Форрест Гамп» — лучший фильм за свою искренность и неподдель\n",
      "«Форрест Гамп» — лучший фильм 1995 года за свою искренность и\n",
      "«Форрест Гамп» — лучший фильм 1995 года\n",
      "\n",
      "\n",
      "id=679486\n",
      "Мультфильм \"Хомяк\" показал детям наглядно, что такое смерть\n",
      "Мультфильм \"Хомяк\" показал детям, что такое смерть\n",
      "Мультфильм \"Хомяк\" показал детям, что такое смерть (Видео)\n",
      "\n",
      "\n",
      "id=3498\n",
      "L.O.T.R: Shadow of Mordor: Shadow of Mordor:\n",
      "Вторая часть L.O.T.R: Shadow of Mordor: \n",
      "В третьей части L.O.T.R: Shadow of Mordor -\n",
      "\n",
      "\n",
      "id=258687\n",
      "Лучшие фильмы Нолана, которые я смотрел в первый раз\n",
      "Лучшие фильмы Нолана, которые я смотрел 8 лет назад\n",
      "Лучшие фильмы Нолана, которые я не смотрел 8 лет назад\n",
      "\n",
      "\n",
      "id=342\n",
      "Лучшие сцены фильма «Криминальное чтиво» от Квентина Таранти\n",
      "Криминальное чтиво: лучшие сцены фильма Тарантино\n",
      "Лучшие сцены фильма «Криминальное чтиво»\n",
      "\n",
      "\n",
      "id=476\n",
      "«Назад в будущее» — о шедевре Роберта Земекиса «На\n",
      "«Назад в будущее» — о шедевре Роберта Земекиса\n",
      "Фильм Роберта Земекиса «Назад в будущее»\n",
      "\n",
      "\n",
      "id=328\n",
      "Фильм «Властелин колец: Братство кольца»\n",
      "Фильм «Властелин колец: Братство кольца» оставило положительные\n",
      "«Властелин колец: Братство кольца»\n",
      "\n",
      "\n",
      "id=361\n",
      "«Бойцовский клуб» — один из самых уникальных фильмов, которые\n",
      "Фильм «Бойцовский клуб» — один из самых уникальных фильмов,\n",
      "«Бойцовский клуб» — один из лучших фильмов, которые я\n",
      "\n",
      "\n",
      "id=2360\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 9\u001b[0m\n\u001b[1;32m      4\u001b[0m     article_text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(reviews[:\u001b[38;5;241m100\u001b[39m])\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m#     with open('reviews.txt', 'at+') as f:\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m#         print(article_text, file=f)\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m     input_ids \u001b[38;5;241m=\u001b[39m \u001b[43mtokenizer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m        \u001b[49m\u001b[43m[\u001b[49m\u001b[43marticle_text\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m600\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m        \u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_length\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtruncation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;66;03m# print(tokenizer.tokenize(article_text))\u001b[39;00m\n\u001b[1;32m     20\u001b[0m     output_ids \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mgenerate(\n\u001b[1;32m     21\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m     22\u001b[0m         max_new_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m,\n\u001b[1;32m     23\u001b[0m         num_return_sequences\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,\n\u001b[1;32m     24\u001b[0m         min_new_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m,\n\u001b[1;32m     25\u001b[0m     )\n",
      "File \u001b[0;32m~/Inter/linux_packages/anaconda3/envs/nlp/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2523\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.__call__\u001b[0;34m(self, text, text_pair, text_target, text_pair_target, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2521\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_in_target_context_manager:\n\u001b[1;32m   2522\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_switch_to_input_mode()\n\u001b[0;32m-> 2523\u001b[0m     encodings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_one\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_pair\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext_pair\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mall_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m text_target \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2525\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_switch_to_target_mode()\n",
      "File \u001b[0;32m~/Inter/linux_packages/anaconda3/envs/nlp/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2609\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase._call_one\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2604\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2605\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch length of `text`: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(text)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not match batch length of `text_pair`:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2606\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(text_pair)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2607\u001b[0m         )\n\u001b[1;32m   2608\u001b[0m     batch_text_or_text_pairs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(text, text_pair)) \u001b[38;5;28;01mif\u001b[39;00m text_pair \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m text\n\u001b[0;32m-> 2609\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_encode_plus\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2610\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_text_or_text_pairs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_text_or_text_pairs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2611\u001b[0m \u001b[43m        \u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madd_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2612\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2613\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtruncation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtruncation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2614\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2615\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstride\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2616\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_split_into_words\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_split_into_words\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2617\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2618\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2619\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2620\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2621\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2622\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2623\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2624\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2625\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2626\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2627\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2628\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2629\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencode_plus(\n\u001b[1;32m   2630\u001b[0m         text\u001b[38;5;241m=\u001b[39mtext,\n\u001b[1;32m   2631\u001b[0m         text_pair\u001b[38;5;241m=\u001b[39mtext_pair,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2647\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   2648\u001b[0m     )\n",
      "File \u001b[0;32m~/Inter/linux_packages/anaconda3/envs/nlp/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2800\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.batch_encode_plus\u001b[0;34m(self, batch_text_or_text_pairs, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2790\u001b[0m \u001b[38;5;66;03m# Backward compatibility for 'truncation_strategy', 'pad_to_max_length'\u001b[39;00m\n\u001b[1;32m   2791\u001b[0m padding_strategy, truncation_strategy, max_length, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_padding_truncation_strategies(\n\u001b[1;32m   2792\u001b[0m     padding\u001b[38;5;241m=\u001b[39mpadding,\n\u001b[1;32m   2793\u001b[0m     truncation\u001b[38;5;241m=\u001b[39mtruncation,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2797\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   2798\u001b[0m )\n\u001b[0;32m-> 2800\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_batch_encode_plus\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2801\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_text_or_text_pairs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_text_or_text_pairs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2802\u001b[0m \u001b[43m    \u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madd_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2803\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpadding_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2804\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtruncation_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtruncation_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2805\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2806\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstride\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2807\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_split_into_words\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_split_into_words\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2808\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2809\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2810\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2811\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2812\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2813\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2814\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2815\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2816\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2817\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2818\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Inter/linux_packages/anaconda3/envs/nlp/lib/python3.10/site-packages/transformers/tokenization_utils_fast.py:429\u001b[0m, in \u001b[0;36mPreTrainedTokenizerFast._batch_encode_plus\u001b[0;34m(self, batch_text_or_text_pairs, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose)\u001b[0m\n\u001b[1;32m    420\u001b[0m \u001b[38;5;66;03m# Set the truncation and padding strategy and restore the initial configuration\u001b[39;00m\n\u001b[1;32m    421\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_truncation_and_padding(\n\u001b[1;32m    422\u001b[0m     padding_strategy\u001b[38;5;241m=\u001b[39mpadding_strategy,\n\u001b[1;32m    423\u001b[0m     truncation_strategy\u001b[38;5;241m=\u001b[39mtruncation_strategy,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    426\u001b[0m     pad_to_multiple_of\u001b[38;5;241m=\u001b[39mpad_to_multiple_of,\n\u001b[1;32m    427\u001b[0m )\n\u001b[0;32m--> 429\u001b[0m encodings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode_batch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    430\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_text_or_text_pairs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    431\u001b[0m \u001b[43m    \u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madd_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    432\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_pretokenized\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_split_into_words\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    433\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    435\u001b[0m \u001b[38;5;66;03m# Convert encoding to dict\u001b[39;00m\n\u001b[1;32m    436\u001b[0m \u001b[38;5;66;03m# `Tokens` has type: Tuple[\u001b[39;00m\n\u001b[1;32m    437\u001b[0m \u001b[38;5;66;03m#                       List[Dict[str, List[List[int]]]] or List[Dict[str, 2D-Tensor]],\u001b[39;00m\n\u001b[1;32m    438\u001b[0m \u001b[38;5;66;03m#                       List[EncodingFast]\u001b[39;00m\n\u001b[1;32m    439\u001b[0m \u001b[38;5;66;03m#                    ]\u001b[39;00m\n\u001b[1;32m    440\u001b[0m \u001b[38;5;66;03m# with nested dimensions corresponding to batch, overflows, sequence length\u001b[39;00m\n\u001b[1;32m    441\u001b[0m tokens_and_encodings \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    442\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_encoding(\n\u001b[1;32m    443\u001b[0m         encoding\u001b[38;5;241m=\u001b[39mencoding,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    452\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m encoding \u001b[38;5;129;01min\u001b[39;00m encodings\n\u001b[1;32m    453\u001b[0m ]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for film_id in data.film_id.unique():\n",
    "    reviews = data[data.film_id == film_id].review\n",
    "    print(f'id={film_id}')\n",
    "    article_text = ' '.join(reviews[:100])\n",
    "    \n",
    "#     with open('reviews.txt', 'at+') as f:\n",
    "#         print(article_text, file=f)\n",
    "    \n",
    "    input_ids = tokenizer(\n",
    "        [article_text],\n",
    "        max_length=600,\n",
    "        add_special_tokens=True,\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        return_tensors=\"pt\"\n",
    "    )[\"input_ids\"]\n",
    "    \n",
    "    # print(tokenizer.tokenize(article_text))\n",
    "\n",
    "    output_ids = model.generate(\n",
    "        input_ids=input_ids,\n",
    "        max_new_tokens=20,\n",
    "        num_return_sequences=3,\n",
    "        min_new_tokens=8,\n",
    "    )\n",
    "    \n",
    "    # print(output_ids)\n",
    "\n",
    "    for sequence in output_ids:\n",
    "        headline = tokenizer.decode(sequence, skip_special_tokens=True)\n",
    "        print(headline)\n",
    "        \n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "964fd7fd",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "346bf23d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>film_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>59964</th>\n",
       "      <td>Это первый американский фильм известного немец...</td>\n",
       "      <td>Ханжа</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73154</th>\n",
       "      <td>На маленький городок ночью обрушивается буря. ...</td>\n",
       "      <td>Мгла</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39456</th>\n",
       "      <td>Все мы знаем что вселенная Гарри Поттера, пожа...</td>\n",
       "      <td>Гарри Поттер и Дары Смерти: Часть I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65759</th>\n",
       "      <td>&lt;B&gt;When you can live forever...What do you liv...</td>\n",
       "      <td>Сумерки</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39753</th>\n",
       "      <td>&lt;b&gt;Ночью вдруг из рук,\\r\\nВыпала гитара.\\r\\nВе...</td>\n",
       "      <td>Не может быть!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28256</th>\n",
       "      <td>Кристофер Нолан для «Бэтменианы» — своего рода...</td>\n",
       "      <td>Темный рыцарь: Возрождение легенды</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43123</th>\n",
       "      <td>Десять лет и почти вдвое больше фильмов – тако...</td>\n",
       "      <td>Мстители: Финал</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27999</th>\n",
       "      <td>Новая картина Кристофера Нолана «Тёмный рыцарь...</td>\n",
       "      <td>Темный рыцарь: Возрождение легенды</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38576</th>\n",
       "      <td>Как же хочется иногда сесть перед экраном и пр...</td>\n",
       "      <td>Железный человек</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50233</th>\n",
       "      <td>Никогда не видел настолько необычного фильма.\\...</td>\n",
       "      <td>Догвилль</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13597 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review  \\\n",
       "59964  Это первый американский фильм известного немец...   \n",
       "73154  На маленький городок ночью обрушивается буря. ...   \n",
       "39456  Все мы знаем что вселенная Гарри Поттера, пожа...   \n",
       "65759  <B>When you can live forever...What do you liv...   \n",
       "39753  <b>Ночью вдруг из рук,\\r\\nВыпала гитара.\\r\\nВе...   \n",
       "...                                                  ...   \n",
       "28256  Кристофер Нолан для «Бэтменианы» — своего рода...   \n",
       "43123  Десять лет и почти вдвое больше фильмов – тако...   \n",
       "27999  Новая картина Кристофера Нолана «Тёмный рыцарь...   \n",
       "38576  Как же хочется иногда сесть перед экраном и пр...   \n",
       "50233  Никогда не видел настолько необычного фильма.\\...   \n",
       "\n",
       "                                   film_id  \n",
       "59964                                Ханжа  \n",
       "73154                                 Мгла  \n",
       "39456  Гарри Поттер и Дары Смерти: Часть I  \n",
       "65759                              Сумерки  \n",
       "39753                       Не может быть!  \n",
       "...                                    ...  \n",
       "28256   Темный рыцарь: Возрождение легенды  \n",
       "43123                      Мстители: Финал  \n",
       "27999   Темный рыцарь: Возрождение легенды  \n",
       "38576                     Железный человек  \n",
       "50233                             Догвилль  \n",
       "\n",
       "[13597 rows x 2 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "134404c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>film_id</th>\n",
       "      <th>len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>59964</th>\n",
       "      <td>Это первый американский фильм известного немец...</td>\n",
       "      <td>Ханжа</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73154</th>\n",
       "      <td>На маленький городок ночью обрушивается буря. ...</td>\n",
       "      <td>Мгла</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39456</th>\n",
       "      <td>Все мы знаем что вселенная Гарри Поттера, пожа...</td>\n",
       "      <td>Гарри Поттер и Дары Смерти: Часть I</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65759</th>\n",
       "      <td>&lt;B&gt;When you can live forever...What do you liv...</td>\n",
       "      <td>Сумерки</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39753</th>\n",
       "      <td>&lt;b&gt;Ночью вдруг из рук,\\r\\nВыпала гитара.\\r\\nВе...</td>\n",
       "      <td>Не может быть!</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28256</th>\n",
       "      <td>Кристофер Нолан для «Бэтменианы» — своего рода...</td>\n",
       "      <td>Темный рыцарь: Возрождение легенды</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43123</th>\n",
       "      <td>Десять лет и почти вдвое больше фильмов – тако...</td>\n",
       "      <td>Мстители: Финал</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27999</th>\n",
       "      <td>Новая картина Кристофера Нолана «Тёмный рыцарь...</td>\n",
       "      <td>Темный рыцарь: Возрождение легенды</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38576</th>\n",
       "      <td>Как же хочется иногда сесть перед экраном и пр...</td>\n",
       "      <td>Железный человек</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50233</th>\n",
       "      <td>Никогда не видел настолько необычного фильма.\\...</td>\n",
       "      <td>Догвилль</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13597 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review  \\\n",
       "59964  Это первый американский фильм известного немец...   \n",
       "73154  На маленький городок ночью обрушивается буря. ...   \n",
       "39456  Все мы знаем что вселенная Гарри Поттера, пожа...   \n",
       "65759  <B>When you can live forever...What do you liv...   \n",
       "39753  <b>Ночью вдруг из рук,\\r\\nВыпала гитара.\\r\\nВе...   \n",
       "...                                                  ...   \n",
       "28256  Кристофер Нолан для «Бэтменианы» — своего рода...   \n",
       "43123  Десять лет и почти вдвое больше фильмов – тако...   \n",
       "27999  Новая картина Кристофера Нолана «Тёмный рыцарь...   \n",
       "38576  Как же хочется иногда сесть перед экраном и пр...   \n",
       "50233  Никогда не видел настолько необычного фильма.\\...   \n",
       "\n",
       "                                   film_id  len  \n",
       "59964                                Ханжа    1  \n",
       "73154                                 Мгла    1  \n",
       "39456  Гарри Поттер и Дары Смерти: Часть I    7  \n",
       "65759                              Сумерки    1  \n",
       "39753                       Не может быть!    3  \n",
       "...                                    ...  ...  \n",
       "28256   Темный рыцарь: Возрождение легенды    4  \n",
       "43123                      Мстители: Финал    2  \n",
       "27999   Темный рыцарь: Возрождение легенды    4  \n",
       "38576                     Железный человек    2  \n",
       "50233                             Догвилль    1  \n",
       "\n",
       "[13597 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['len'] = test.loc[:, 'film_id'].apply(lambda text: len(text.split()))\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fa847ea3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Это первый американский фильм известного немецкого режиссёра Уве Болла, который до этого снимал в основном комедии. Эта картина относится к тому периоду творчества Болла, когда он ещё и не думал снимать экранизации видеоигр, а просто работал в сфере малобюджетных триллеров. Как и большинство последующих фильмов Болла, эта работа насквозь вторична, так как не вносит совершенно ничего нового в расхожий сюжет о полицейских детективах, расследующих преступления очередного маньяка. Такие фильмы пачками снимали в то время американские кинематографисты, вдохновившись великим примером культового режиссёра Дэвида Финчера («Семь»). Хорошие актёры фильмов категории B (пожалуй, к числу неоспоримых достоинств Уве Болла как режиссёра нужно отнести его умение подбирать актёров) изо всех сил стараются оживить банальную историю (особенно запоминаются усилия Каспера Ван Дина, которому пришлось играть загадочного миллионера), но их старания, конечно, идут прахом, так как не подкреплены ни достойной режиссурой, ни интересным сценарием (а его, кстати, сочинил Уве Болл!). В итоге ханжой оказывается вовсе не главный злодей, а наш «чудесный» автор, который явно держит зрителя за идиота, предлагая ему столь банальный продукт.\\r\\n\\r\\nВпрочем, этот фильм всё же поинтереснее последующих фильмов Болла («Сумрак разума», «Дом мёртвых» и «Один в темноте»), так как, в отличие от них, является хотя бы динамичным и не производит при этом впечатление откровенного трэшака. А будучи телевизионным по происхождению, не оказался для режиссёра коммерческим провалом, чего нельзя сказать, например, о «Сумраке разума», который, при бюджете в 3 000 000 долларов, сумел собрать в американском прокате всего лишь … 1 500! Возможно именно поэтому свой следующий фильм «Сердце Америки» Болл решил снимать в жанре драмы.\\r\\n\\r\\n4,5 из 10',\n",
       " 'На маленький городок ночью обрушивается буря. Пострадал также и дом семьи Дрейтон. Утром отец, осмотрев причиненный ущерб, отправляется в ближайший супермаркет, прихватив своего сына. Как только они добираются до магазина, на городок спускается плотный туман, в котором прячется нечто ужасное. Посетители магазина становятся заложниками ситуации.\\r\\n\\r\\nКаков бы не был финал данной ленты, закономерным остается одно: бороться за жизнь нужно до конца, несмотря ни на что, до самого конца. Уже в обыденной жизни преобладает равнодушие, этакий пофигизм на происходящее, а уж если происходит давление безысходности, то все становится еще хуже. Тем насмешливее выглядит представленный здесь финал, словно режиссерская издевка. По крайней мере, зритель получил то, что хотел: нестандартный ход и это хорошо.\\r\\n\\r\\nФильм еще раз подчеркивает, как тяжело человеку остаться человеком, когда на его глазах рушатся устои и заведенные порядки. Туман выступает в роли прекрасного дезориентирующего фактора и надежды на спасение не видно. Люди будто ослепли, не видя ничего дальше своего носа в ожидании второго пришествия. Так что за атмосферу режиссеру плюс.\\r\\n\\r\\nВ действиях актеров кто-то может усмотреть халтуру. Даже меня посещали мысли, что русские в данной ситуации поступили бы не так. Но одно дело американское кино, другое дело российская реальность. Поэтому считаю, что данное поведение людей вполне адекватно ситуации. Больше всего, конечно, запоминается образ проповедницы. Как только она начинала сыпать цитатами из священного писания, тут же хотелось бежать прочь либо настаивать, чтобы она заткнулась. Как тут не вспомнить «Книгу Илая»: вот они, те самые нужные слова для заблудших душ.\\r\\n\\r\\n4 из 10',\n",
       " 'Все мы знаем что вселенная Гарри Поттера, пожалуй, одна из самых интересных и захватывающих историй которые были придуманы писателями (не зря книги о приключениях молодого волшебника так популярны во всем мире). Ну и конечно же, грех был-бы не снять фильм по этим книгам. Первые книги были прекрасно переданы на экраны, сохранив весь шарм истории. Чего нельзя сказать о пятом, и уж тем более о шестом фильме. Если в пятом можно было уловить хотя-бы смысл происходящего (я его уловил возможно только потому что я прочитал с первой по пятую книгу, а остальные было откровенно говоря лень читать), то в шестом фильме получилась неописуемая каша. Я волновался что что-то подобное будет и последующих, заключительных, частях. Но слава Богу я ошибся.\\r\\n\\r\\nТеперь непосредственно о предпоследнем фильме. Наконец-то почуствовалась атмосфера не сказки (которая наблюдалась на протяжении всех фильмов о Поттере), а самого настоящего мистического фэнтези. Одни Пожиратели Смерти чего стоят. Их взгляды, их методы достичь своей цели, все это передано прекрасно(в чем конечно же заслуга актеров которые исполняли свои роли). Главные герои очень выросли (не в плане визуального взгляда, а в плане их поступков), они не бояться поступить так, как считают правильно.\\r\\n\\r\\nТеперь об актерах взрослой гвардии. Больше всех запомнился мне Северус Снегг (хотя он появлялся в фильме буквально пару раз, но зато какой колорит исходит от этого персонажа). Не могу представить себе кого-либо другого на эту роль, кроме Алана Рикмана. Как всегда превосходна Хелена Бонем Картер. Ее Беллатрисса получилась неповторимой, огонь в ее глазах настолько отчетливо видно, что просто не возможно не поверить в ее игру. Также очень посмешил отец Полумны Лавгуд, Ксенофилиус (доволно таки смешное имя даже для волшебного мира, не так ли?). Не могу ни сказать пару слов о персонаже Люциуса Малфоя. Актер также играет очень на приличном уровне, как в принципе и все остальные.\\r\\n\\r\\nТеперь о молодой гвардии. Больше всех мне всегда нравился Драко Малфой (особенно в шестой части), в его персонаже чувствуется безысходность, в его любом движении возникает это чувство. Руперт Гринт наконец-то не перегибает палку (в смысле не переигрывает), в этот раз Рон поучился что надо. Решительный, отважный, готовый придти на помощь своим друзьям. О Гермионе говорить особо нечего - как всегда идеально сыгранная роль Эммы Уотсон. Рэдклифф же в этот раз порадовал гораздо больше чем когда либо, в шестой части он сыграл довольно таки деревянно, но на этот раз все вышло как надо. \\r\\n\\r\\nЭтот фильм абсолютно не похож на предыдущие части режиссера Дэвида Йетса. Я боялся что он приведет к краху всю франшизу, но в этот раз он порадовал как никогда. Фильм прекрасный во всех отношениях, смотреть в обязательном порядке в кинотеатре.\\r\\n\\r\\n10 из 10',\n",
       " \"<B>When you can live forever...What do you live for?</B>\\r\\n\\r\\nИстория про вампиров стара как мир. Но не в каждой эти хищники переступают через жажду и влюбляются в человека. Возможно на экранах была похожая идея совместить 'охотника и добычу', но уж точно не было тех противоречивых чувств, что постоянно мучают главного героя - невыносимая жажда и бесконечная любовь.\\r\\n\\r\\n<B>...and so the lion fell in love with the lamb. \\r\\n- What a stupid lamb. \\r\\n- What a sick, masochitic lion.</B>\\r\\n\\r\\nНа протяжении полуфильма Эдвард старается держаться подальше от искушения, даже уезжает на неделю. Но он не в силах быть далеко от Беллы. Он долго и упорно пытается объяснить ей, что возможно он плохой парень и лучше им не общаться. Но каждая его попытка убедить ее похожа на повод побыть рядом и скорее он убедить себя, но <I>единственный способ избавиться от искушения - поддаться ему.</I>\\r\\n\\r\\n<B>- Are you going to tell me how you stopped the van?\\r\\n- Yeah. um... I had an adrenaline rush. It's very common. You can google it.\\r\\n\\r\\n -How old are you?\\r\\n -17.\\r\\n -How long have you been 17?\\r\\n -A while.</B>\\r\\n\\r\\nПотрясающе написаны реплики для актеров, практически все стали давно известными всему миру цитатами. Не верно суждение, что фильм снят только для молодежи. Люди любого возраста с наслаждением смотрят и пересматривают 'Сумерки' раз за разом, окунаясь в те годы, когда их настигла первая любовь. Фильм заслуживает высших наград. Прекрасно подобрана музыка и декорации, костюмы и спецэффекты.\\r\\n\\r\\n<B>-I'll be back so soon you won't have time to miss me. Look after my heart - I've left it with you.</B>\\r\\n\\r\\nСамая прекрасная история первой любви. Когда опасности для влюбленных представляют не только враги, но и страстные поцелуи. В книге очень хорошо переданы чувства Беллы, трепет ее сердца от каждого прикосновения Эдварда. Но в фильме герои кажутся не такими влюбленными, Эдвард выглядит очень неуверенным в себе, иногда очень похож на труса. На экране он не так мужественно справляется с трудностями. Возможно дело в сценарии, в идее именно так показать влюбленного вампира, а может все дело в Роберте Паттинсоне. Интересно как бы на его месте смотрелся Гаспар Улье (изначально выбраный на эту роль)?\\r\\n\\r\\nВ целом фильм хороший, рекомендую смотреть всем обязательно!\\r\\n\\r\\n10 из 10\",\n",
       " '<b>Ночью вдруг из рук,\\r\\nВыпала гитара.\\r\\nВетер дунул вдруг,\\r\\nИ любви не стало…</b>\\r\\n\\r\\nЯ очень мало пишу про старые советские фильмы. Наверное, кино меняется вместе с людьми. И вообще на этом сайте, большего всего пишут отзывы на современные американские ленты. А в СССР было очень много интересных картин. Режиссеры снимали свои фильмы с большой любовью, а не с большими деньгами. Одного из них звали Леонид Гайдай. Он снял много известных шедевров, но я хотел бы немного рассказать о не самом популярном фильме Гайдая. Он называется…\\r\\n\\r\\n<b>НЕ МОЖЕТ БЫТЬ! (я люблю этот фильм)</b> \\r\\n\\r\\nГайдай экранизировал три рассказа Михаила Зощенко. Сделал он это, как мне кажется, очень ярко и очень смешно. У Гайдая был свой неповторимый стиль. Он умел делать, так что его фильмы запоминали надолго. Гайдай был удивительным режиссером.\\r\\n\\r\\nПомимо профессиональной режиссуры у фильма очень сильный актерский состав. Гайдай собрал самых лучших советских актеров, например Михаил Пуговкин, Олег Даль, Леонид Куравлев, Георгий Вицин, Савелий Крамаров и др. Все они сыграли просто великолепно. И отдельно я хотел бы отметить двух великих актеров - Сергей Филиппов и Вячеслав Невинный. Я никогда не забуду их. Как смешно они пели свои песенки, один про пиво, а второй про подковы. Это не передать словами, это надо видеть.\\r\\n\\r\\nМне кажется, каждый русский человек, который любит кинематограф, должен знать фильмы Леонида Гайдая. Не забывайте НАСТОЯЩИХ режиссеров.\\r\\n\\r\\n<b>Спасибо.\\r\\n\\r\\n10 из 10 </b> \\r\\n\\r\\n<b></b>',\n",
       " \"Итак, на экраны вышел один из самых нашумевших фильмов в этом году. Долгожданная 'Алиса'. Честно говоря, очень ожидал эту картину и обязательно хотел сходить на 3D.\\r\\n\\r\\nФильм, если честно, получился очень даже неплохой. Тим Бертон показал Алису во всём ее великолепии. Очень красивый фильм благодаря современной графики. Чем берет этот фильм? В основном своим бредом. Совершенно фантастические вещи происходят по ходу фильма.\\r\\n\\r\\nАктерский состав был на самом высоком уровне. Единственное, немного разочаровал Джонни Депп, если честно, мог бы сыграть намного лучше. Самый очаровательным героем был именно Чеширский Кот. Очень он уж милым получился. А самый забавный герой, конечно же, Мартовский Заяц. Таких бешеных героев я просто не видел, каждое его появление на экране - просто безумный заряд позитива. Еще понравилась Красная Королева, но только своей фразой: 'Голову с плеч'.\\r\\n\\r\\nИтак, на фильм надо идти обязательно всем, чтобы просто оценить эти чудеса бреда, который заряжает самыми позитивными нотками. Минус фильма состоит в том, что не использовали все возможности, но...\\r\\n\\r\\n8 из 10\",\n",
       " 'Через глаза современного зрителя уже прошли тысячи кинофильмов о войне. Начиная с «Летят журавли» Михаила Калатозова и заканчивая «Пианистом» Романа Поланского. Все уже давно привыкли к ужасам на экране, давно уже засела мысль о том, что фашисты — сволочи и т. д. Точно так же было и со мной, когда я сел перед телевизором, посмотреть фильм «Иди и смотри». Но, как оказалось, это был не очередной кровавый военный детектив, а нечто большое.\\r\\n\\r\\nВо-первых, в данной кинокартине многие эпизоды сняты одним куском. Это трудно воспринимается зрителем, который привык к клиповому монтажу, а не длинными панорамами. Например, когда Флёра и его подруга идут по болоту, у тебя прямо рушится всё внутри, что-то даже подкатывает к горлу, но не тошнота, а нечто другое. Такими длинными, и, некоторые подумают, «занудными» кадрами режиссёр мастерски передаёт нам ощущение того времени, того, что там было. Ты переживаешь вместе с героем его трудность, хотя это слабое слово для того, что пережил Флёра.\\r\\n\\r\\nВо-вторых, если кто заметил, 2-я часть фильма практически без слов. Одним изображением, подкреплённым давящим звуком, Климов говорит с нами через экран. Ни тебе диалогов, ни красивых слов. Как говорится, «Слово — это одно, а дело — совсем другое». А дело страшное. Когда смотришь, прямо чувствуешь, как внутри что-то крошится, становится неуютно, противно, как будто на тебя надавили, и ты «через не хочу» смотришь это.\\r\\n\\r\\nВ-третьих, Флёра — это мы с Вами. Мы, наверное, тоже думаем, что война — место романтическое, не страшное, по лесам, по лугам гулять будем. Но на это Климов отвечает: «Иди и смотри». Флёра пошёл и увидел все эти ужасы, он стареет у нас на глазах оттого, что увидел, и мы вместе с ним. \\r\\n\\r\\nДумаю, что Вам нужно не читать моё безобразное писание, а пойти и посмотреть этот фильм. Вы всё поймёте. Без слов.',\n",
       " 'DreamWorks потчует зрителя мультиками: Кунг-Фу Панда, Как приручить дракона, Шрек, Лесная и Подводная братва, Мегамозг. И делает это весьма умело, дорого и качественно. Серия приносит прибыль - сделают продолжение, но с перерывом в 3-4 года, а пока смотрите сериалы и dtv. Честно говоря, лучше просто смотреть полнометражки. Вот и дождались.\\r\\n\\r\\nИккинг и Ко повзрослели. Друг Беззубика никак не хочет меняться, отец-вождь читает мораль, и это не пустой звук - всё к этому и идёт. Вводятся новые персонажи, раскрывается тайна прошлого. Ранее драконы были врагами для людей и творили зло, наверно, это и будет постоянным напоминанием в каждой новой части. Дружба подвергается жестокому испытанию, но она крепка и ничто её не разрушит. \\r\\n\\r\\nРадует глаз замечательная картинка, пополняется живой уголок, дракончики всё еще могут умилять и веселить. В принципе, без огрехов или не очень нужных конфликтов не обошлось. Раздражает сюжетная линия близняшки, ну, не забавно это. Линия, как и сам персонаж Мамы протагониста, выглядит лишней, неправильно обставленной.   \\r\\n\\r\\nГодится для семейного просмотра, но если бы настрой мультика оставался оптимистичным и бодрым от начала до конца, то оценка была бы выше. \\r\\n\\r\\n7 из 10',\n",
       " \"Удивительный фильм, в котором можно увидеть все. На мой взгляд, это лучшая работа Леонида Быкова. И мне кажется, что черно-белый вариант фильма более приятен для восприятия, чем разукрашеная новая версия. А песня 'Смуглянка' неразрывно связана в сознании с этой картиной. А игра актеров? Это идеальное попадание в образы: Ромео, Смуглянка, Маэстро, Кузнечик.\\r\\n\\r\\nДля меня это фильм, который можно пересматривать и пересматривать. Он не может надоесть!\",\n",
       " \"Первое, что сразу бросается в глаза: не будет интриги. До самого конца её не оказывается вовсе. Уже в самом начале под атмосферную музыку <b>Томаса Ньюмана</b> появляется своеобразная шутка. У космического корабля проложен определённый курс с <i>Земли</i> до планеты <i>Родная обитель-2</i>. Это нужно, чтобы переселить горстку людей на новое место жительства, ибо, видите ли, жизнь на <i>Земле</i> стала дорогостоящей. С чего вдруг? Наверное, капиталисты пришли к власти. Или комиксы захватили мир. Ответа нет. Да и не важно. \\r\\n\\r\\n   <i>I am the passenger and I ride and I ride\\r\\n   I ride through the city's backsides\\r\\n   I see the stars come out of the sky</i>\\r\\n\\r\\n   Как бы подразумевается, что проект перенаселения получил успешный старт с <i>Родной обителью-1</i>. Скорее всего, вселенная, Сила и Бог вместе взятые возмутились такому раскладу, поэтому решили создать преграду на пути корабля. Экипаж и пассажиры спят, так что отдуваться в защите приходится самому транспорту. Из-за этого сыр-бора раньше времени просыпается механик-инженер с телом <b>Криса Пратта</b>. Бывает, неполадки с чипом произошли. Да вот только быстро он смекает, что одинок на корабле, а лететь ещё 90 лет. Провал!\\r\\n\\r\\n   <i>Yeah, the bright and hollow sky\\r\\n   You know it looks so good tonight</i>\\r\\n\\r\\n   Всё! Дальше идут заигрывания с <i>'Сиянием'</i> и <i>'Изгоем' Земекиса</i> в повышенном комфорте. Неудачные попытки хоть что-то исправить заставляют механика радоваться услугам корабля. Да только и это надоест. Превратится в <i>Робинзона Крузо</i> и после мыслей о самоубийстве вдруг удачно так упадет у капсулы со спящей красавицей. 5000 пассажиров, а любовь нашлась сразу. Оказалось, спящая блондинка - писатель. Механик находит информацию о ней в архиве и постепенно влюбляется. Естественно! А кто-то думал, он будет работать правой рукой?\\r\\n\\r\\n   <i>I am the passenger, I stay under glass\\r\\n   I look through my window so bright\\r\\n   I see the stars come out tonight</i>\\r\\n\\r\\n   Вам уже скучно? Понимаю. Вы уже поняли, что произойдет дальше? Отлично. Ход событий читается ведь легко. Мелодрама в декорациях фантастики. Не путать с фантастической мелодрамой, поскольку в отношениях героев ничего сверхъестественного не происходит. Нет ни пришельцев, ни телепортации. Даже захудалого искусственного интеллекта нет! Вот это поразило больше всего. Разве ИИ не должен прилагаться на случай непредвиденных обстоятельств? С космосом шутки плохи. Это же верная гибель - усыпить всех на корабле! \\r\\n\\r\\n   <i>I see the bright and hollow sky\\r\\n   Over the city's ripped backsides\\r\\n   And everything looks good tonight</i>\\r\\n\\r\\n   Жаль, не было собрата великого HAL. Он бы указал пассажирам на их место. А так... Ясно, почему первым в титрах идёт имя <b>Дженнифер Лоуренс</b>. Ничего нового: её героиня - журналист, экономист, спасатель, красавица и обладатель золотого уровня. В корабле есть свои VIP. Маленький механик и богемная писательница могли встретиться только в таком месте, рассказывает нам история. Чистая сказка для взрослых (?). Оба не подростки, но ведут себя, как <i>Ромео</i> и <i>Джульетта</i>. Хочется смеяться, а не переживать. \\r\\n\\r\\n   <i>Singing, la la la</i>\\r\\n\\r\\n   <b>'Пассажиры'</b> - действительно кино, которое после просмотра забудется. Это не <i>'где же мой пудинг'</i> и не <i>'внутренняя богиня'</i>. Что хотел донести проект <b>Мортена Тильдума</b>? Живи настоящим и не беспокойся о будущем, которое не контролируешь? Позволь себе разрушить жизнь человека? Так скучно и одиноко, что заведи себе друга против его воли? Мой ответ: эй, если тебе так скучно, почему бы тебе не подойти ко мне и не почесать между ног. Кстати, больше всего всё-таки поразил <b>Энди Гарсиа</b>, появляющийся лишь в двух кадрах! В двух!\\r\\n\\r\\n   Я понял. <b>Дженнифер Лоуренс</b> хочет играть самодостаточных, сильных, независимых героинь. Было тревожно, когда в одной из сцен она кулаками (не пощёчинами) избивала бедного механика. <b>'Пассажиры'</b> - её фильм. В то же время очень старался <b>Крис Пратт</b>, да только по большей части ему нужно было изображать виноватого человека. И он пополнил ряды 'подружек' <i>Дженнифер Лоуренс</i>. Там уже <i>Лиам Хемсворт, Джош Хатчерсон, Брэдли Купер, Эдгар Рамирес, Джеймс Макэвой</i>. Это не критика, а правда, как она есть. Кому-то по душе.\\r\\n\\r\\n   6 из 10\\r\\n\\r\\n   P.s. Мне точно запомнился бы фильм, играй в ней <b>The Passenger</b> в исполнении <b>Игги Попа</b>.\"]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['review'][:10].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "206999ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pristalovya/Inter/linux_packages/anaconda3/envs/nlp/lib/python3.10/site-packages/transformers/generation/utils.py:1273: UserWarning: Neither `max_length` nor `max_new_tokens` has been set, `max_length` will default to 100 (`generation_config.max_length`). Controlling `max_length` via the config is deprecated and `max_length` will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "«Сердце Америки» Уве Болла: «Сердце Америки»\n",
      "Фильм «Книга Илая» о тумане: кто-то может усмотреть халтуру в действиях актеров\n",
      "10 лучших актеров взрослой гвардии в фильме о Гарри Поттере\n",
      "Фильм \"Сумерки\" - лучшие цитаты о первой любви\n",
      "10 из 10 фильмов Леонида Гайдая\n",
      "Долгожданная 'Алиса\": ТОП-5 самых красивых фильмов в этом году\n",
      "Фильм «Иди и смотри» — это не очередной кровавый военный детектив, а нечто большое\n",
      "7 из 10 мультиков DreamWorks: Кунг-Фу Панда, Как приручить дракона, Шрек, Лесная и Подводная братва, Мегамозг\n",
      "Фильм \"Смуглянка\" - лучшая работа Леонида Быкова\n",
      "Механик перенаселяет космический корабль до планеты \"Родная обитель-2\"\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, T5ForConditionalGeneration\n",
    "\n",
    "model_name = \"IlyaGusev/rut5_base_headline_gen_telegram\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "article_text = \"\"\n",
    "\n",
    "input_ids = tokenizer(\n",
    "    test['review'][:10].to_list(),\n",
    "    max_length=600,\n",
    "    add_special_tokens=True,\n",
    "    padding=\"max_length\",\n",
    "    truncation=True,\n",
    "    return_tensors=\"pt\"\n",
    ")[\"input_ids\"]\n",
    "\n",
    "\n",
    "output_ids = model.generate(\n",
    "    input_ids=input_ids\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "for sequence in output_ids:\n",
    "    headline = tokenizer.decode(sequence, skip_special_tokens=True)\n",
    "    print(headline)\n",
    "\n",
    "# headline = tokenizer.decode(output_ids, skip_special_tokens=True)\n",
    "# print(headline)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ae09bac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "MODEL_NAME = 'cointegrated/rut5-base-absum'\n",
    "model = T5ForConditionalGeneration.from_pretrained(MODEL_NAME)\n",
    "tokenizer = T5Tokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "# model.cuda();\n",
    "model.eval();\n",
    "\n",
    "def summarize(\n",
    "    text, n_words=None, compression=None,\n",
    "    max_length=1000, num_beams=3, do_sample=False, repetition_penalty=10.0, \n",
    "    **kwargs\n",
    "):\n",
    "    \"\"\"\n",
    "    Summarize the text\n",
    "    The following parameters are mutually exclusive:\n",
    "    - n_words (int) is an approximate number of words to generate.\n",
    "    - compression (float) is an approximate length ratio of summary and original text.\n",
    "    \"\"\"\n",
    "    if n_words:\n",
    "        text = '[{}] '.format(n_words) + text\n",
    "    elif compression:\n",
    "        text = '[{0:.1g}] '.format(compression) + text\n",
    "    x = tokenizer(text, return_tensors='pt', padding=True).to(model.device)\n",
    "    with torch.inference_mode():\n",
    "        out = model.generate(\n",
    "            **x, \n",
    "            max_length=max_length, num_beams=num_beams, \n",
    "            do_sample=do_sample, repetition_penalty=repetition_penalty, \n",
    "            **kwargs\n",
    "        )\n",
    "    return tokenizer.decode(out[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8c7d9b6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ханжа\n",
      "Это первый американский фильм известного немецкого режиссёра Уве Болла, который до этого снимал в основном комедии.\n",
      "\n",
      "Мгла\n",
      "На маленьком городке ночью обрушивается буря, в которой прячется нечто ужасное.\n",
      "\n",
      "Гарри Поттер и Дары Смерти: Часть I\n",
      "Фильм Гарри Поттера, пожалуй, самый интересный и захватывающий.\n",
      "\n",
      "Сумерки\n",
      "В фильме \"Сумерки\" очень хорошая музыка, костюмы и спецэффекты.\n",
      "\n",
      "Не может быть!\n",
      "Мне нравятся советские фильмы.\n",
      "\n",
      "Алиса в Стране чудес\n",
      "На экраны вышел один из самых нашумевших фильмов в этом году.\n",
      "\n",
      "Иди и смотри\n",
      "Фильм «Иди и смотри».\n",
      "\n",
      "Как приручить дракона 2\n",
      "Серия DreamWorks потчует зрителя мультиками: Кунг-Фу Панда, Как приручить дракона, Шрек, Лесная и Подводная братва.\n",
      "\n",
      "В бой идут одни «старики»\n",
      "Фильм Леонида Быкова.\n",
      "\n",
      "Пассажиры\n",
      "Фильм, который выглядит как фантастическая мелодрама в декорациях фантастики\n",
      "\n",
      "Корпорация монстров\n",
      "«Корпорация монстров» — один из самых популярных анимационных лент.\n",
      "\n",
      "Реквием по мечте\n",
      "Фильм Джаред Лето.\n",
      "\n",
      "Лучшее предложение\n",
      "Хороший фильм.\n",
      "\n",
      "Принц Персии: Пески времени\n",
      "Режиссёр, как бы нам ни хотелось, не Болл\n",
      "\n",
      "Стражи Галактики\n",
      "Лучший фильм 2ой фазы вселенной Marvel!\n",
      "\n",
      "Шрэк\n",
      "В мультфильме «Зеленый огр» впервые вышел первый фильм серии. Огромное количество юмора, которое заставит смеяться и ребенка и взрослого\n",
      "\n",
      "Леон\n",
      "Фильм Люка Бессона «Леон» не исключение.\n",
      "\n",
      "Дэдпул\n",
      "Фильм вышел вполне себе хорошим, но благодаря рекламе некоторые стали думать, что это будет лучший фильм на супергеройский мотив.\n",
      "\n",
      "Гарри Поттер и Орден Феникса\n",
      "Премьера романа Джоан Кэтлин Роулинг.\n",
      "\n",
      "Господин Никто\n",
      "Человек не в состоянии справиться с таким тяжким грузом, как знать все наперед.\n",
      "\n",
      "Дневник памяти\n",
      "Огромное спасибо создателям фильма «Дневник памяти»\n",
      "\n",
      "Рапунцель: Запутанная история\n",
      "Мне нравится Дисней!\n",
      "\n",
      "Джокер\n",
      "Создайте сценарий, чтобы выглядеть заслуженными и безнаказанными\n",
      "\n",
      "Бегущий по лезвию 2049\n",
      "Фильм Вильнёва «Бегущий по лезвию 2049» — немыслимая затея\n",
      "\n",
      "Законопослушный гражданин\n",
      "Фильм Джерард Батлер потрясающий, динамичный и держит тебя в напряжении с самого начала.\n",
      "\n",
      "Сумерки\n",
      "В кинотеатре увидел трейлер «Сумерек». Запомнилось, что парень с лицом, раскрашенным под клоуна, прыгал по деревьям.\n",
      "\n",
      "В джазе только девушки\n",
      "Это самая смешная комедия всех времен и народов.\n",
      "\n",
      "Господин Никто\n",
      "На месте главного героя: «Если мы не делаем выбор, его могут сделать за нас»\n",
      "\n",
      "Запах женщины\n",
      "Название фильма «запах женщины»\n",
      "\n",
      "Пятьдесят оттенков серого\n",
      "Мне не нравится фильм Джеймс Кена.\n",
      "\n",
      "Ирония судьбы, или С легким паром!\n",
      "Фильм Эльдара Рязанова «С лёгким паром, или Однажды в новогоднюю ночь» стал прорывом\n",
      "\n",
      "Дневник памяти\n",
      "Фильм, который меняет сознание.\n",
      "\n",
      "Сумерки\n",
      "Фильм, по моему мнению, не удался.\n",
      "\n",
      "Пятьдесят оттенков серого\n",
      "Фильм \"Пятьдесят оттенков серого\" готов повсеместно взорвать бокс-офис по обе стороны океана\n",
      "\n",
      "Пираты Карибского моря: Проклятие Черной жемчужины\n",
      "Джонни Депп в роли Джека Воробья играет блестяще.\n",
      "\n",
      "Побег из Шоушенка\n",
      "«Побег из Шоушенка» — именно такой фильм\n",
      "\n",
      "Криминальное чтиво\n",
      "Фильм «Криминальное Чтиво» с Джоном Траволтом, который поучаствует в трёх историях: Винсент и Джулс, Ситуация с Бонни, Винсент Вега и жена Марселоса Уоллеса.\n",
      "\n",
      "Драйв\n",
      "Режиссер Дэвид Рефн выглядит главным демиургом этого фильма\n",
      "\n",
      "Великий Гэтсби\n",
      "Мне одинаково приятен оригинальный голос Тоби Магуайар. Дубляж Бурунова (Бурунов гений).\n",
      "\n",
      "Майор Гром: Чумной Доктор\n",
      "Сходите на Майора Грома в кино и друзей сводите\n",
      "\n",
      "Бесславные ублюдки\n",
      "В Каннах дали награду «Иди и смотри».\n",
      "\n",
      "Кошмар перед Рождеством\n",
      "Это один из лучших мультфильмов в мире\n",
      "\n",
      "Игра на понижение\n",
      "Фильм про цифры, но этот фильм по-настоящему зацепил меня.\n",
      "\n",
      "Билет на Vegas\n",
      "Армянин из Еревана Гор Киракосян снял комедию «Билет на Vegas»\n",
      "\n",
      "Пираты Карибского моря: На краю света\n",
      "Фильм «На края Света» не обошлось без забавных моментов.\n",
      "\n",
      "Вечное сияние чистого разума\n",
      "Мне кажется, что у меня не было любовь... но кто-то её вырезал из моей истории?\n",
      "\n",
      "Реквием по мечте\n",
      "Фильм «Реквием по мечте»\n",
      "\n",
      "Клуб Винкс — Школа волшебниц\n",
      "Посмотрела на рисовку.\n",
      "\n",
      "Социальная сеть\n",
      "Марка Цукерберга создает самую большую социальную сеть в мире.\n",
      "\n",
      "Побег из Шоушенка\n",
      "Побег из Шоушенка Тюрьма\n",
      "\n",
      "Пираты Карибского моря: Проклятие Черной жемчужины\n",
      "Джонни Депп: «Мы собираемся украсть корабль? — Реквизировать этот корабль»\n",
      "\n",
      "Дурак\n",
      "Фильм «Дурак» построен таким образом, что не позволяет строить дома.\n",
      "\n",
      "Джон Уик 2\n",
      "«Джон Уик 2» — это один из лучших представителей жанра боевик.\n",
      "\n",
      "Общество мертвых поэтов\n",
      "Подростковый возраст - это время формирования морали, закаливания личности.\n",
      "\n",
      "Стражи Галактики\n",
      "Смотрите фильм «Стражи галактики» в качестве глотка свежего воздуха среди бесконечных блокбастеров аля «Трансформеры».\n",
      "\n",
      "Игра престолов\n",
      "Игра Престолов - один из тех фильмов, в которых наперед знаешь, что произойдет\n",
      "\n",
      "Игры разума\n",
      "Фильм «Игры Разума» в исполнении изумившего меня Рассела Кроу.\n",
      "\n",
      "Дэдпул\n",
      "Фильм Дедпул, в котором сценаристы решили отойти от привычных канонов в сторону пародии.\n",
      "\n",
      "Дьявол носит Prada\n",
      "Фильм, который лично для меня стал обозрением блестящей игры молодой и опытной актрисы.\n",
      "\n",
      "Интерстеллар\n",
      "Фильм про крах земли, а всей планете сразу грозит гибель.\n",
      "\n",
      "Смех и горе у Бела моря\n",
      "Смотри, как выглядит этот мультфильм?\n",
      "\n",
      "Жизнь прекрасна\n",
      "Впечатляющий фильм о нелегких жутких временах\n",
      "\n",
      "Старикам тут не место\n",
      "Фильм «Плавание в Византию» вымотал меня. Поставить на кон собственную душу, чтобы не попасть под отбойный молоток преобразований\n",
      "\n",
      "Властелин колец: Две крепости\n",
      "Фильм «Властелин Колец» вышел на экраны после выхода первой серии трилогии – «Братство Кольца».\n",
      "\n",
      "Аватар\n",
      "После просмотра фильма Аватар, впервые посмотрел на 3D. Посмотрев трейлер из интернета, я сразу понял: «Этот фильм я полюблю!»\n",
      "\n",
      "Одержимость\n",
      "В этом фильме мы стремимся добиваться своих целей.\n",
      "\n",
      "Амели\n",
      "Посмотрите и почувствуйте себя в фильме.\n",
      "\n",
      "О чём говорят мужчины\n",
      "Фильм «О чем говорят мужчины» уселся смотреть безо всяких иллюзий\n",
      "\n",
      "Реквием по мечте\n",
      "Фильм «Реквием по мечте» — это чистая победа\n",
      "\n",
      "Джокер\n",
      "В Венецианских кинофестивалях вышел третий режиссер, который переквалифицировался из комедийного в драматического\n",
      "\n",
      "Она\n",
      "Виртуальный роман с компьютером.\n",
      "\n",
      "Господин Никто\n",
      "Фильм «Господин Никто» (2009).\n",
      "\n",
      "Дурак\n",
      "Фильм Юрия Быкова «Дурак» показал, что люди не были бы плохими или насколько бы они не пытались казаться таковыми.\n",
      "\n",
      "Форрест Гамп\n",
      "Сказать об этом фильме, что он хорош — это все равно, что ничего не сказать.\n",
      "\n",
      "Джон Уик\n",
      "Что заставляет звезд такого уровня, как Киану Ривз сниматься в фильме \"тупое мочилово\"\n",
      "\n",
      "Гарри Поттер и Дары Смерти: Часть I\n",
      "Лучшая экранизация с момента выхода 'Тайной комнаты'.\n",
      "\n",
      "Сумерки\n",
      "Поэма М. Ю. Лермонтова 'Демон'\n",
      "\n",
      "Хранители снов\n",
      "Лучший детский мультфильм года\n",
      "\n",
      "Королевство полной луны\n",
      "Режиссер «Бесподобного мистера Фокса» Уэс Андерсон открыл коробку из-под обуви, в которой ты хранишь все свои мечты и воспоминания.\n",
      "\n",
      "Майор Гром: Чумной Доктор\n",
      "Смотри фильм по комиксам, да и к тому же с такими персонажами\n",
      "\n",
      "Темный рыцарь: Возрождение легенды\n",
      "Фильм «Темный Рыцарь: Возрождение легенды» сделал вескую заявку на звание Лучшего фильма года\n",
      "\n",
      "Образцовый самец\n",
      "Это просто невероятно смешная комедия!\n",
      "\n",
      "Терминатор 2: Судный день\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(test)):\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(test\u001b[38;5;241m.\u001b[39miloc[i]\u001b[38;5;241m.\u001b[39mfilm_id)\n\u001b[0;32m----> 7\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[43msummarize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreview\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_words\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28mprint\u001b[39m()\n",
      "Cell \u001b[0;32mIn[14], line 27\u001b[0m, in \u001b[0;36msummarize\u001b[0;34m(text, n_words, compression, max_length, num_beams, do_sample, repetition_penalty, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m x \u001b[38;5;241m=\u001b[39m tokenizer(text, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m'\u001b[39m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39mto(model\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39minference_mode():\n\u001b[0;32m---> 27\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_beams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_beams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdo_sample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdo_sample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrepetition_penalty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepetition_penalty\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tokenizer\u001b[38;5;241m.\u001b[39mdecode(out[\u001b[38;5;241m0\u001b[39m], skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/Inter/linux_packages/anaconda3/envs/nlp/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Inter/linux_packages/anaconda3/envs/nlp/lib/python3.10/site-packages/transformers/generation/utils.py:1252\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, **kwargs)\u001b[0m\n\u001b[1;32m   1244\u001b[0m         logger\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[1;32m   1245\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA decoder-only architecture is being used, but right-padding was detected! For correct \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1246\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgeneration results, please set `padding_side=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m` when initializing the tokenizer.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1247\u001b[0m         )\n\u001b[1;32m   1249\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoder_outputs\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m model_kwargs:\n\u001b[1;32m   1250\u001b[0m     \u001b[38;5;66;03m# if model is encoder decoder encoder_outputs are created\u001b[39;00m\n\u001b[1;32m   1251\u001b[0m     \u001b[38;5;66;03m# and added to `model_kwargs`\u001b[39;00m\n\u001b[0;32m-> 1252\u001b[0m     model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_prepare_encoder_decoder_kwargs_for_generation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1253\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_input_name\u001b[49m\n\u001b[1;32m   1254\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1256\u001b[0m \u001b[38;5;66;03m# 5. Prepare `input_ids` which will be used for auto-regressive generation\u001b[39;00m\n\u001b[1;32m   1257\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder:\n",
      "File \u001b[0;32m~/Inter/linux_packages/anaconda3/envs/nlp/lib/python3.10/site-packages/transformers/generation/utils.py:617\u001b[0m, in \u001b[0;36mGenerationMixin._prepare_encoder_decoder_kwargs_for_generation\u001b[0;34m(self, inputs_tensor, model_kwargs, model_input_name)\u001b[0m\n\u001b[1;32m    615\u001b[0m encoder_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreturn_dict\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    616\u001b[0m encoder_kwargs[model_input_name] \u001b[38;5;241m=\u001b[39m inputs_tensor\n\u001b[0;32m--> 617\u001b[0m model_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoder_outputs\u001b[39m\u001b[38;5;124m\"\u001b[39m]: ModelOutput \u001b[38;5;241m=\u001b[39m \u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mencoder_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    619\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model_kwargs\n",
      "File \u001b[0;32m~/Inter/linux_packages/anaconda3/envs/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Inter/linux_packages/anaconda3/envs/nlp/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py:1055\u001b[0m, in \u001b[0;36mT5Stack.forward\u001b[0;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, inputs_embeds, head_mask, cross_attn_head_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1042\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m checkpoint(\n\u001b[1;32m   1043\u001b[0m         create_custom_forward(layer_module),\n\u001b[1;32m   1044\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1052\u001b[0m         \u001b[38;5;28;01mNone\u001b[39;00m,  \u001b[38;5;66;03m# past_key_value is always None with gradient checkpointing\u001b[39;00m\n\u001b[1;32m   1053\u001b[0m     )\n\u001b[1;32m   1054\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1055\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1056\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1057\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1058\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_bias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1059\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1060\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1061\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_decoder_position_bias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_decoder_position_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1062\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1063\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcross_attn_layer_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcross_attn_layer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1064\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1065\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1066\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1067\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1069\u001b[0m \u001b[38;5;66;03m# layer_outputs is a tuple with:\u001b[39;00m\n\u001b[1;32m   1070\u001b[0m \u001b[38;5;66;03m# hidden-states, key-value-states, (self-attention position bias), (self-attention weights), (cross-attention position bias), (cross-attention weights)\u001b[39;00m\n\u001b[1;32m   1071\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n",
      "File \u001b[0;32m~/Inter/linux_packages/anaconda3/envs/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Inter/linux_packages/anaconda3/envs/nlp/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py:687\u001b[0m, in \u001b[0;36mT5Block.forward\u001b[0;34m(self, hidden_states, attention_mask, position_bias, encoder_hidden_states, encoder_attention_mask, encoder_decoder_position_bias, layer_head_mask, cross_attn_layer_head_mask, past_key_value, use_cache, output_attentions, return_dict)\u001b[0m\n\u001b[1;32m    684\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    685\u001b[0m     self_attn_past_key_value, cross_attn_past_key_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 687\u001b[0m self_attention_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    688\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    689\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    690\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_bias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    691\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    692\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mself_attn_past_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    693\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    694\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    695\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    696\u001b[0m hidden_states, present_key_value_state \u001b[38;5;241m=\u001b[39m self_attention_outputs[:\u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m    697\u001b[0m attention_outputs \u001b[38;5;241m=\u001b[39m self_attention_outputs[\u001b[38;5;241m2\u001b[39m:]  \u001b[38;5;66;03m# Keep self-attention outputs and relative position weights\u001b[39;00m\n",
      "File \u001b[0;32m~/Inter/linux_packages/anaconda3/envs/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Inter/linux_packages/anaconda3/envs/nlp/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py:593\u001b[0m, in \u001b[0;36mT5LayerSelfAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, position_bias, layer_head_mask, past_key_value, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    582\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    583\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    584\u001b[0m     hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    590\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    591\u001b[0m ):\n\u001b[1;32m    592\u001b[0m     normed_hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer_norm(hidden_states)\n\u001b[0;32m--> 593\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSelfAttention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    594\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnormed_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    595\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    596\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_bias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    597\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    598\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    599\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    600\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    601\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    602\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m hidden_states \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(attention_output[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    603\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (hidden_states,) \u001b[38;5;241m+\u001b[39m attention_output[\u001b[38;5;241m1\u001b[39m:]  \u001b[38;5;66;03m# add attentions if we output them\u001b[39;00m\n",
      "File \u001b[0;32m~/Inter/linux_packages/anaconda3/envs/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Inter/linux_packages/anaconda3/envs/nlp/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py:518\u001b[0m, in \u001b[0;36mT5Attention.forward\u001b[0;34m(self, hidden_states, mask, key_value_states, position_bias, past_key_value, layer_head_mask, query_length, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    514\u001b[0m \u001b[38;5;66;03m# get key/value states\u001b[39;00m\n\u001b[1;32m    515\u001b[0m key_states \u001b[38;5;241m=\u001b[39m project(\n\u001b[1;32m    516\u001b[0m     hidden_states, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk, key_value_states, past_key_value[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m past_key_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    517\u001b[0m )\n\u001b[0;32m--> 518\u001b[0m value_states \u001b[38;5;241m=\u001b[39m \u001b[43mproject\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    519\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey_value_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[1;32m    520\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    522\u001b[0m \u001b[38;5;66;03m# compute scores\u001b[39;00m\n\u001b[1;32m    523\u001b[0m scores \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmatmul(\n\u001b[1;32m    524\u001b[0m     query_states, key_states\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    525\u001b[0m )  \u001b[38;5;66;03m# equivalent of torch.einsum(\"bnqd,bnkd->bnqk\", query_states, key_states), compatible with onnx op>9\u001b[39;00m\n",
      "File \u001b[0;32m~/Inter/linux_packages/anaconda3/envs/nlp/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py:489\u001b[0m, in \u001b[0;36mT5Attention.forward.<locals>.project\u001b[0;34m(hidden_states, proj_layer, key_value_states, past_key_value)\u001b[0m\n\u001b[1;32m    485\u001b[0m \u001b[38;5;124;03m\"\"\"projects hidden states correctly to key/query states\"\"\"\u001b[39;00m\n\u001b[1;32m    486\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key_value_states \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    487\u001b[0m     \u001b[38;5;66;03m# self-attn\u001b[39;00m\n\u001b[1;32m    488\u001b[0m     \u001b[38;5;66;03m# (batch_size, n_heads, seq_length, dim_per_head)\u001b[39;00m\n\u001b[0;32m--> 489\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m shape(\u001b[43mproj_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    490\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m past_key_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    491\u001b[0m     \u001b[38;5;66;03m# cross-attn\u001b[39;00m\n\u001b[1;32m    492\u001b[0m     \u001b[38;5;66;03m# (batch_size, n_heads, seq_length, dim_per_head)\u001b[39;00m\n\u001b[1;32m    493\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m shape(proj_layer(key_value_states))\n",
      "File \u001b[0;32m~/Inter/linux_packages/anaconda3/envs/nlp/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Inter/linux_packages/anaconda3/envs/nlp/lib/python3.10/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# text = \"\"\"Высота башни составляет 324 метра (1063 фута), примерно такая же высота, как у 81-этажного здания, и самое высокое сооружение в Париже. Его основание квадратно, размером 125 метров (410 футов) с любой стороны. Во время строительства Эйфелева башня превзошла монумент Вашингтона, став самым высоким искусственным сооружением в мире, и этот титул она удерживала в течение 41 года до завершения строительство здания Крайслер в Нью-Йорке в 1930 году. Это первое сооружение которое достигло высоты 300 метров. Из-за добавления вещательной антенны на вершине башни в 1957 году она сейчас выше здания Крайслер на 5,2 метра (17 футов). За исключением передатчиков, Эйфелева башня является второй самой высокой отдельно стоящей структурой во Франции после виадука Мийо.\"\"\"\n",
    "# print(summarize(test.review.iloc[0], n_words=100))\n",
    "\n",
    "\n",
    "for i in range(len(test)):\n",
    "    print(test.iloc[i].film_id)\n",
    "    print(summarize(test.iloc[i].review, n_words=10))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "815684d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ханжа\n",
      "В российском прокате «Сумрак разума» Уве Болла — первый фильм известного немецкого режиссёра, снятый в жанре драмы.\n",
      "Мгла\n",
      "В российском прокате «Туман» — фильм о том, как бороться за жизнь до конца, несмотря ни на что, до самого конца.\n",
      "Гарри Поттер и Дары Смерти: Часть I\n",
      "В российском прокате «Гарри Поттера: Последняя часть» — шестая часть фильма о волшебном мире.\n",
      "Сумерки\n",
      "В российский прокат выходит «Сумерки» Роберта Паттинсона - история первой любви вампира, влюбленного в Беллу.\n",
      "Не может быть!\n",
      "На этом сайте я хочу поделиться своими впечатлениями от фильма Леонида Гайдая «НЕ МОЖЕТ БЫТЬ!».\n",
      "Алиса в Стране чудес\n",
      "В российский прокат выходит «Алиса» Тима Бертона - один из самых нашумевших фильмов в этом году.\n",
      "Иди и смотри\n",
      "В российский прокат вышла вторая часть фильма «Иди и смотри» Александра Климова. Режиссёр рассказал об ужасах, которые он видит на экране.\n",
      "Как приручить дракона 2\n",
      "В российском прокате мультфильм DreamWorks: Иккинг и Ко повзрослели, драконы творят зло, Мама протагониста выглядит лишней, неправильно обставленной.\n",
      "В бой идут одни «старики»\n",
      "В российский прокат выходит «Смуглянка» Леонида Быкова — фильм, который можно пересматривать и пересматривать.\n",
      "Пассажиры\n",
      "В космическом романе «Родная обитель-2» не будет интриги, а будет только любовь.\n"
     ]
    }
   ],
   "source": [
    "from transformers import MBartTokenizer, MBartForConditionalGeneration\n",
    "\n",
    "# model_name = \"IlyaGusev/mbart_ru_sum_gazeta\"\n",
    "# tokenizer = MBartTokenizer.from_pretrained(model_name)\n",
    "# model = MBartForConditionalGeneration.from_pretrained(model_name)\n",
    "\n",
    "article_text = \"...\"\n",
    "\n",
    "input_ids = tokenizer(\n",
    "    test['review'][:10].to_list(),\n",
    "    max_length=600,\n",
    "    padding=\"max_length\",\n",
    "    truncation=True,\n",
    "    return_tensors=\"pt\",\n",
    ")[\"input_ids\"]\n",
    "\n",
    "output_ids = model.generate(\n",
    "    input_ids=input_ids,\n",
    "    no_repeat_ngram_size=4,\n",
    "    max_length=200\n",
    ")\n",
    "\n",
    "# summary = tokenizer.decode(output_ids, skip_special_tokens=True)\n",
    "# print(summary)\n",
    "\n",
    "i = 0\n",
    "for ids in output_ids:\n",
    "    print(test.iloc[i].film_id)\n",
    "    i += 1\n",
    "    summary = tokenizer.decode(ids, skip_special_tokens=True)\n",
    "    print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "78b2ad8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ханжа\n",
      "\"Никаких сюрпризов не будет!\": в России рассказали, как изменилась жизнь россиян в период самоизоляции\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, EncoderDecoderModel\n",
    "\n",
    "model_name = \"IlyaGusev/rubert_telegram_headlines\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, do_lower_case=False, do_basic_tokenize=False, strip_accents=False)\n",
    "model = EncoderDecoderModel.from_pretrained(model_name)\n",
    "\n",
    "article_text = \"...\"\n",
    "\n",
    "input_ids = tokenizer(\n",
    "    [''],\n",
    "    add_special_tokens=True,\n",
    "    max_length=512,\n",
    "    padding=\"max_length\",\n",
    "    truncation=True,\n",
    "    return_tensors=\"pt\",\n",
    ")[\"input_ids\"]\n",
    "\n",
    "output_ids = model.generate(\n",
    "    input_ids=input_ids,\n",
    "    max_length=64,\n",
    "    no_repeat_ngram_size=3,\n",
    "    num_beams=10,\n",
    "    top_p=0.95\n",
    ")\n",
    "\n",
    "i = 0\n",
    "for ids in output_ids:\n",
    "    print(test.iloc[i].film_id)\n",
    "    i += 1\n",
    "    headline = tokenizer.decode(ids, skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
    "    print(headline)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c231ede",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec62e4d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f6871b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6da2f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84129d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d701ea63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07689fa4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
