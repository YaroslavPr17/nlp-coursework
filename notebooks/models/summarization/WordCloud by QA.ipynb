{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "83d5b936",
   "metadata": {
    "cellId": "abji4dgz19dhq15ohf89s"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter/work/resources/nlp-coursework\n"
     ]
    }
   ],
   "source": [
    "%cd ../../.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "721be912",
   "metadata": {
    "cellId": "z9tqp9d34fkb4ts9d3loj",
    "execution_id": "2edce053-8fd2-4294-8202-84cd1599c180"
   },
   "outputs": [
    {
     "ename": "Execute error",
     "evalue": "Failed to allocate servant c1.4: internal error. Please try again",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "from src.nlp.application import (Pipeline, \n",
    "                                 get_df_by_film_and_person, \n",
    "                                 get_df_by_person, \n",
    "                                 collect_sents_to_summarize,\n",
    "                                 split_opinions_to_chunks)\n",
    "from datasets_ import DatasetLoader\n",
    "\n",
    "import dill\n",
    "from tqdm.notebook import tqdm\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib notebook\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering, pipeline\n",
    "from transformers import MBartTokenizer, MBartForConditionalGeneration\n",
    "from transformers import AutoTokenizer, T5ForConditionalGeneration\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "from transformers.pipelines.question_answering import QuestionAnsweringPipeline\n",
    "\n",
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\"\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import torch\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "77751404",
   "metadata": {
    "cellId": "a5qi7e4w9m9shp0g4bcv5d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter/work/resources/nlp-coursework/data/named_entities.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ne</th>\n",
       "      <th>occurrences</th>\n",
       "      <th>film_id</th>\n",
       "      <th>n_sents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Кинг</td>\n",
       "      <td>[Несколько лет назад прочитала оригинальный ро...</td>\n",
       "      <td>435</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Дарабонт</td>\n",
       "      <td>[После взросления и прочтения книги фильм Дара...</td>\n",
       "      <td>435</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Перси</td>\n",
       "      <td>[Особенно нелепа вся эта линия с травлей Перси...</td>\n",
       "      <td>435</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Депрессия</td>\n",
       "      <td>[За то, что работает по блату (во времена Депр...</td>\n",
       "      <td>435</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Делакруа</td>\n",
       "      <td>[И кстати, ради большей слезовыжималки сценари...</td>\n",
       "      <td>435</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106669</th>\n",
       "      <td>Сергей Эйзенштейн</td>\n",
       "      <td>[В качестве наглядного примера могу предложить...</td>\n",
       "      <td>969760</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106670</th>\n",
       "      <td>Ферруччо</td>\n",
       "      <td>[Молодой Ферруччо - типичный англо-саксонский ...</td>\n",
       "      <td>969760</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106671</th>\n",
       "      <td>Эдуардо де Филиппо</td>\n",
       "      <td>[Авторам смотреть старые итальянские фильмы и ...</td>\n",
       "      <td>969760</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106672</th>\n",
       "      <td>Ютюба</td>\n",
       "      <td>[И он по законам мотивашек с Ютюба читает как ...</td>\n",
       "      <td>969760</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106673</th>\n",
       "      <td>Энцо</td>\n",
       "      <td>[По итогу процесс создания машины тоже не раск...</td>\n",
       "      <td>969760</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>106674 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        ne  ... n_sents\n",
       "0                     Кинг  ...     150\n",
       "1                 Дарабонт  ...      65\n",
       "2                    Перси  ...      93\n",
       "3                Депрессия  ...       1\n",
       "4                 Делакруа  ...      26\n",
       "...                    ...  ...     ...\n",
       "106669   Сергей Эйзенштейн  ...       1\n",
       "106670            Ферруччо  ...       9\n",
       "106671  Эдуардо де Филиппо  ...       1\n",
       "106672               Ютюба  ...       1\n",
       "106673                Энцо  ...       1\n",
       "\n",
       "[106674 rows x 4 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = DatasetLoader.load_named_entities_dataset(show_path=True)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "66af7154",
   "metadata": {
    "cellId": "77c933f6xauuopbtumxen"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d69f67cb58cc4c9986c56e73e74b6a6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/781 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b875dfa2f0648869ccae604749496ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/2.08G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3257a6b5f3a14f779af6e0a5c44c066b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/516 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8b59fd0a9264c83a5ba05e9bf9863b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/4.83M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcdb0ab3dfae4c88928b0e81e6f79ae3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/8.68M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af6ee7df25654be9a6df068e95901990",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/150 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "model_name = \"AlexKay/xlm-roberta-large-qa-multilingual-finedtuned-ru\"\n",
    "model = pipeline('question-answering', model=model_name, tokenizer=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "25cf1407",
   "metadata": {
    "cellId": "dhsq9b1nzqjkkripx1sy4i"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afd97eafac6545169efe74d40e0a696f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/781 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a951241e9207411e8f57a8b5f2616f61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/2.08G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d3db0dab66c4550926c9649cf59f754",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/516 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "335a631d875f48a9ad96d0296e788b1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/4.83M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e2be854ebe44cf0896ce7e3a4f3a13a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/8.68M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4efd85d5f329459e8f1cbb40fee210b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/150 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#!g1.1\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "model_name = \"AlexKay/xlm-roberta-large-qa-multilingual-finedtuned-ru\"\n",
    "model = pipeline('question-answering', model=model_name, tokenizer=model_name, device=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "a33e0a5f",
   "metadata": {
    "cellId": "ejywm1yhgttjdxeme6cro"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "def get_person_characteristics(data: pd.DataFrame, \n",
    "                               name: str, \n",
    "                               model: QuestionAnsweringPipeline,\n",
    "                               film_id: int = None,\n",
    "                               ):\n",
    "    from src.nlp.preprocessing import clean\n",
    "    from random import shuffle\n",
    "    import numpy as np\n",
    "    \n",
    "    _N_SENTS = 100\n",
    "    \n",
    "    if film_id is not None:\n",
    "        listed_opinions = collect_sents_to_summarize(\n",
    "            get_df_by_film_and_person(data, film_id, name), \n",
    "            n_sents = _N_SENTS\n",
    "        )\n",
    "    else:\n",
    "        listed_opinions = collect_sents_to_summarize(\n",
    "            get_df_by_person(data, name), \n",
    "            n_sents = _N_SENTS\n",
    "        )       \n",
    "    \n",
    "    opinions = '\\n'.join(listed_opinions)\n",
    "#     print(opinions, end='\\n------------------------------------\\n')\n",
    "    opinions = clean(opinions, char_clean_only=True, lowercase=False)\n",
    "#     print(opinions)\n",
    "    \n",
    "    answers = []\n",
    "    scores = []\n",
    "  \n",
    "\n",
    "    try:\n",
    "        while True:\n",
    "            questions = [\n",
    "                {\n",
    "                    'question': f'Какая {name}?',\n",
    "                    'context': opinions\n",
    "                },\n",
    "                {\n",
    "                    'question': f'Что сделала {name}?',\n",
    "                    'context': opinions\n",
    "                },\n",
    "                {\n",
    "                    'question': f'Что хорошо у {name}?',\n",
    "                    'context': opinions\n",
    "                },\n",
    "                {\n",
    "                    'question': f'Что плохо у {name}?',\n",
    "                    'context': opinions\n",
    "                }                \n",
    "            ]\n",
    "            \n",
    "            for question in questions:\n",
    "                answer = model(question)\n",
    "                print(answer, end='\\n\\n')\n",
    "                opinions = opinions.replace(answer['answer'], ' ')\n",
    "                answers.append(answer['answer'])\n",
    "                scores.append(answer['score'])\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        pass\n",
    "    finally:\n",
    "        return np.array(scores), np.array(answers)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "0276f869",
   "metadata": {
    "cellId": "tj9kfijlkp1efwz6ohkzn",
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 0.686664879322052, 'start': 5516, 'end': 5536, 'answer': ' прекрасная актриса,'}\n",
      "\n",
      "{'score': 0.5645750164985657, 'start': 6473, 'end': 6508, 'answer': ' отлично отыграла своего персонажа,'}\n",
      "\n",
      "{'score': 0.3694474995136261, 'start': 11617, 'end': 11652, 'answer': ' свежа, очаровательна и убедительна'}\n",
      "\n",
      "{'score': 0.3420935869216919, 'start': 12963, 'end': 12983, 'answer': ' стала Селиной Кайл.'}\n",
      "\n",
      "{'score': 0.4906530976295471, 'start': 12358, 'end': 12378, 'answer': ' Потрясающая, милая,'}\n",
      "\n",
      "{'score': 0.34241214394569397, 'start': 16342, 'end': 16356, 'answer': ' делает выбор,'}\n",
      "\n",
      "{'score': 0.327901154756546, 'start': 8010, 'end': 8039, 'answer': ' невероятно красивая женщина.'}\n",
      "\n",
      "{'score': 0.28490975499153137, 'start': 6804, 'end': 6818, 'answer': ' Неплохую игру'}\n",
      "\n",
      "{'score': 0.475708544254303, 'start': 14934, 'end': 14944, 'answer': ' милая Энн'}\n",
      "\n",
      "{'score': 0.15502893924713135, 'start': 2470, 'end': 2529, 'answer': ' занималась физическими упражнениями по пять дней в неделю,'}\n",
      "\n",
      "{'score': 0.4341236650943756, 'start': 14026, 'end': 14066, 'answer': ' своенравная, дерзкая, гордая и опасная,'}\n",
      "\n",
      "{'score': 0.6439129114151001, 'start': 2479, 'end': 2509, 'answer': ' изучала танцы и разные трюки,'}\n",
      "\n",
      "{'score': 0.4748254120349884, 'start': 3592, 'end': 3622, 'answer': ' одной из моих любимых актрис,'}\n",
      "\n",
      "{'score': 0.3841743767261505, 'start': 2784, 'end': 2813, 'answer': ' играла с переменным успехом,'}\n",
      "\n",
      "{'score': 0.5734874606132507, 'start': 15828, 'end': 15857, 'answer': ' обычной обаятельной девушки,'}\n",
      "\n",
      "{'score': 0.27950385212898254, 'start': 5517, 'end': 5552, 'answer': ' прекрасно справилась с этой ролью.'}\n",
      "\n",
      "{'score': 0.4629943072795868, 'start': 3436, 'end': 3473, 'answer': ' красивая, сексуальная и убедительная'}\n",
      "\n",
      "{'score': 0.31956905126571655, 'start': 3747, 'end': 3762, 'answer': ' актерскую игру'}\n",
      "\n",
      "{'score': 0.3682567775249481, 'start': 7986, 'end': 8037, 'answer': ' милая, обаятельная и мечтательная Белая Королева..'}\n",
      "\n",
      "{'score': 0.2939811050891876, 'start': 3765, 'end': 3820, 'answer': ' задача заключалась воплотить на экране Белую Королеву.'}\n",
      "\n",
      "{'score': 0.36561545729637146, 'start': 13313, 'end': 13334, 'answer': ' моя любимая актриса,'}\n",
      "\n",
      "{'score': 0.31441187858581543, 'start': 8994, 'end': 9015, 'answer': ' превзошла саму себя,'}\n",
      "\n",
      "{'score': 0.22582301497459412, 'start': 10860, 'end': 10868, 'answer': ' Андреа,'}\n",
      "\n",
      "{'score': 0.15268442034721375, 'start': 1078, 'end': 1116, 'answer': \" отлично сыграла 'блаженную' королеву,\"}\n",
      "\n",
      "{'score': 0.25098252296447754, 'start': 10860, 'end': 10880, 'answer': ' интересную героиню,'}\n",
      "\n",
      "{'score': 0.43385857343673706, 'start': 13314, 'end': 13357, 'answer': ' создав живого, привлекательного персонажа.'}\n",
      "\n",
      "{'score': 0.2403409481048584, 'start': 9635, 'end': 9645, 'answer': ' Красавица'}\n",
      "\n",
      "{'score': 0.24667702615261078, 'start': 13050, 'end': 13086, 'answer': ' с ролью она определенно справилась,'}\n",
      "\n",
      "{'score': 0.2396780550479889, 'start': 5392, 'end': 5464, 'answer': ' это девушка, которая может покорить любого парня своим только взглядом,'}\n",
      "\n",
      "{'score': 0.34348636865615845, 'start': 8605, 'end': 8644, 'answer': ' великолепно справилась со своей ролью,'}\n",
      "\n",
      "{'score': 0.21427685022354126, 'start': 3383, 'end': 3399, 'answer': ' она невероятна:'}\n",
      "\n",
      "{'score': 0.31904223561286926, 'start': 9004, 'end': 9040, 'answer': ' мастерски воплотила Энди на экране,'}\n",
      "\n",
      "{'score': 0.4610283374786377, 'start': 12322, 'end': 12336, 'answer': ' Кошка Хэтэуэй'}\n",
      "\n",
      "{'score': 0.17902222275733948, 'start': 8591, 'end': 8644, 'answer': ' отлично меняя личину симпатичной девушки на воровку,'}\n",
      "\n",
      "{'score': 0.287354975938797, 'start': 11519, 'end': 11535, 'answer': ' Женщину — кошку'}\n",
      "\n",
      "{'score': 0.14728978276252747, 'start': 10604, 'end': 10628, 'answer': ' сыграла очень не плохо,'}\n",
      "\n",
      "{'score': 0.42643898725509644, 'start': 12556, 'end': 12591, 'answer': ' покорительницы космической бездны.'}\n",
      "\n",
      "{'score': 0.1873778998851776, 'start': 11645, 'end': 11676, 'answer': ' отлично выполнила свою работу.'}\n",
      "\n",
      "{'score': 0.24944709241390228, 'start': 7177, 'end': 7189, 'answer': ' бесподобна,'}\n",
      "\n",
      "{'score': 0.1766200065612793, 'start': 10812, 'end': 10849, 'answer': ' исполнила эту роль просто прекрасно,'}\n",
      "\n",
      "{'score': 0.2363743633031845, 'start': 12201, 'end': 12216, 'answer': ' изящный эскиз,'}\n",
      "\n",
      "{'score': 0.1403174102306366, 'start': 9941, 'end': 9979, 'answer': ' очень хорошо изобразила женщину-кошку'}\n",
      "\n",
      "{'score': 0.21152985095977783, 'start': 6212, 'end': 6266, 'answer': ' маленькую, но отлично играющую без скидок на возраст,'}\n",
      "\n",
      "{'score': 0.2270262986421585, 'start': 9891, 'end': 9937, 'answer': ' достойно ответила всем скептикам своей игрой.'}\n",
      "\n",
      "{'score': 0.2603713572025299, 'start': 12401, 'end': 12416, 'answer': ' Женщины-кошки,'}\n",
      "\n",
      "{'score': 0.19377583265304565, 'start': 10407, 'end': 10443, 'answer': ' вошла в свою роль как нельзя лучше.'}\n",
      "\n",
      "{'score': 0.29940664768218994, 'start': 13204, 'end': 13238, 'answer': ' грациозная, гибкая, неприступная,'}\n",
      "\n",
      "{'score': 0.14550438523292542, 'start': 11366, 'end': 11409, 'answer': ' вполне достойно справилась со своей ролью.'}\n",
      "\n",
      "{'score': 0.30582451820373535, 'start': 13180, 'end': 13202, 'answer': ' очень притягательная.'}\n",
      "\n",
      "{'score': 0.28362607955932617, 'start': 11432, 'end': 11460, 'answer': ' сыграла она просто блестяще'}\n",
      "\n",
      "{'score': 0.22277139127254486, 'start': 9763, 'end': 9781, 'answer': ' чертовски хороша,'}\n",
      "\n",
      "{'score': 0.13239851593971252, 'start': 8962, 'end': 9004, 'answer': ' смогла адаптироваться в этом ритме жизни,'}\n",
      "\n",
      "{'score': 0.15738922357559204, 'start': 7142, 'end': 7193, 'answer': ' стервозной, грациозной и сексуальной женщины-кошки'}\n",
      "\n",
      "{'score': 0.24385419487953186, 'start': 7143, 'end': 7172, 'answer': ' удалась ей как нельзя лучше,'}\n",
      "\n",
      "{'score': 0.3884134590625763, 'start': 9757, 'end': 9780, 'answer': ' Героиня Хэтэуэй права,'}\n",
      "\n",
      "{'score': 0.21589715778827667, 'start': 12108, 'end': 12139, 'answer': ' великолепно воплотилась в роль'}\n",
      "\n",
      "{'score': 0.22933414578437805, 'start': 7919, 'end': 7941, 'answer': ' талантливой актрисой,'}\n",
      "\n",
      "{'score': 0.12417608499526978, 'start': 679, 'end': 740, 'answer': ' доказала, что замечательно подходит на роль роковой женщины.'}\n",
      "\n",
      "{'score': 0.5081639885902405, 'start': 7944, 'end': 7951, 'answer': ' Хороша'}\n",
      "\n",
      "{'score': 0.09469693154096603, 'start': 13339, 'end': 13373, 'answer': ' сыграла безупречно Женщину-кошку.'}\n",
      "\n",
      "{'score': 0.3091054856777191, 'start': 8675, 'end': 8698, 'answer': ' очаровательная и милая'}\n",
      "\n",
      "{'score': 0.10706759244203568, 'start': 11610, 'end': 11642, 'answer': ' не просто замечательно сыграла,'}\n",
      "\n",
      "{'score': 0.28037160634994507, 'start': 9423, 'end': 9463, 'answer': ' героиня жаждущая любить и быть любимой,'}\n",
      "\n",
      "{'score': 0.12735383212566376, 'start': 10168, 'end': 10223, 'answer': ' быть самой собой или стать такой же как ее начальница.'}\n",
      "\n",
      "{'score': 0.10764498263597488, 'start': 5303, 'end': 5315, 'answer': ' Энн Хэтэуэй'}\n",
      "\n",
      "{'score': 0.49952173233032227, 'start': 9345, 'end': 9386, 'answer': ' разрушила все законы квантовой механики.'}\n",
      "\n",
      "{'score': 0.4297102689743042, 'start': 6959, 'end': 6979, 'answer': ' взрослеющую звезду,'}\n",
      "\n",
      "{'score': 0.4491485059261322, 'start': 11052, 'end': 11081, 'answer': ' На удивление отлично сыграла'}\n",
      "\n",
      "{'score': 0.3103387951850891, 'start': 2801, 'end': 2818, 'answer': ' милой простушки.'}\n",
      "\n",
      "{'score': 0.49673032760620117, 'start': 2097, 'end': 2119, 'answer': ' сыграла замечательно.'}\n",
      "\n",
      "{'score': 0.30499643087387085, 'start': 9579, 'end': 9619, 'answer': ' слегка мальчишеском, гаврошевом образе,'}\n",
      "\n",
      "{'score': 0.12757211923599243, 'start': 2903, 'end': 2933, 'answer': ' все актеры сыграли на отлично'}\n",
      "\n",
      "{'score': 0.34681716561317444, 'start': 6902, 'end': 6921, 'answer': ' по плечу все роли.'}\n",
      "\n",
      "{'score': 0.3082945942878723, 'start': 10870, 'end': 10893, 'answer': ' прекрасно справляется,'}\n",
      "\n",
      "{'score': 0.47058555483818054, 'start': 6905, 'end': 6929, 'answer': ' была очень убедительна,'}\n",
      "\n",
      "{'score': 0.15312112867832184, 'start': 6906, 'end': 6949, 'answer': ' создав отличную гармоничную пару с Мэттью.'}\n",
      "\n",
      "{'score': 0.305991530418396, 'start': 12905, 'end': 12941, 'answer': ' достаточно готичной Белой королевы;'}\n",
      "\n",
      "{'score': 0.20511656999588013, 'start': 11331, 'end': 11355, 'answer': ' тяжко к ней готовилась,'}\n",
      "\n",
      "{'score': 0.2633085250854492, 'start': 5529, 'end': 5550, 'answer': ' довольно ограничена.'}\n",
      "\n",
      "{'score': 0.1586950272321701, 'start': 6838, 'end': 6882, 'answer': ' дала мне повод воспринимать её как  которой'}\n",
      "\n",
      "{'score': 0.3845245838165283, 'start': 12214, 'end': 12221, 'answer': ' Браво,'}\n",
      "\n",
      "{'score': 0.2482033222913742, 'start': 7582, 'end': 7612, 'answer': ' отлично умеющую менять маски,'}\n",
      "\n",
      "{'score': 0.2832922637462616, 'start': 6802, 'end': 6838, 'answer': ' Хэтэуэй   именно после этой картины'}\n",
      "\n",
      "{'score': 0.1847601681947708, 'start': 12076, 'end': 12123, 'answer': ' всё что она делала было на благо человечества,'}\n",
      "\n",
      "{'score': 0.3708743751049042, 'start': 12129, 'end': 12156, 'answer': ' 8 из 10    Белой королеве,'}\n",
      "\n",
      "{'score': 0.10193856060504913, 'start': 4781, 'end': 4805, 'answer': ' всегда исполняет на 5+,'}\n",
      "\n",
      "{'score': 0.2961641550064087, 'start': 8417, 'end': 8431, 'answer': ' очень хороша.'}\n",
      "\n",
      "{'score': 0.11593963205814362, 'start': 10370, 'end': 10381, 'answer': ' всем назло'}\n",
      "\n",
      "{'score': 0.15352165699005127, 'start': 4728, 'end': 4754, 'answer': ' пусть и не драматическая,'}\n",
      "\n",
      "{'score': 0.1017100140452385, 'start': 6902, 'end': 6917, 'answer': ' актерская игра'}\n",
      "\n",
      "{'score': 0.2872319519519806, 'start': 10365, 'end': 10384, 'answer': ' персонаж на вырост'}\n",
      "\n",
      "{'score': 0.09578395634889603, 'start': 8380, 'end': 8423, 'answer': ' Персонаж  очень гармонично влился в фильм,'}\n",
      "\n",
      "{'score': 0.1821221262216568, 'start': 12130, 'end': 12178, 'answer': ' известная по ряду превосходно исполненных ролей'}\n",
      "\n",
      "{'score': 0.06473815441131592, 'start': 11246, 'end': 11299, 'answer': ' она доказала, что она может думать не только о себе.'}\n",
      "\n",
      "{'score': 0.10191373527050018, 'start': 12116, 'end': 12164, 'answer': ' безумную правительницу белого мраморного замка.'}\n",
      "\n",
      "{'score': 0.30239543318748474, 'start': 12080, 'end': 12116, 'answer': ' способна блестяще воплотить в жизнь'}\n",
      "\n",
      "{'score': 0.10113240778446198, 'start': 12971, 'end': 13003, 'answer': ' Женщину-кошку образца XXI века.'}\n",
      "\n",
      "{'score': 0.17508690059185028, 'start': 12949, 'end': 12972, 'answer': ' достойно воспроизвела '}\n",
      "\n",
      "{'score': 0.266809344291687, 'start': 12232, 'end': 12271, 'answer': ' была уж слишком напыщенна и изнеженна.'}\n",
      "\n",
      "{'score': 0.20741663873195648, 'start': 12873, 'end': 12899, 'answer': ' превзошла Мишель Пфайфер,'}\n",
      "\n",
      "{'score': 0.0861188992857933, 'start': 7549, 'end': 7565, 'answer': ' Белой Королевы,'}\n",
      "\n",
      "{'score': 0.10713990032672882, 'start': 10121, 'end': 10130, 'answer': ' реализм.'}\n",
      "\n",
      "{'score': 0.16292643547058105, 'start': 7594, 'end': 7606, 'answer': ' прекрасная.'}\n",
      "\n",
      "{'score': 0.122649185359478, 'start': 9242, 'end': 9286, 'answer': ' демонстрируют запасы пороха в пороховницах,'}\n",
      "\n",
      "{'score': 0.4485721290111542, 'start': 9251, 'end': 9269, 'answer': ' губаста и упряма,'}\n",
      "\n",
      "{'score': 0.048471588641405106, 'start': 1036, 'end': 1096, 'answer': ' создала по-настоящему запоминающийся и притягательный образ'}\n",
      "\n",
      "{'score': 0.34693625569343567, 'start': 12110, 'end': 12137, 'answer': ' нежной, легкой, воздушной,'}\n",
      "\n",
      "{'score': 0.10391546040773392, 'start': 1037, 'end': 1058, 'answer': ' воровки Селины Кайл,'}\n",
      "\n",
      "{'score': 0.505405604839325, 'start': 1038, 'end': 1073, 'answer': ' Кошки, Которая Гуляет Сама По Себе'}\n",
      "\n",
      "{'score': 0.18881404399871826, 'start': 1131, 'end': 1166, 'answer': ' это тоже была очень серьезная роль'}\n",
      "\n",
      "{'score': 0.28160426020622253, 'start': 4808, 'end': 4848, 'answer': ' хрупкой, но решительной Белой Королевы.'}\n",
      "\n",
      "{'score': 0.23809632658958435, 'start': 10254, 'end': 10281, 'answer': ' очень гармонично смотрится'}\n",
      "\n",
      "{'score': 0.24333037436008453, 'start': 8417, 'end': 8442, 'answer': ' абсолютна,  безгранична,'}\n",
      "\n",
      "{'score': 0.23447120189666748, 'start': 10254, 'end': 10305, 'answer': ' вышло даже намного лучше, чем когда то у Пфайффер.'}\n",
      "\n",
      "{'score': 0.40403422713279724, 'start': 10256, 'end': 10300, 'answer': ' Возможно  немного не хватает сексуальности,'}\n",
      "\n",
      "{'score': 0.1954149454832077, 'start': 4901, 'end': 4939, 'answer': ' проникновенно сыграла Белую Королеву;'}\n",
      "\n",
      "{'score': 0.18605269491672516, 'start': 11284, 'end': 11300, 'answer': ' была на высоте,'}\n",
      "\n",
      "{'score': 0.1386607587337494, 'start': 1935, 'end': 1947, 'answer': ' непривычно,'}\n",
      "\n",
      "{'score': 0.22153271734714508, 'start': 4861, 'end': 4878, 'answer': ' очаровательная ,'}\n",
      "\n",
      "{'score': 0.24002839624881744, 'start': 4772, 'end': 4797, 'answer': ' прекрасно воплотила роль'}\n",
      "\n",
      "{'score': 0.3965749740600586, 'start': 7501, 'end': 7524, 'answer': ' неопытной и неуклюжей,'}\n",
      "\n",
      "{'score': 0.14391236007213593, 'start': 11385, 'end': 11431, 'answer': ' было отведено не так много экранного времени,'}\n",
      "\n",
      "{'score': 0.5211890935897827, 'start': 11386, 'end': 11411, 'answer': ' как её злобной сестрице,'}\n",
      "\n",
      "{'score': 0.1413448452949524, 'start': 4171, 'end': 4198, 'answer': ' сыграли свои роли шикарно,'}\n",
      "\n",
      "{'score': 0.12810897827148438, 'start': 9994, 'end': 10006, 'answer': ' Эн Хэтэуэй,'}\n",
      "\n",
      "{'score': 0.16337673366069794, 'start': 4445, 'end': 4494, 'answer': ' образ у      здесь был действительно жутковатый,'}\n",
      "\n",
      "{'score': 0.2192048579454422, 'start': 11277, 'end': 11288, 'answer': ' Хэтэуэй  !'}\n",
      "\n",
      "{'score': 0.32347720861434937, 'start': 8450, 'end': 8475, 'answer': ' сотворила чудо в финале,'}\n",
      "\n",
      "{'score': 0.422992467880249, 'start': 12077, 'end': 12093, 'answer': ' вполне вероятно'}\n",
      "\n",
      "{'score': 0.2091444730758667, 'start': 6794, 'end': 6802, 'answer': ' повезло'}\n",
      "\n",
      "{'score': 0.43263348937034607, 'start': 6819, 'end': 6872, 'answer': ' единственная женщина, которая получила двоякую роль,'}\n",
      "\n",
      "{'score': 0.20523716509342194, 'start': 6563, 'end': 6586, 'answer': \" в 'Дьявол носит prada'\"}\n",
      "\n",
      "{'score': 0.1311134546995163, 'start': 7795, 'end': 7820, 'answer': ' настоящая белая королева'}\n",
      "\n",
      "{'score': 0.047592103481292725, 'start': 5135, 'end': 5187, 'answer': ' Остальной актерский состав тоже держится на уровне,'}\n",
      "\n",
      "{'score': 0.5196651816368103, 'start': 5162, 'end': 5173, 'answer': ' прекрасную'}\n",
      "\n",
      "{'score': 0.11549067497253418, 'start': 6798, 'end': 6815, 'answer': ' она их приложила'}\n",
      "\n",
      "{'score': 0.24447205662727356, 'start': 4053, 'end': 4076, 'answer': ' чудесная Маккензи Фой,'}\n",
      "\n",
      "{'score': 0.09306250512599945, 'start': 4811, 'end': 4850, 'answer': ' создаёт чудесный образ белой королевы.'}\n",
      "\n",
      "{'score': 0.19493506848812103, 'start': 10236, 'end': 10275, 'answer': ' женщина-кошка была просто великолепна,'}\n",
      "\n",
      "{'score': 0.1171920895576477, 'start': 6694, 'end': 6735, 'answer': ' сыграть двоякость с небольшими усилиями,'}\n",
      "\n",
      "{'score': 0.18986643850803375, 'start': 9242, 'end': 9271, 'answer': ' героиня  столь же интересна,'}\n",
      "\n",
      "{'score': 0.08808787912130356, 'start': 6669, 'end': 6723, 'answer': ' талант Хэтэуэй позволяет  но  и вышло просто отлично.'}\n",
      "\n",
      "{'score': 0.22182761132717133, 'start': 11177, 'end': 11193, 'answer': ' весьма неплохо,'}\n",
      "\n",
      "{'score': 0.05685856565833092, 'start': 6644, 'end': 6662, 'answer': ' в данной трилогии'}\n",
      "\n",
      "{'score': 0.36718183755874634, 'start': 6645, 'end': 6652, 'answer': ' она  а'}\n",
      "\n",
      "{'score': 0.08671987801790237, 'start': 9307, 'end': 9372, 'answer': ' заполняет пространство вокруг себя сексуальным и дерзким шармом.'}\n",
      "\n",
      "{'score': 0.45748066902160645, 'start': 9267, 'end': 9293, 'answer': ' очень живые и динамичные,'}\n",
      "\n",
      "{'score': 0.04977790266275406, 'start': 5102, 'end': 5135, 'answer': ' Маккензи Фой   и   Мэтта Дэймона'}\n",
      "\n",
      "{'score': 0.7705545425415039, 'start': 5105, 'end': 5133, 'answer': ' в очень неожиданном образе.'}\n",
      "\n",
      "{'score': 0.2382839322090149, 'start': 9508, 'end': 9539, 'answer': ' Кошки и цели, и методы другие.'}\n",
      "\n",
      "{'score': 0.22112999856472015, 'start': 9209, 'end': 9238, 'answer': ' она буквально   Хэтэуэй   но'}\n",
      "\n",
      "{'score': 0.0936373919248581, 'start': 6735, 'end': 6765, 'answer': ' когда этого требует ситуация!'}\n",
      "\n",
      "{'score': 0.1220635399222374, 'start': 7559, 'end': 7592, 'answer': ' не покидала пределы лаборатории.'}\n",
      "\n",
      "{'score': 0.06579602509737015, 'start': 9540, 'end': 9582, 'answer': ' все рано она была достойна моего уважения'}\n",
      "\n",
      "{'score': 0.21439851820468903, 'start': 7563, 'end': 7595, 'answer': ' она заслуживает особой похвалы,'}\n",
      "\n",
      "{'score': 0.041669003665447235, 'start': 8375, 'end': 8424, 'answer': ' даря жизнь росткам более зрелого актерствования,'}\n",
      "\n",
      "{'score': 0.10520263761281967, 'start': 1836, 'end': 1855, 'answer': ' сексуальная особа,'}\n",
      "\n",
      "{'score': 0.03301868215203285, 'start': 8025, 'end': 8075, 'answer': ' она сыграла  которая встала перед сложным выбором'}\n",
      "\n",
      "{'score': 0.43649759888648987, 'start': 9441, 'end': 9456, 'answer': ' женщины-кошки,'}\n",
      "\n",
      "{'score': 0.12857505679130554, 'start': 1118, 'end': 1127, 'answer': ' для нее.'}\n",
      "\n",
      "{'score': 0.2396439015865326, 'start': 1953, 'end': 1987, 'answer': ' не менее яркая актриса Голливуда.'}\n",
      "\n",
      "{'score': 0.07317948341369629, 'start': 8399, 'end': 8422, 'answer': ' поколебать чаши весов,'}\n",
      "\n",
      "{'score': 0.13505864143371582, 'start': 1918, 'end': 1935, 'answer': ' такую яркую роль'}\n",
      "\n",
      "{'score': 0.05217939242720604, 'start': 3239, 'end': 3256, 'answer': ' выбрали именно ,'}\n",
      "\n",
      "{'score': 0.14283479750156403, 'start': 6827, 'end': 6842, 'answer': ' героиню      ,'}\n",
      "\n",
      "{'score': 0.13630416989326477, 'start': 8423, 'end': 8449, 'answer': ' прекращаю графонедержание'}\n",
      "\n",
      "{'score': 0.13187390565872192, 'start': 10397, 'end': 10437, 'answer': ' немного суховатым, немного жестковатыми'}\n",
      "\n",
      "{'score': 0.050895582884550095, 'start': 4953, 'end': 4994, 'answer': ' роль    отдельно хочется отметить      ;'}\n",
      "\n",
      "{'score': 0.1300959438085556, 'start': 6635, 'end': 6655, 'answer': ' я просто влюбилась,'}\n",
      "\n",
      "{'score': 0.04421365261077881, 'start': 1227, 'end': 1248, 'answer': ' первоклассную игру ,'}\n",
      "\n",
      "{'score': 0.16004081070423126, 'start': 4822, 'end': 4839, 'answer': ' Энн как до луны,'}\n",
      "\n",
      "{'score': 0.06375111639499664, 'start': 7790, 'end': 7823, 'answer': ' отошедшая от роли принцессы Мии,'}\n",
      "\n",
      "{'score': 0.1641116738319397, 'start': 7738, 'end': 7756, 'answer': ' физическое чудо –'}\n",
      "\n",
      "{'score': 0.04631666839122772, 'start': 1025, 'end': 1046, 'answer': ' (до поры до времени,'}\n",
      "\n",
      "{'score': 0.2100944221019745, 'start': 1026, 'end': 1036, 'answer': ' конечно).'}\n",
      "\n",
      "{'score': 0.10552721470594406, 'start': 2003, 'end': 2026, 'answer': ' сыграла очень красиво,'}\n",
      "\n",
      "{'score': 0.4769749641418457, 'start': 1727, 'end': 1765, 'answer': ' дерзкая, пластичная, веселая, хитрая,'}\n",
      "\n",
      "{'score': 0.1171308234333992, 'start': 6706, 'end': 6729, 'answer': ' обрести чувство стиля,'}\n",
      "\n",
      "{'score': 0.20136809349060059, 'start': 9465, 'end': 9520, 'answer': ' радует глаз не только внешностью, но и отличной игрой,'}\n",
      "\n",
      "{'score': 0.0954466238617897, 'start': 6739, 'end': 6792, 'answer': ' смогла заслужить одобрение своей суровой начальницы.'}\n",
      "\n",
      "{'score': 0.10941479355096817, 'start': 6662, 'end': 6693, 'answer': ' вначале казалась слишком юной,'}\n",
      "\n",
      "{'score': 0.060644447803497314, 'start': 6882, 'end': 6912, 'answer': \" решил сняться   'Марсианине.'\"}\n",
      "\n",
      "{'score': 0.15789780020713806, 'start': 6645, 'end': 6675, 'answer': ' которая  которая   но которая'}\n",
      "\n",
      "{'score': 0.21737466752529144, 'start': 6636, 'end': 6680, 'answer': ' Сыграла     а своим упорством и трудолюбием'}\n",
      "\n",
      "{'score': 0.16626983880996704, 'start': 6940, 'end': 6966, 'answer': ' не идеальна, но достойна.'}\n",
      "\n",
      "{'score': 0.031789008527994156, 'start': 4895, 'end': 4943, 'answer': ' показала , очень порадовала Хелена Бонем Картер'}\n",
      "\n",
      "{'score': 0.1003686711192131, 'start': 4917, 'end': 4939, 'answer': ' компьютерная модель),'}\n",
      "\n",
      "{'score': 0.07087940722703934, 'start': 7547, 'end': 7577, 'answer': ' в избранном ею  Литгоу и Кейн'}\n",
      "\n",
      "{'score': 0.0851326733827591, 'start': 2882, 'end': 2903, 'answer': ' образ Белой Королевы'}\n",
      "\n",
      "{'score': 0.044051505625247955, 'start': 7559, 'end': 7581, 'answer': ' Честейн  Маккензи Фой'}\n",
      "\n",
      "{'score': 0.17598187923431396, 'start': 2894, 'end': 2930, 'answer': ' проигрышный по отношению к Красной.'}\n",
      "\n",
      "{'score': 0.08340009301900864, 'start': 5956, 'end': 5981, 'answer': ' приятно удивила  Хэтэуэй'}\n",
      "\n",
      "{'score': 0.3158065378665924, 'start': 5902, 'end': 5942, 'answer': ' пожалуй самое главное украшение фильма.'}\n",
      "\n",
      "{'score': 0.15113501250743866, 'start': 9375, 'end': 9408, 'answer': ' искренне верила как своему отцу,'}\n",
      "\n",
      "{'score': 0.2623366415500641, 'start': 5838, 'end': 5855, 'answer': ' Безумный Шляпник'}\n",
      "\n",
      "{'score': 0.04996384307742119, 'start': 7438, 'end': 7465, 'answer': ' вовсю   втаптывает в пепел'}\n",
      "\n",
      "{'score': 0.1274760663509369, 'start': 5839, 'end': 5884, 'answer': ' в исполнении не менее безумного Джонни Деппа'}\n",
      "\n",
      "{'score': 0.06300003826618195, 'start': 7547, 'end': 7569, 'answer': ' сумеет весьма ощутимо'}\n",
      "\n",
      "{'score': 0.2096763551235199, 'start': 5803, 'end': 5842, 'answer': ' по моему мнению,              -  и   -'}\n",
      "\n",
      "{'score': 0.0431046262383461, 'start': 1926, 'end': 1964, 'answer': ' вносит свою лепту в атмосферу фильма.'}\n",
      "\n",
      "{'score': 0.14961545169353485, 'start': 9492, 'end': 9501, 'answer': ' 10 из 10'}\n",
      "\n",
      "{'score': 0.07526441663503647, 'start': 1106, 'end': 1141, 'answer': ' я рада была видеть в Интерстеллар,'}\n",
      "\n",
      "{'score': 0.06102140620350838, 'start': 4013, 'end': 4041, 'answer': ' очень люблю данную актрису,'}\n",
      "\n",
      "{'score': 0.13971403241157532, 'start': 7259, 'end': 7287, 'answer': ' прошлую «сумеречную» жизнь,'}\n",
      "\n",
      "{'score': 0.1873461902141571, 'start': 3986, 'end': 4005, 'answer': ' готичной королевы.'}\n",
      "\n",
      "{'score': 0.08369074016809464, 'start': 1119, 'end': 1150, 'answer': ' постоянно сталкиваюсь с Харди.'}\n",
      "\n",
      "{'score': 0.139555886387825, 'start': 2287, 'end': 2303, 'answer': ' жесткого босса,'}\n",
      "\n",
      "{'score': 0.09654630720615387, 'start': 3867, 'end': 3908, 'answer': ' игра мне понравилась вообще больше всех.'}\n",
      "\n",
      "{'score': 0.10808999836444855, 'start': 2200, 'end': 2213, 'answer': ' великолепна,'}\n",
      "\n",
      "{'score': 0.1499367356300354, 'start': 5959, 'end': 5983, 'answer': ' Также очень понравилась'}\n",
      "\n",
      "{'score': 0.11347489058971405, 'start': 2922, 'end': 2936, 'answer': ' женщины-кошки'}\n",
      "\n",
      "{'score': 0.10648071020841599, 'start': 6083, 'end': 6099, 'answer': ' сыграл отлично.'}\n",
      "\n",
      "{'score': 0.1964576542377472, 'start': 8761, 'end': 8771, 'answer': ' отличный,'}\n",
      "\n",
      "{'score': 0.16046638786792755, 'start': 6672, 'end': 6721, 'answer': ' окольцовывать и прошлое, и настоящее, и будущее,'}\n",
      "\n",
      "{'score': 0.29838845133781433, 'start': 5815, 'end': 5831, 'answer': ' сильно удивила,'}\n",
      "\n",
      "{'score': 0.04170827567577362, 'start': 5669, 'end': 5723, 'answer': ' роли романтичных, мечтательных и обаятельных девушек.'}\n",
      "\n",
      "{'score': 0.06541864573955536, 'start': 7613, 'end': 7649, 'answer': ' чья мотивация не до конца показана,'}\n",
      "\n",
      "{'score': 0.04262900725007057, 'start': 6020, 'end': 6063, 'answer': ' слилась с   МакКонахи   в отличный тандем.'}\n",
      "\n",
      "{'score': 0.12118616700172424, 'start': 6885, 'end': 6909, 'answer': ' на второстепенных ролях'}\n",
      "\n",
      "{'score': 0.3736749589443207, 'start': 6889, 'end': 6915, 'answer': ' Уэс Бентли играет мебель,'}\n",
      "\n",
      "{'score': 0.5676910281181335, 'start': 6890, 'end': 6902, 'answer': ' Мэтт Дэймон'}\n",
      "\n",
      "{'score': 0.42843344807624817, 'start': 6893, 'end': 6901, 'answer': ' удивил,'}\n",
      "\n",
      "{'score': 0.05391596630215645, 'start': 6894, 'end': 6942, 'answer': ' ни в одном трейлере и тизере вы его не найдете,'}\n",
      "\n",
      "{'score': 0.038315869867801666, 'start': 1123, 'end': 1156, 'answer': ' исполнившей роль Белой королевы.'}\n",
      "\n",
      "{'score': 0.16813482344150543, 'start': 6877, 'end': 6890, 'answer': ' его персонаж'}\n",
      "\n",
      "{'score': 0.12485739588737488, 'start': 3844, 'end': 3878, 'answer': ' было приятно следить за ее игрой,'}\n",
      "\n",
      "{'score': 0.07558603584766388, 'start': 4473, 'end': 4496, 'answer': ' во второстепенной роли'}\n",
      "\n",
      "{'score': 0.05901118367910385, 'start': 4467, 'end': 4500, 'answer': ' Также  было приятно видеть     .'}\n",
      "\n",
      "{'score': 0.2440655678510666, 'start': 4634, 'end': 4648, 'answer': ' книжная Алиса'}\n",
      "\n",
      "{'score': 0.033715683966875076, 'start': 6887, 'end': 6906, 'answer': ' в фильме исполнила'}\n",
      "\n",
      "{'score': 0.34408819675445557, 'start': 4635, 'end': 4698, 'answer': ' должна быть такой не эмоциональной и даже слегка инфернальной.'}\n",
      "\n",
      "{'score': 0.04862464964389801, 'start': 8753, 'end': 8798, 'answer': ' удалось очень хорошо войти в образ Энди Сакс'}\n",
      "\n",
      "{'score': 0.07592014223337173, 'start': 4927, 'end': 4942, 'answer': ' очаровательной'}\n",
      "\n",
      "{'score': 0.07158993929624557, 'start': 8825, 'end': 8865, 'answer': ' меняет свой образ, становится успешной,'}\n",
      "\n",
      "{'score': 0.08769790083169937, 'start': 8793, 'end': 8825, 'answer': ' готова работать с утра до ночи,'}\n",
      "\n",
      "{'score': 0.05929815024137497, 'start': 8752, 'end': 8793, 'answer': ' пытаясь удержаться в жестоком мире моды,'}\n",
      "\n",
      "{'score': 0.3647095263004303, 'start': 7710, 'end': 7740, 'answer': ' роль на самом деле небольшая.'}\n",
      "\n",
      "{'score': 0.05837597697973251, 'start': 6725, 'end': 6764, 'answer': ' еще долго не смогут найти равновесие,…'}\n",
      "\n",
      "{'score': 0.17348699271678925, 'start': 6711, 'end': 6725, 'answer': ' поколебанные,'}\n",
      "\n",
      "{'score': 0.06593510508537292, 'start': 6828, 'end': 6861, 'answer': ' Очень понравилась в своей роли ,'}\n",
      "\n",
      "{'score': 0.15404842793941498, 'start': 6692, 'end': 6711, 'answer': ' в фильме    и они,'}\n",
      "\n",
      "{'score': 0.037858039140701294, 'start': 6829, 'end': 6841, 'answer': ' лучшая роль'}\n",
      "\n",
      "{'score': 0.0965239405632019, 'start': 6687, 'end': 6740, 'answer': ' зато    впрочем,  ибо так до спойлеров рукой подать.'}\n",
      "\n",
      "{'score': 0.18170173466205597, 'start': 6743, 'end': 6753, 'answer': ' она     .'}\n",
      "\n",
      "{'score': 0.2545675039291382, 'start': 6751, 'end': 6791, 'answer': ' (это, пожалуй её  на сегодняшний день),'}\n",
      "\n",
      "{'score': 0.09554751217365265, 'start': 6876, 'end': 6931, 'answer': ' она отлично вписывается под фирменный прием режиссера,'}\n",
      "\n",
      "{'score': 0.1727832704782486, 'start': 6761, 'end': 6785, 'answer': ' легендарную Мэрил Стрип'}\n",
      "\n",
      "{'score': 0.14477306604385376, 'start': 6783, 'end': 6798, 'answer': ' её класс видно'}\n",
      "\n",
      "{'score': 0.22986064851284027, 'start': 6752, 'end': 6783, 'answer': ' ну а про  и говорить не нужно,'}\n",
      "\n",
      "{'score': 0.2798433005809784, 'start': 6754, 'end': 6788, 'answer': ' в каждом движении и каждой фразе.'}\n",
      "\n",
      "{'score': 0.05351366475224495, 'start': 6756, 'end': 6776, 'answer': ' Не сказать, что  но'}\n",
      "\n",
      "{'score': 0.04112718999385834, 'start': 7647, 'end': 7697, 'answer': ' расправляется с любыми сомнениями в вашей голове.'}\n",
      "\n",
      "{'score': 0.025529641658067703, 'start': 5960, 'end': 6004, 'answer': ' её печаль, какая то тревога и чувство вины,'}\n",
      "\n",
      "{'score': 0.023827916011214256, 'start': 8417, 'end': 8450, 'answer': \" 'покорил' ее начальницу Миранду.\"}\n",
      "\n",
      "{'score': 0.022659529000520706, 'start': 2610, 'end': 2677, 'answer': ' Красная Королева была более характерной и интересной нежели Белая,'}\n",
      "\n",
      "{'score': 0.0493132509291172, 'start': 5693, 'end': 5735, 'answer': \" ничуть не выпадала из 'веселой компании'.\"}\n",
      "\n",
      "{'score': 0.09424957633018494, 'start': 2294, 'end': 2319, 'answer': ' настоящая женщина-кошка,'}\n",
      "\n",
      "{'score': 0.050194110721349716, 'start': 2880, 'end': 2896, 'answer': ' подбор актёров,'}\n",
      "\n",
      "{'score': 0.11811036616563797, 'start': 3840, 'end': 3857, 'answer': ' отличный пример.'}\n",
      "\n",
      "{'score': 0.04428301751613617, 'start': 3989, 'end': 4019, 'answer': ' Великолепный актёрский состав'}\n",
      "\n",
      "{'score': 0.06000977382063866, 'start': 4134, 'end': 4158, 'answer': ' сексапильной   воровку,'}\n",
      "\n",
      "{'score': 0.05718318000435829, 'start': 3993, 'end': 4020, 'answer': ' работал над этой картиной:'}\n",
      "\n",
      "{'score': 0.07521630078554153, 'start': 4867, 'end': 4892, 'answer': ' браво!  Блестящая игра ,'}\n",
      "\n",
      "{'score': 0.037009287625551224, 'start': 7795, 'end': 7843, 'answer': ' он получился  и              7 из 10     в роли'}\n",
      "\n",
      "{'score': 0.09395921230316162, 'start': 6684, 'end': 6697, 'answer': ' она   в роли'}\n",
      "\n",
      "{'score': 0.02608564868569374, 'start': 6806, 'end': 6839, 'answer': ' если бы она не являлась таковой,'}\n",
      "\n",
      "{'score': 0.0642988309264183, 'start': 6803, 'end': 6813, 'answer': ' но   за ,'}\n",
      "\n",
      "{'score': 0.05431227385997772, 'start': 6812, 'end': 6831, 'answer': ' огромный потенциал'}\n",
      "\n",
      "{'score': 0.04215375334024429, 'start': 6830, 'end': 6845, 'answer': ' очень странно:'}\n",
      "\n",
      "{'score': 0.028060339391231537, 'start': 6531, 'end': 6560, 'answer': ' способности и внешний облик,'}\n",
      "\n",
      "{'score': 0.027258452028036118, 'start': 3139, 'end': 3171, 'answer': ' выглядит немного неестественно.'}\n",
      "\n",
      "{'score': 0.060855433344841, 'start': 4786, 'end': 4812, 'answer': ' восхитила и запомнилась ,'}\n",
      "\n",
      "{'score': 0.246485635638237, 'start': 6524, 'end': 6549, 'answer': ' сыгравшая в этом фильме,'}\n",
      "\n",
      "{'score': 0.023813683539628983, 'start': 1179, 'end': 1236, 'answer': ' Бедной      пришлось сначала поправиться, потом похудеть'}\n",
      "\n",
      "{'score': 0.02800881676375866, 'start': 5092, 'end': 5096, 'answer': ' Энн'}\n",
      "\n",
      "{'score': 0.06558176130056381, 'start': 4243, 'end': 4271, 'answer': ' может играть намного лучше,'}\n",
      "\n",
      "{'score': 0.06660418212413788, 'start': 4270, 'end': 4285, 'answer': ' Мия Васиковска'}\n",
      "\n",
      "{'score': 0.2184465527534485, 'start': 4273, 'end': 4307, 'answer': ' лично мне очень даже понравилась,'}\n",
      "\n",
      "{'score': 0.3695753514766693, 'start': 4251, 'end': 4268, 'answer': ' всеми обруганная'}\n",
      "\n",
      "{'score': 0.020527800545096397, 'start': 340, 'end': 377, 'answer': ' она просто была  игрива, сексуальна,'}\n",
      "\n",
      "{'score': 0.45466142892837524, 'start': 341, 'end': 387, 'answer': ' местами весёлая и очень очень опасная штучка.'}\n",
      "\n",
      "{'score': 0.18567876517772675, 'start': 6854, 'end': 6882, 'answer': ' поигрывая разными эмоциями,'}\n",
      "\n",
      "{'score': 0.07949942350387573, 'start': 83, 'end': 97, 'answer': ' актриса     ,'}\n",
      "\n",
      "{'score': 0.05181220546364784, 'start': 4113, 'end': 4144, 'answer': ' Джонни Депп неплохо смотрелся,'}\n",
      "\n",
      "{'score': 0.09211672842502594, 'start': 4888, 'end': 4914, 'answer': ' очень хорошо удаются    ,'}\n",
      "\n",
      "{'score': 0.03666360303759575, 'start': 6787, 'end': 6816, 'answer': ' она так легко запоминается и'}\n",
      "\n",
      "{'score': 0.08541163802146912, 'start': 47, 'end': 83, 'answer': ' никому еще так хорошо не известная,'}\n",
      "\n",
      "{'score': 0.14912049472332, 'start': 2834, 'end': 2870, 'answer': ' размышляет вслух о высших материях,'}\n",
      "\n",
      "{'score': 0.11149275302886963, 'start': 3998, 'end': 4008, 'answer': ' хоть и её'}\n",
      "\n",
      "{'score': 0.04795291647315025, 'start': 5060, 'end': 5099, 'answer': ' мне непривычно видеть ее в такой роли,'}\n",
      "\n",
      "{'score': 0.1498195230960846, 'start': 4810, 'end': 4843, 'answer': ' лучше, нежели Мегги Джилленхаал,'}\n",
      "\n",
      "{'score': 0.028723105788230896, 'start': 5, 'end': 35, 'answer': ' главную роль здесь исполняет,'}\n",
      "\n",
      "{'score': 0.09891212731599808, 'start': 4001, 'end': 4019, 'answer': ' ее   хотя  и даже'}\n",
      "\n",
      "{'score': 0.035212621092796326, 'start': 1986, 'end': 2017, 'answer': ' великолепно выглядела в образе'}\n",
      "\n",
      "{'score': 0.11650796234607697, 'start': 6770, 'end': 6780, 'answer': ' героиней,'}\n",
      "\n",
      "{'score': 0.04760080948472023, 'start': 4860, 'end': 4884, 'answer': ' вопреки моим ожиданиям,'}\n",
      "\n",
      "{'score': 0.0891982838511467, 'start': 28, 'end': 82, 'answer': ' с недавних пор числится в моем списку любимых актрис.'}\n",
      "\n",
      "{'score': 0.043766796588897705, 'start': 2090, 'end': 2148, 'answer': ' достойно вписались в последний фильм нолановской трилогии'}\n",
      "\n",
      "{'score': 0.31836825609207153, 'start': 323, 'end': 376, 'answer': ' хитрой и соблазнительной воровки с инстинктами кошки'}\n",
      "\n",
      "{'score': 0.09113568067550659, 'start': 243, 'end': 282, 'answer': ' потрясающие акробатические возможности'}\n",
      "\n",
      "{'score': 0.20844997465610504, 'start': 3753, 'end': 3771, 'answer': ' (по крайней мере,'}\n",
      "\n",
      "{'score': 0.03863564506173134, 'start': 3868, 'end': 3913, 'answer': ' МакКонахи является душой «  Интерстеллара  »'}\n",
      "\n",
      "{'score': 0.26005545258522034, 'start': 3885, 'end': 3920, 'answer': ' клеем, который держит все воедино.'}\n",
      "\n",
      "{'score': 0.04821993410587311, 'start': 3887, 'end': 3938, 'answer': ' Он как всегда интересен, как всегда не подорожаем,'}\n",
      "\n",
      "{'score': 0.0998542308807373, 'start': 3930, 'end': 3984, 'answer': ' появление которой вызывает одни положительные эмоции.'}\n",
      "\n",
      "{'score': 0.03844691440463066, 'start': 3908, 'end': 3963, 'answer': ' не меркнет на фоне  ,   Но больше всего меня поразила,'}\n",
      "\n",
      "{'score': 0.03352750465273857, 'start': 2177, 'end': 2188, 'answer': ' изначально'}\n",
      "\n",
      "{'score': 0.07338123768568039, 'start': 2282, 'end': 2315, 'answer': ' смотрелись в кадре замечательно.'}\n",
      "\n",
      "{'score': 0.11795949935913086, 'start': 5888, 'end': 5926, 'answer': ' замечательно смотрится в образе Кошки'}\n",
      "\n",
      "{'score': 0.039978135377168655, 'start': 5828, 'end': 5883, 'answer': ' не утратила человеческих чувств и чувство сострадания,'}\n",
      "\n",
      "{'score': 0.1059742346405983, 'start': 2211, 'end': 2235, 'answer': ' в образе Белой Королевы'}\n",
      "\n",
      "{'score': 0.03619753569364548, 'start': 244, 'end': 272, 'answer': ' дают пикантности её образу.'}\n",
      "\n",
      "{'score': 0.08833786845207214, 'start': 1034, 'end': 1094, 'answer': ' Впечатлила     , которая уже второй раз работает с Ноланом,'}\n",
      "\n",
      "{'score': 0.04901205375790596, 'start': 49, 'end': 95, 'answer': ' изображенная ею излишняя нежность и движения,'}\n",
      "\n",
      "{'score': 0.147274911403656, 'start': 1187, 'end': 1202, 'answer': ' Белой королевы'}\n",
      "\n",
      "{'score': 0.03552747890353203, 'start': 5045, 'end': 5089, 'answer': ' трудно поставить на ее место кого-то иного.'}\n",
      "\n",
      "{'score': 0.045972928404808044, 'start': 4073, 'end': 4094, 'answer': ' да только Хэтэуэй  —'}\n",
      "\n",
      "{'score': 0.027112973853945732, 'start': 5874, 'end': 5919, 'answer': ' она мне очень понравилась как своей улыбкой,'}\n",
      "\n",
      "{'score': 0.23267105221748352, 'start': 5809, 'end': 5817, 'answer': ' плохой,'}\n",
      "\n",
      "{'score': 0.019709134474396706, 'start': 2069, 'end': 2085, 'answer': ' Миа Васиковска,'}\n",
      "\n",
      "{'score': 0.03146371617913246, 'start': 6417, 'end': 6443, 'answer': ' Сейчас еще трудно судить,'}\n",
      "\n",
      "{'score': 0.10669966787099838, 'start': 2078, 'end': 2097, 'answer': ' сыграла саму Алису'}\n",
      "\n",
      "{'score': 0.04906151071190834, 'start': 2024, 'end': 2040, 'answer': ' просто     Еще,'}\n",
      "\n",
      "{'score': 0.05720067024230957, 'start': 6362, 'end': 6380, 'answer': ' заслужил уважение'}\n",
      "\n",
      "{'score': 0.14261122047901154, 'start': 6380, 'end': 6404, 'answer': ' если и не  но уж точно '}\n",
      "\n",
      "{'score': 0.037116799503564835, 'start': 6109, 'end': 6125, 'answer': ' Картер отыграли'}\n",
      "\n",
      "{'score': 0.06418371200561523, 'start': 6353, 'end': 6356, 'answer': ' но'}\n",
      "\n",
      "{'score': 0.110008604824543, 'start': 3016, 'end': 3028, 'answer': ' свои роли в'}\n",
      "\n",
      "{'score': 0.15834015607833862, 'start': 2030, 'end': 2034, 'answer': ' чья'}\n",
      "\n",
      "{'score': 0.043372735381126404, 'start': 2051, 'end': 2069, 'answer': ' Очень обрадовало,'}\n",
      "\n",
      "{'score': 0.13030296564102173, 'start': 2020, 'end': 2030, 'answer': ' отмечу  ,'}\n",
      "\n",
      "{'score': 0.04007047787308693, 'start': 2068, 'end': 2085, 'answer': ' было неоспоримо.'}\n",
      "\n",
      "{'score': 0.09138351678848267, 'start': 2043, 'end': 2055, 'answer': ' что на роль'}\n",
      "\n",
      "{'score': 0.150303915143013, 'start': 2059, 'end': 2099, 'answer': ' Не маловажную роль похода на этот фильм'}\n",
      "\n",
      "{'score': 0.10703667998313904, 'start': 2011, 'end': 2020, 'answer': ' пожалуй,'}\n",
      "\n",
      "{'score': 0.15130314230918884, 'start': 2052, 'end': 2082, 'answer': ' сыграл и  , Мэттью МакКонахи,'}\n",
      "\n",
      "{'score': 0.04675544798374176, 'start': 5144, 'end': 5183, 'answer': ' я не могу относиться к ней объективно,'}\n",
      "\n",
      "{'score': 0.15137381851673126, 'start': 5991, 'end': 6005, 'answer': ' массу ошибок,'}\n",
      "\n",
      "{'score': 0.03683014586567879, 'start': 4209, 'end': 4232, 'answer': ' доброта и отзывчивость'}\n",
      "\n",
      "{'score': 0.18892014026641846, 'start': 5978, 'end': 6036, 'answer': ' вовремя понимает, что гламурный мир - не главное в жизни,'}\n",
      "\n",
      "{'score': 0.15836720168590546, 'start': 5981, 'end': 6013, 'answer': \" роль 'гламазонки' - не для нее,\"}\n",
      "\n",
      "{'score': 0.052206601947546005, 'start': 2094, 'end': 2124, 'answer': ' с до смеха недавнего периода,'}\n",
      "\n",
      "{'score': 0.03649880364537239, 'start': 5110, 'end': 5131, 'answer': ' Также  чувствуется у'}\n",
      "\n",
      "{'score': 0.025451168417930603, 'start': 5062, 'end': 5085, 'answer': ' Хотелось бы отметить ,'}\n",
      "\n",
      "{'score': 0.0345931276679039, 'start': 3962, 'end': 3976, 'answer': ' настолько она'}\n",
      "\n",
      "{'score': 0.021749909967184067, 'start': 4110, 'end': 4137, 'answer': ' Все смотрелись гармонично.'}\n",
      "\n",
      "{'score': 0.11571333557367325, 'start': 5016, 'end': 5032, 'answer': ' у её    вообще,'}\n",
      "\n",
      "{'score': 0.058667514473199844, 'start': 5040, 'end': 5080, 'answer': ' рассказывала во многочисленных интервью'}\n",
      "\n",
      "{'score': 0.348482221364975, 'start': 5018, 'end': 5030, 'answer': ' так как она'}\n",
      "\n",
      "{'score': 0.01543028187006712, 'start': 5047, 'end': 5075, 'answer': ' вымечтана ею была эта роль,'}\n",
      "\n",
      "{'score': 0.17643585801124573, 'start': 5067, 'end': 5086, 'answer': ' в роли Селины Кайл'}\n",
      "\n",
      "{'score': 0.04271962121129036, 'start': 5030, 'end': 5062, 'answer': ' о том, насколько  как  смотришь'}\n",
      "\n",
      "{'score': 0.060533251613378525, 'start': 5058, 'end': 5109, 'answer': ' она  и     —   в то же время    в отличии от самой'}\n",
      "\n",
      "{'score': 0.05138678476214409, 'start': 5011, 'end': 5043, 'answer': ' ведь          и     —     —  её'}\n",
      "\n",
      "{'score': 0.11480339616537094, 'start': 5065, 'end': 5103, 'answer': ' персонаж более глубокий и интересный)'}\n",
      "\n",
      "{'score': 0.008399424143135548, 'start': 3455, 'end': 3466, 'answer': ' она  роль,'}\n",
      "\n",
      "{'score': 0.07680145651102066, 'start': 4930, 'end': 4978, 'answer': ' кто бы мог представить себе ее в подобной роли,'}\n",
      "\n",
      "{'score': 0.01963203400373459, 'start': 2056, 'end': 2114, 'answer': ' ростом которого я слежу честно говоря  периода 2012 года.'}\n",
      "\n",
      "{'score': 0.3233948349952698, 'start': 2058, 'end': 2078, 'answer': ' Оно конечно хорошо,'}\n",
      "\n",
      "{'score': 0.04414505884051323, 'start': 2077, 'end': 2116, 'answer': ' любовь, посреди неизвестной Галактики,'}\n",
      "\n",
      "{'score': 0.05836205556988716, 'start': 5405, 'end': 5465, 'answer': ' которая,    несмотря на   все же  а  и  который все-таки  и'}\n",
      "\n",
      "{'score': 0.03623553737998009, 'start': 4037, 'end': 4067, 'answer': ' немного переигрывает местами,'}\n",
      "\n",
      "{'score': 0.03971824795007706, 'start': 2201, 'end': 2237, 'answer': ' отношения профессора и его ученицы.'}\n",
      "\n",
      "{'score': 0.04830748587846756, 'start': 4709, 'end': 4742, 'answer': ' разовьются в продолжении фильма.'}\n",
      "\n",
      "{'score': 0.015671340748667717, 'start': 4131, 'end': 4181, 'answer': ' единственная валюта, что мы имеем это наша любовь'}\n",
      "\n",
      "{'score': 0.17374944686889648, 'start': 4586, 'end': 4619, 'answer': ' Все сцены с участием Хэтэуэй   и'}\n",
      "\n",
      "{'score': 0.018512172624468803, 'start': 4020, 'end': 4046, 'answer': ' которая за всю свою жизнь'}\n",
      "\n",
      "{'score': 0.01412153523415327, 'start': 4149, 'end': 4185, 'answer': ' любовь может проникать сквозь время'}\n",
      "\n",
      "{'score': 0.17830313742160797, 'start': 4191, 'end': 4198, 'answer': ' ничто.'}\n",
      "\n",
      "{'score': 0.012381183914840221, 'start': 2113, 'end': 2183, 'answer': ' Другие взаимоотношения отца и дочери воплощают      и   Майкл Кейн  ,'}\n",
      "\n",
      "{'score': 0.08481880277395248, 'start': 4144, 'end': 4183, 'answer': ' любовь, проникнув сквозь все преграды,'}\n",
      "\n",
      "{'score': 0.00916924886405468, 'start': 5061, 'end': 5070, 'answer': ' Хэтэуэй '}\n",
      "\n",
      "{'score': 0.15425482392311096, 'start': 4024, 'end': 4041, 'answer': ' как и Вселенная,'}\n",
      "\n",
      "{'score': 0.12319494038820267, 'start': 3975, 'end': 3997, 'answer': ' выбором  на эту роль,'}\n",
      "\n",
      "{'score': 0.1166047528386116, 'start': 3998, 'end': 4053, 'answer': ' она   только  и  все остальное в сравнении с вечностью'}\n",
      "\n",
      "{'score': 0.020093975588679314, 'start': 267, 'end': 299, 'answer': ' наивность, доброта и жизнелюбие'}\n",
      "\n",
      "{'score': 0.13656631112098694, 'start': 219, 'end': 267, 'answer': ' безграничной надменности, сухости противостояла'}\n",
      "\n",
      "{'score': 0.03176375851035118, 'start': 282, 'end': 306, 'answer': ' очень достойно обыгран.'}\n",
      "\n",
      "{'score': 0.14178891479969025, 'start': 4353, 'end': 4365, 'answer': ' такую как .'}\n",
      "\n",
      "{'score': 0.010267533361911774, 'start': 3296, 'end': 3322, 'answer': ' невозможно оторвать глаз,'}\n",
      "\n",
      "{'score': 0.05920375883579254, 'start': 4162, 'end': 4208, 'answer': ' отчего-то мне кажется  —   а  думаю    так же'}\n",
      "\n",
      "{'score': 0.05821750685572624, 'start': 4170, 'end': 4179, 'answer': ' Хэтэуэй,'}\n",
      "\n",
      "{'score': 0.6357874870300293, 'start': 3087, 'end': 3108, 'answer': ' Хелены Бонем Картер,'}\n",
      "\n",
      "{'score': 0.1334335058927536, 'start': 4627, 'end': 4646, 'answer': ' больше экспрессии.'}\n",
      "\n",
      "{'score': 0.30393385887145996, 'start': 2777, 'end': 2789, 'answer': ' Холли Берри'}\n",
      "\n",
      "{'score': 0.037232428789138794, 'start': 1276, 'end': 1294, 'answer': ' белоснежная     ,'}\n",
      "\n",
      "{'score': 0.03295750916004181, 'start': 2118, 'end': 2143, 'answer': ' современный Исаак Ньютон'}\n",
      "\n",
      "{'score': 0.03775975480675697, 'start': 1282, 'end': 1306, 'answer': ' её было совсем немного.'}\n",
      "\n",
      "{'score': 0.03805404528975487, 'start': 2182, 'end': 2194, 'answer': ' Мэрил Стрип'}\n",
      "\n",
      "{'score': 0.04667288810014725, 'start': 2299, 'end': 2329, 'answer': ' приятно удивила своим образом'}\n",
      "\n",
      "{'score': 0.017361588776111603, 'start': 3163, 'end': 3172, 'answer': ' которая,'}\n",
      "\n",
      "{'score': 0.0046058399602770805, 'start': 4390, 'end': 4435, 'answer': ' выйти из зала в некоей эйфории от просмотра,'}\n",
      "\n",
      "{'score': 0.013760917820036411, 'start': 1003, 'end': 1035, 'answer': ' с интересным взглядом на жизнь.'}\n",
      "\n",
      "{'score': 0.008696445263922215, 'start': 2094, 'end': 2147, 'answer': ' предстоит еще не раз показать себя на наших экранах.'}\n",
      "\n",
      "{'score': 0.018160583451390266, 'start': 4116, 'end': 4129, 'answer': ' Амелия Бренд'}\n",
      "\n",
      "{'score': 0.005913113243877888, 'start': 1278, 'end': 1284, 'answer': ' игру,'}\n",
      "\n",
      "{'score': 0.020094437524676323, 'start': 30, 'end': 72, 'answer': ' У  мне понравилась  настолько грациозные,'}\n",
      "\n",
      "{'score': 0.035872410982847214, 'start': 3305, 'end': 3350, 'answer': ' Майкл Кейн   сыграл хитрого старика-ученого,'}\n",
      "\n",
      "{'score': 0.02481880970299244, 'start': 57, 'end': 69, 'answer': ' она плывет.'}\n",
      "\n",
      "{'score': 0.041095297783613205, 'start': 1249, 'end': 1319, 'answer': ' отлично показала, как сложно приходится провинциалке в большом городе'}\n",
      "\n",
      "{'score': 0.03985665366053581, 'start': 1073, 'end': 1090, 'answer': ' очень сексуально'}\n",
      "\n",
      "{'score': 0.05024437606334686, 'start': 4150, 'end': 4179, 'answer': ' Картер наверно даже получше,'}\n",
      "\n",
      "{'score': 0.05130569636821747, 'start': 3138, 'end': 3167, 'answer': ' она        в роли  в которую'}\n",
      "\n",
      "{'score': 0.025454627349972725, 'start': 117, 'end': 145, 'answer': ' идеально смотрится в образе'}\n",
      "\n",
      "{'score': 0.40499553084373474, 'start': 3075, 'end': 3109, 'answer': ' мрачный и весьма серьезный фильм,'}\n",
      "\n",
      "{'score': 0.02911779284477234, 'start': 3124, 'end': 3168, 'answer': ' Мэтту Дэймону  настолько понравился космос,'}\n",
      "\n",
      "{'score': 0.05147339776158333, 'start': 3143, 'end': 3192, 'answer': ' Далее  - ,  с другой стороны  -  -   , по моему,'}\n",
      "\n",
      "{'score': 0.016417156904935837, 'start': 1367, 'end': 1399, 'answer': ' кто  то тут же появляется ответ'}\n",
      "\n",
      "{'score': 0.056156307458877563, 'start': 1134, 'end': 1150, 'answer': ' мне понравилась'}\n",
      "\n",
      "{'score': 0.01450338214635849, 'start': 3863, 'end': 3878, 'answer': ' пойти еще раз,'}\n",
      "\n",
      "{'score': 0.03025394305586815, 'start': 3290, 'end': 3327, 'answer': ' весь актерский состав очень сильный:'}\n",
      "\n",
      "{'score': 0.007504986133426428, 'start': 872, 'end': 905, 'answer': ' Каждое мгновение сыграно на 100%'}\n",
      "\n",
      "{'score': 0.019134163856506348, 'start': 1323, 'end': 1332, 'answer': ' Хэтэуэй.'}\n",
      "\n",
      "{'score': 0.010249380022287369, 'start': 2402, 'end': 2442, 'answer': ' Холли природа одарила большей красотой.'}\n",
      "\n",
      "{'score': 0.016277538612484932, 'start': 1409, 'end': 1472, 'answer': ' идеальное сочетание качеств для исполнения роли женщин -кошки.'}\n",
      "\n",
      "{'score': 0.019796356558799744, 'start': 2106, 'end': 2138, 'answer': ' в обтягивающем кожаном костюме.'}\n",
      "\n",
      "{'score': 0.051367782056331635, 'start': 1060, 'end': 1095, 'answer': ' украшенной потрясающими костюмами.'}\n",
      "\n",
      "{'score': 0.03218255564570427, 'start': 1106, 'end': 1123, 'answer': ' мне понравилось.'}\n",
      "\n",
      "{'score': 0.026021571829915047, 'start': 1110, 'end': 1160, 'answer': \" среди людей, которым глубоко 'наплевать' на тебя.\"}\n",
      "\n",
      "{'score': 0.009033926762640476, 'start': 1112, 'end': 1157, 'answer': ' И даже  была  чего я, признаюсь, не ожидала.'}\n",
      "\n",
      "{'score': 0.04899660870432854, 'start': 1114, 'end': 1121, 'answer': ' Кстати'}\n",
      "\n",
      "{'score': 0.0385558195412159, 'start': 1033, 'end': 1060, 'answer': ' благодаря своей внешности,'}\n",
      "\n",
      "{'score': 0.017325803637504578, 'start': 1301, 'end': 1309, 'answer': ' которая'}\n",
      "\n",
      "{'score': 0.03335846588015556, 'start': 1691, 'end': 1705, 'answer': ' Стэнли Туччи,'}\n",
      "\n",
      "{'score': 0.09302308410406113, 'start': 2338, 'end': 2356, 'answer': ' Саши Барона Коэна'}\n",
      "\n",
      "{'score': 0.02267412841320038, 'start': 2607, 'end': 2631, 'answer': ' она не впишется в такой'}\n",
      "\n",
      "{'score': 0.013911211863160133, 'start': 1165, 'end': 1200, 'answer': ' Котийяр, Гордон-Левитт  о Бэтмене.'}\n",
      "\n",
      "{'score': 0.013127168640494347, 'start': 765, 'end': 802, 'answer': ' ее образ был самым сложным в фильме,'}\n",
      "\n",
      "{'score': 0.07305845618247986, 'start': 1466, 'end': 1483, 'answer': ' Джессика Честейн'}\n",
      "\n",
      "{'score': 0.029499320313334465, 'start': 879, 'end': 915, 'answer': ' Я очень рад, что  получила именно ,'}\n",
      "\n",
      "{'score': 0.08235052227973938, 'start': 1332, 'end': 1367, 'answer': ' представительницы прекрасного пола'}\n",
      "\n",
      "{'score': 0.008009109646081924, 'start': 2168, 'end': 2193, 'answer': ' снова заставляет зрителя'}\n",
      "\n",
      "{'score': 0.02793211117386818, 'start': 2373, 'end': 2394, 'answer': ' Что касается актеров'}\n",
      "\n",
      "{'score': 0.34852486848831177, 'start': 2169, 'end': 2212, 'answer': ' окунуться в потрясающую атмосферу безумия.'}\n",
      "\n",
      "{'score': 0.014785220846533775, 'start': 2316, 'end': 2350, 'answer': ' которой         то  меня  я думал'}\n",
      "\n",
      "{'score': 0.0364077128469944, 'start': 2171, 'end': 2229, 'answer': ' Когда она в кадре от нее  несмотря на близкое присутствие'}\n",
      "\n",
      "{'score': 0.013322021812200546, 'start': 1295, 'end': 1320, 'answer': ' Не менее запоминающимися'}\n",
      "\n",
      "{'score': 0.28798091411590576, 'start': 2171, 'end': 2218, 'answer': ' посмотрев еще несколько фильмов с ее участием,'}\n",
      "\n",
      "{'score': 0.010435448959469795, 'start': 231, 'end': 299, 'answer': ' почти все девушки в фильме внешне привлекательнее главной героини))'}\n",
      "\n",
      "{'score': 0.027584997937083244, 'start': 2217, 'end': 2271, 'answer': ' несмотря на все несогласие поклонников трилогии с   и'}\n",
      "\n",
      "{'score': 0.02412642538547516, 'start': 232, 'end': 263, 'answer': ' Особенно близняшки понравились'}\n",
      "\n",
      "{'score': 0.01318697351962328, 'start': 2690, 'end': 2716, 'answer': ' по его глазам было видно.'}\n",
      "\n",
      "{'score': 0.009986832737922668, 'start': 233, 'end': 251, 'answer': ' (которые девушки)'}\n",
      "\n",
      "{'score': 0.01793971285223961, 'start': 2702, 'end': 2719, 'answer': ' было достаточно,'}\n",
      "\n",
      "{'score': 0.008793432265520096, 'start': 2570, 'end': 2580, 'answer': ' персонаж,'}\n",
      "\n",
      "{'score': 0.01995205692946911, 'start': 2694, 'end': 2732, 'answer': ' для демонстрации того простого факта,'}\n",
      "\n",
      "{'score': 0.031212380155920982, 'start': 1451, 'end': 1463, 'answer': ' грима лица.'}\n",
      "\n",
      "{'score': 0.011804437264800072, 'start': 1453, 'end': 1494, 'answer': ' Во-первых      такого рода  и этот фильм'}\n",
      "\n",
      "{'score': 0.004557858686894178, 'start': 1198, 'end': 1238, 'answer': ' со своим глубоким непостижимым взглядом'}\n",
      "\n",
      "{'score': 0.2524389326572418, 'start': 1201, 'end': 1220, 'answer': ' монологом о любви,'}\n",
      "\n",
      "{'score': 0.00635408004745841, 'start': 1258, 'end': 1325, 'answer': ' сложно наверное было бы найти более подходящих на эти роли актеров'}\n",
      "\n",
      "{'score': 0.012574891559779644, 'start': 1192, 'end': 1212, 'answer': ' и  —   и   а-ля  и,'}\n",
      "\n",
      "{'score': 0.021999644115567207, 'start': 192, 'end': 205, 'answer': ' Про актёров.'}\n",
      "\n",
      "{'score': 0.017020873725414276, 'start': 1444, 'end': 1486, 'answer': ' своими огромными глазами и телодвижениями'}\n",
      "\n",
      "{'score': 0.004104702267795801, 'start': 195, 'end': 204, 'answer': ' Парадокс'}\n",
      "\n",
      "{'score': 0.05840863659977913, 'start': 294, 'end': 329, 'answer': ' При всем моем предвзятом отношении'}\n",
      "\n",
      "{'score': 0.027836021035909653, 'start': 295, 'end': 317, 'answer': ' к маленькой принцессе'}\n",
      "\n",
      "{'score': 0.008785642683506012, 'start': 667, 'end': 686, 'answer': ' в роли  смотрелась'}\n",
      "\n",
      "{'score': 0.006505381315946579, 'start': 1100, 'end': 1126, 'answer': ' конечно же,  которой явно'}\n",
      "\n",
      "{'score': 0.010633453726768494, 'start': 1389, 'end': 1418, 'answer': ' в роли  в одноимённом фильме'}\n",
      "\n",
      "{'score': 0.010073996149003506, 'start': 590, 'end': 604, 'answer': ' много чувств,'}\n",
      "\n",
      "{'score': 0.014755076728761196, 'start': 340, 'end': 371, 'answer': ' Был невозможно приятно удивлен'}\n",
      "\n",
      "{'score': 0.013059441931545734, 'start': 147, 'end': 170, 'answer': ' довольно тонкий момент'}\n",
      "\n",
      "{'score': 0.017529435455799103, 'start': 350, 'end': 371, 'answer': \" Дьявол сит Прада  ',\"}\n",
      "\n",
      "{'score': 0.0170097965747118, 'start': 1321, 'end': 1338, 'answer': ' она не виновата,'}\n",
      "\n",
      "{'score': 0.01860802061855793, 'start': 194, 'end': 229, 'answer': ' сам ее образ раскрыт не полностью,'}\n",
      "\n",
      "{'score': 0.036826033145189285, 'start': 177, 'end': 189, 'answer': ' на мой вкус'}\n",
      "\n",
      "{'score': 0.013069376349449158, 'start': 274, 'end': 296, 'answer': ' появлением в фильме .'}\n",
      "\n",
      "{'score': 0.004766284953802824, 'start': 1361, 'end': 1373, 'answer': ' Майкл Кейн,'}\n",
      "\n",
      "{'score': 0.007228996139019728, 'start': 289, 'end': 335, 'answer': ' нельзя ни в коем случае пропустить мимо глаз,'}\n",
      "\n",
      "{'score': 0.05732208862900734, 'start': 290, 'end': 365, 'answer': ' потому что каждая женщина знает, как сложно дается любое усилие над собой,'}\n",
      "\n",
      "{'score': 0.004708411637693644, 'start': 1293, 'end': 1337, 'answer': ' несколько,     Мии Васиковски, Джонни Деппа'}\n",
      "\n",
      "{'score': 0.006040412001311779, 'start': 325, 'end': 333, 'answer': ' героине'}\n",
      "\n",
      "{'score': 0.006485392805188894, 'start': 1433, 'end': 1436, 'answer': ' ее'}\n",
      "\n",
      "{'score': 0.005232049617916346, 'start': 1568, 'end': 1599, 'answer': ' Саймон Бейкер, Жизель Бюндхен.'}\n",
      "\n",
      "{'score': 0.025801552459597588, 'start': 1555, 'end': 1568, 'answer': ' Стэнли Тучи,'}\n",
      "\n",
      "{'score': 0.006133215501904488, 'start': 1316, 'end': 1342, 'answer': ' меня   и,  я могу назвать'}\n",
      "\n",
      "{'score': 0.004858564119786024, 'start': 1522, 'end': 1599, 'answer': ' Да и  ,      даже           –        и что было для меня большим удивлением,'}\n",
      "\n",
      "{'score': 0.006346600130200386, 'start': 1658, 'end': 1666, 'answer': ' Друзья,'}\n",
      "\n",
      "{'score': 0.06578875333070755, 'start': 52, 'end': 103, 'answer': ' Что же касается , вот здесь не всё так однозначно.'}\n",
      "\n",
      "{'score': 0.07657990604639053, 'start': 473, 'end': 492, 'answer': ' она   как и в роли'}\n",
      "\n",
      "{'score': 0.013679812662303448, 'start': 98, 'end': 108, 'answer': ' в фильме,'}\n",
      "\n",
      "{'score': 0.019428139552474022, 'start': 1106, 'end': 1138, 'answer': ' в команду членов экипажа фильма'}\n",
      "\n",
      "{'score': 0.004268159624189138, 'start': 365, 'end': 375, 'answer': ' смотрится'}\n",
      "\n",
      "{'score': 0.004664226900786161, 'start': 904, 'end': 930, 'answer': ' она то в шикарном платье,'}\n",
      "\n",
      "{'score': 0.0020479049999266863, 'start': 949, 'end': 1006, 'answer': ' Далеко не все российские зрители узнали в   до   2004 г.'}\n",
      "\n",
      "{'score': 0.004455970134586096, 'start': 232, 'end': 285, 'answer': ' как сложно себе отказать.    к    как положительных,'}\n",
      "\n",
      "{'score': 0.0034494895953685045, 'start': 1377, 'end': 1385, 'answer': ' Бёртона'}\n",
      "\n",
      "{'score': 0.005408936645835638, 'start': 233, 'end': 249, 'answer': ' так и не очень.'}\n",
      "\n",
      "{'score': 0.00303857633844018, 'start': 125, 'end': 142, 'answer': ' как мне кажется.'}\n",
      "\n",
      "{'score': 0.009218265302479267, 'start': 127, 'end': 157, 'answer': ' Отмечу только, что          -'}\n",
      "\n",
      "{'score': 0.010446956381201744, 'start': 236, 'end': 270, 'answer': ' благодаря чему и  в данном фильме'}\n",
      "\n",
      "{'score': 0.005942468531429768, 'start': 80, 'end': 83, 'answer': ' Её'}\n",
      "\n",
      "{'score': 0.000969927990809083, 'start': 870, 'end': 881, 'answer': ' входят и ,'}\n",
      "\n",
      "{'score': 0.002598278922960162, 'start': 1292, 'end': 1355, 'answer': ' PS:  помогите найти   А вот есть  не скажу, что  ведь персонаж'}\n",
      "\n",
      "{'score': 0.001936930580995977, 'start': 568, 'end': 606, 'answer': ' это    оказались      и  в этом плане'}\n",
      "\n",
      "{'score': 0.0010324306786060333, 'start': 647, 'end': 716, 'answer': ' надо сказать, что         —  что уже говорить о трех часовом фильме,'}\n",
      "\n",
      "{'score': 0.006171272601932287, 'start': 28, 'end': 46, 'answer': ' невольно думаешь,'}\n",
      "\n",
      "{'score': 0.0010797259164974093, 'start': 80, 'end': 88, 'answer': ' который'}\n",
      "\n",
      "{'score': 0.0008597482228651643, 'start': 689, 'end': 692, 'answer': ' 2)'}\n",
      "\n",
      "{'score': 0.0007636288064531982, 'start': 373, 'end': 443, 'answer': ' это    является   не могу не признать, что   это не в укор          и'}\n",
      "\n",
      "{'score': 0.003968839067965746, 'start': 24, 'end': 39, 'answer': ' что  что     ,'}\n",
      "\n",
      "{'score': 0.001361867063678801, 'start': 313, 'end': 355, 'answer': ' Хочется добавить,  —    Ну и конечно же ,'}\n",
      "\n",
      "{'score': 0.0009061339660547674, 'start': 37, 'end': 46, 'answer': ' в образе'}\n",
      "\n",
      "{'score': 0.0011126489844173193, 'start': 133, 'end': 162, 'answer': ' что                 и кстати'}\n",
      "\n",
      "{'score': 0.0006996490410529077, 'start': 558, 'end': 610, 'answer': ' Несмотря на то, что   и  и  именно  и в то же время'}\n",
      "\n",
      "{'score': 0.0011612738016992807, 'start': 1137, 'end': 1163, 'answer': ' Что касается , то и ей  -'}\n",
      "\n",
      "{'score': 0.0017800554633140564, 'start': 611, 'end': 704, 'answer': ' Поэтому                не смотря на то что        И         а  что он теперь       хотя тоже'}\n",
      "\n",
      "{'score': 0.0013912206050008535, 'start': 875, 'end': 896, 'answer': ' не скажу, что      ,'}\n",
      "\n",
      "{'score': 0.0017422670498490334, 'start': 111, 'end': 131, 'answer': \" отмечу        для '\"}\n",
      "\n",
      "{'score': 0.005165361799299717, 'start': 105, 'end': 111, 'answer': ' Также'}\n",
      "\n",
      "{'score': 0.0017216954147443175, 'start': 618, 'end': 664, 'answer': ' Поэтому, наверное,   просто я бы сказали    ,'}\n",
      "\n",
      "{'score': 0.00400529382750392, 'start': 360, 'end': 390, 'answer': ' в том числе и     н    Вообще'}\n",
      "\n",
      "{'score': 0.002850450575351715, 'start': 94, 'end': 103, 'answer': ' почему я'}\n",
      "\n",
      "{'score': 0.009406301192939281, 'start': 83, 'end': 94, 'answer': ' И если  то'}\n",
      "\n",
      "{'score': 0.0014945149887353182, 'start': 572, 'end': 607, 'answer': ' на тот момент еще не до конца    ,'}\n",
      "\n",
      "{'score': 0.0068195536732673645, 'start': 0, 'end': 18, 'answer': 'Также  на то время'}\n",
      "\n",
      "{'score': 0.0047781215980648994, 'start': 286, 'end': 302, 'answer': ' умными словами,'}\n",
      "\n",
      "{'score': 0.005014275666326284, 'start': 408, 'end': 465, 'answer': ' здесь  что                                    и при всем'}\n",
      "\n",
      "{'score': 0.004519204143434763, 'start': 137, 'end': 206, 'answer': ' если в целом взять   то             Теперь если у меня и есть вопрос'}\n",
      "\n",
      "{'score': 0.0015759090892970562, 'start': 127, 'end': 173, 'answer': ' хотя       —  —      —     -       что думаю,'}\n",
      "\n",
      "{'score': 0.043348055332899094, 'start': 132, 'end': 144, 'answer': ' за    когда'}\n",
      "\n",
      "{'score': 0.014132421463727951, 'start': 583, 'end': 601, 'answer': ' всего этого мало,'}\n",
      "\n",
      "{'score': 0.0007093642489053309, 'start': 35, 'end': 39, 'answer': ' это'}\n",
      "\n",
      "{'score': 0.021051714196801186, 'start': 279, 'end': 292, 'answer': ' при м     и,'}\n",
      "\n",
      "{'score': 0.0014391897711902857, 'start': 445, 'end': 545, 'answer': ' у  т                  в то же время       так и своей    так и                       и го   что уже'}\n",
      "\n",
      "{'score': 0.006016842555254698, 'start': 424, 'end': 445, 'answer': ' (лично на мой взгляд'}\n",
      "\n",
      "{'score': 0.0011880958918482065, 'start': 431, 'end': 501, 'answer': ' Но  чтобы  чтобы    однако ж в то же время            и              '}\n",
      "\n",
      "{'score': 0.011807896196842194, 'start': 209, 'end': 257, 'answer': ' касается      И  где  то                    так'}\n",
      "\n",
      "{'score': 0.0024890820495784283, 'start': 300, 'end': 385, 'answer': ' то что                а именно —       —            и         в тоже время          '}\n",
      "\n",
      "{'score': 0.018420547246932983, 'start': 28, 'end': 35, 'answer': ' кстати'}\n",
      "\n",
      "{'score': 0.00605057692155242, 'start': 17, 'end': 43, 'answer': ' А                       -'}\n",
      "\n",
      "{'score': 0.0077254935167729855, 'start': 121, 'end': 177, 'answer': ' такими      в то же время    -   и  хоть и  в частности'}\n",
      "\n",
      "{'score': 0.02455710433423519, 'start': 214, 'end': 215, 'answer': ' '}\n",
      "\n",
      "{'score': 0.020288195461034775, 'start': 112, 'end': 215, 'answer': ' да еще и      И, наконец,          конечно же,                              – потому что              '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.017963610589504242, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n",
      "{'score': 0.05198545381426811, 'start': 112, 'end': 113, 'answer': ' '}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/question_answering.py:301: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  p_mask = np.asarray(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/question_answering.py:301: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  p_mask = np.asarray(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/question_answering.py:301: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  p_mask = np.asarray(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/question_answering.py:301: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  p_mask = np.asarray(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/question_answering.py:301: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  p_mask = np.asarray(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/question_answering.py:301: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  p_mask = np.asarray(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/question_answering.py:301: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  p_mask = np.asarray(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/question_answering.py:301: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  p_mask = np.asarray(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/question_answering.py:301: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  p_mask = np.asarray(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/question_answering.py:301: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  p_mask = np.asarray(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/question_answering.py:301: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  p_mask = np.asarray(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/question_answering.py:301: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  p_mask = np.asarray(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/question_answering.py:301: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  p_mask = np.asarray(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/question_answering.py:301: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  p_mask = np.asarray(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/question_answering.py:301: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  p_mask = np.asarray(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/question_answering.py:301: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  p_mask = np.asarray(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/question_answering.py:301: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  p_mask = np.asarray(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/question_answering.py:301: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  p_mask = np.asarray(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/question_answering.py:301: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  p_mask = np.asarray(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/question_answering.py:301: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  p_mask = np.asarray(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/question_answering.py:301: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  p_mask = np.asarray(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/question_answering.py:301: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  p_mask = np.asarray(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/question_answering.py:301: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  p_mask = np.asarray(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/question_answering.py:301: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  p_mask = np.asarray(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/question_answering.py:301: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  p_mask = np.asarray(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/question_answering.py:301: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  p_mask = np.asarray(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/question_answering.py:301: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  p_mask = np.asarray(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/question_answering.py:301: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  p_mask = np.asarray(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/question_answering.py:301: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  p_mask = np.asarray(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/question_answering.py:301: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  p_mask = np.asarray(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/question_answering.py:301: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  p_mask = np.asarray(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/question_answering.py:301: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  p_mask = np.asarray(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/question_answering.py:301: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  p_mask = np.asarray(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/question_answering.py:301: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  p_mask = np.asarray(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/question_answering.py:301: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  p_mask = np.asarray(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/question_answering.py:301: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  p_mask = np.asarray(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/question_answering.py:301: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  p_mask = np.asarray(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/question_answering.py:301: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  p_mask = np.asarray(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/question_answering.py:301: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  p_mask = np.asarray(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/question_answering.py:301: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  p_mask = np.asarray(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/question_answering.py:301: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  p_mask = np.asarray(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/question_answering.py:301: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  p_mask = np.asarray(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/question_answering.py:301: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  p_mask = np.asarray(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/question_answering.py:301: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  p_mask = np.asarray(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/question_answering.py:301: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  p_mask = np.asarray(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/question_answering.py:301: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  p_mask = np.asarray(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/question_answering.py:301: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  p_mask = np.asarray(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/question_answering.py:301: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  p_mask = np.asarray(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/question_answering.py:301: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  p_mask = np.asarray(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/question_answering.py:301: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  p_mask = np.asarray(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/question_answering.py:301: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  p_mask = np.asarray(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/question_answering.py:301: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  p_mask = np.asarray(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/question_answering.py:301: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  p_mask = np.asarray(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/question_answering.py:301: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  p_mask = np.asarray(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/question_answering.py:301: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  p_mask = np.asarray(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/question_answering.py:301: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  p_mask = np.asarray(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/question_answering.py:301: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  p_mask = np.asarray(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/question_answering.py:301: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  p_mask = np.asarray(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/question_answering.py:301: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  p_mask = np.asarray(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/question_answering.py:301: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  p_mask = np.asarray(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/question_answering.py:301: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  p_mask = np.asarray(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/question_answering.py:301: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  p_mask = np.asarray(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/question_answering.py:301: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  p_mask = np.asarray(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/question_answering.py:301: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  p_mask = np.asarray(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/question_answering.py:301: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  p_mask = np.asarray(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/question_answering.py:301: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  p_mask = np.asarray(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/question_answering.py:301: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  p_mask = np.asarray(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/question_answering.py:301: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  p_mask = np.asarray(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/question_answering.py:301: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  p_mask = np.asarray(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/question_answering.py:301: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  p_mask = np.asarray(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/question_answering.py:301: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  p_mask = np.asarray(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/question_answering.py:301: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  p_mask = np.asarray(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/question_answering.py:301: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  p_mask = np.asarray(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/question_answering.py:301: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  p_mask = np.asarray(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/question_answering.py:301: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  p_mask = np.asarray(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/question_answering.py:301: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  p_mask = np.asarray(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/question_answering.py:301: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  p_mask = np.asarray(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/question_answering.py:301: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  p_mask = np.asarray(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/question_answering.py:301: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  p_mask = np.asarray(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:705: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/question_answering.py:301: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  p_mask = np.asarray(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1077: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "scores, answers = get_person_characteristics(data, 'Хэтэуэй', model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "a9a523cb",
   "metadata": {
    "cellId": "u0qvbtb7pb6cpyq6zbtl"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fdaad687430>]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#!g1.1\n",
    "plt.plot(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "d717c23a",
   "metadata": {
    "cellId": "vzoqcgpfn3aq2bdcthc5an"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "clean_answers = list(map(lambda s: s.strip(' .,:'), answers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "343b1e22",
   "metadata": {
    "cellId": "axjz9478ufmasb2epvqagt"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "clean_answers = np.array(clean_answers)\n",
    "scores = np.array(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "81d16f1f",
   "metadata": {
    "cellId": "w6kji1r0w6p29wumjhms8c"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "clean_answers = clean_answers[scores > 0.18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "bed39252",
   "metadata": {
    "cellId": "qz3wiwdzeypxffzsp9snb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['прекрасная актриса', 'отлично отыграла своего персонажа',\n",
       "       'свежа, очаровательна и убедительна', 'стала Селиной Кайл',\n",
       "       'Потрясающая, милая', 'делает выбор',\n",
       "       'невероятно красивая женщина', 'Неплохую игру', 'милая Энн',\n",
       "       'своенравная, дерзкая, гордая и опасная',\n",
       "       'изучала танцы и разные трюки', 'одной из моих любимых актрис',\n",
       "       'играла с переменным успехом', 'обычной обаятельной девушки',\n",
       "       'прекрасно справилась с этой ролью',\n",
       "       'красивая, сексуальная и убедительная', 'актерскую игру',\n",
       "       'милая, обаятельная и мечтательная Белая Королева',\n",
       "       'задача заключалась воплотить на экране Белую Королеву',\n",
       "       'моя любимая актриса', 'превзошла саму себя', 'Андреа',\n",
       "       'интересную героиню', 'создав живого, привлекательного персонажа',\n",
       "       'Красавица', 'с ролью она определенно справилась',\n",
       "       'это девушка, которая может покорить любого парня своим только взглядом',\n",
       "       'великолепно справилась со своей ролью', 'она невероятна',\n",
       "       'мастерски воплотила Энди на экране', 'Кошка Хэтэуэй',\n",
       "       'Женщину — кошку', 'покорительницы космической бездны',\n",
       "       'отлично выполнила свою работу', 'бесподобна', 'изящный эскиз',\n",
       "       'маленькую, но отлично играющую без скидок на возраст',\n",
       "       'достойно ответила всем скептикам своей игрой', 'Женщины-кошки',\n",
       "       'вошла в свою роль как нельзя лучше',\n",
       "       'грациозная, гибкая, неприступная', 'очень притягательная',\n",
       "       'сыграла она просто блестяще', 'чертовски хороша',\n",
       "       'удалась ей как нельзя лучше', 'Героиня Хэтэуэй права',\n",
       "       'великолепно воплотилась в роль', 'талантливой актрисой', 'Хороша',\n",
       "       'очаровательная и милая', 'героиня жаждущая любить и быть любимой',\n",
       "       'разрушила все законы квантовой механики', 'взрослеющую звезду',\n",
       "       'На удивление отлично сыграла', 'милой простушки',\n",
       "       'сыграла замечательно', 'слегка мальчишеском, гаврошевом образе',\n",
       "       'по плечу все роли', 'прекрасно справляется',\n",
       "       'была очень убедительна', 'достаточно готичной Белой королевы;',\n",
       "       'тяжко к ней готовилась', 'довольно ограничена', 'Браво',\n",
       "       'отлично умеющую менять маски',\n",
       "       'Хэтэуэй   именно после этой картины',\n",
       "       'всё что она делала было на благо человечества',\n",
       "       '8 из 10    Белой королеве', 'очень хороша', 'персонаж на вырост',\n",
       "       'известная по ряду превосходно исполненных ролей',\n",
       "       'способна блестяще воплотить в жизнь',\n",
       "       'была уж слишком напыщенна и изнеженна',\n",
       "       'превзошла Мишель Пфайфер', 'губаста и упряма',\n",
       "       'нежной, легкой, воздушной', 'Кошки, Которая Гуляет Сама По Себе',\n",
       "       'это тоже была очень серьезная роль',\n",
       "       'хрупкой, но решительной Белой Королевы',\n",
       "       'очень гармонично смотрится', 'абсолютна,  безгранична',\n",
       "       'вышло даже намного лучше, чем когда то у Пфайффер',\n",
       "       'Возможно  немного не хватает сексуальности',\n",
       "       'проникновенно сыграла Белую Королеву;', 'была на высоте',\n",
       "       'очаровательная', 'прекрасно воплотила роль',\n",
       "       'неопытной и неуклюжей', 'как её злобной сестрице', 'Хэтэуэй  !',\n",
       "       'сотворила чудо в финале', 'вполне вероятно', 'повезло',\n",
       "       'единственная женщина, которая получила двоякую роль',\n",
       "       \"в 'Дьявол носит prada'\", 'прекрасную', 'чудесная Маккензи Фой',\n",
       "       'женщина-кошка была просто великолепна',\n",
       "       'героиня  столь же интересна', 'весьма неплохо', 'она  а',\n",
       "       'очень живые и динамичные', 'в очень неожиданном образе',\n",
       "       'Кошки и цели, и методы другие', 'она буквально   Хэтэуэй   но',\n",
       "       'она заслуживает особой похвалы', 'женщины-кошки',\n",
       "       'не менее яркая актриса Голливуда', 'конечно)',\n",
       "       'дерзкая, пластичная, веселая, хитрая',\n",
       "       'радует глаз не только внешностью, но и отличной игрой',\n",
       "       'Сыграла     а своим упорством и трудолюбием',\n",
       "       'пожалуй самое главное украшение фильма', 'Безумный Шляпник',\n",
       "       'по моему мнению,              -  и   -', 'готичной королевы',\n",
       "       'отличный', 'сильно удивила', 'Уэс Бентли играет мебель',\n",
       "       'Мэтт Дэймон', 'удивил', 'книжная Алиса',\n",
       "       'должна быть такой не эмоциональной и даже слегка инфернальной',\n",
       "       'роль на самом деле небольшая', 'она',\n",
       "       '(это, пожалуй её  на сегодняшний день)',\n",
       "       'ну а про  и говорить не нужно',\n",
       "       'в каждом движении и каждой фразе', 'сыгравшая в этом фильме',\n",
       "       'лично мне очень даже понравилась', 'всеми обруганная',\n",
       "       'местами весёлая и очень очень опасная штучка',\n",
       "       'поигрывая разными эмоциями',\n",
       "       'хитрой и соблазнительной воровки с инстинктами кошки',\n",
       "       '(по крайней мере', 'клеем, который держит все воедино', 'плохой',\n",
       "       'вовремя понимает, что гламурный мир - не главное в жизни',\n",
       "       'так как она', 'Оно конечно хорошо', 'Хелены Бонем Картер',\n",
       "       'Холли Берри', 'мрачный и весьма серьезный фильм',\n",
       "       'окунуться в потрясающую атмосферу безумия',\n",
       "       'посмотрев еще несколько фильмов с ее участием',\n",
       "       'монологом о любви'], dtype='<U99')"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g1.1\n",
    "clean_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "a6982b6c",
   "metadata": {
    "cellId": "rt9q9gz17gt3occzbl9oh"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "import dill\n",
    "\n",
    "with open('data/wordcloud/scores.np', 'wb') as f:\n",
    "    dill.dump(scores[scores > 0.18], f)\n",
    "with open('data/wordcloud/clean_answers.np', 'wb') as f:\n",
    "    dill.dump(clean_answers, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e838041",
   "metadata": {
    "cellId": "lqnz3jw2dzxvoz0l11a1l"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e29e37",
   "metadata": {
    "cellId": "dbuso3tj2ulfghhb7d0w5w"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "bc6bfe38",
   "metadata": {
    "cellId": "wao0cd20u3o7p0kp77b4yi"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=400x200>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g1.1\n",
    "wc = WordCloud().generate(' '.join(clean_answers))\n",
    "wc.to_image()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "notebookId": "cfcb4efa-a037-4829-bb77-861193bcfa56",
  "notebookPath": "nlp-coursework/notebooks/models/summarization/WordCloud by QA.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
